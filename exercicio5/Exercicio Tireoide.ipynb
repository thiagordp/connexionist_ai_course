{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 5 - Thyroid desease prediction using Convolutional Neural Networks\n",
    "\n",
    "\n",
    "Available at: \n",
    "- https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease\n",
    "- http://networkrepository.com/thyroid-disease-thyroid0387.php\n",
    "- https://search.r-project.org/CRAN/refmans/MoTBFs/html/thyroid.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 3614,
     "status": "ok",
     "timestamp": 1627161045686,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "ONTVLB0nA89y",
    "outputId": "eabfa509-56e7-4ee7-f092-a70a6d438248",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 12:10:34.006342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: <module 'tensorflow._api.v2.version' from '/home/trdp/anaconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n",
      "Is GPU backend?\n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4045733830364778292\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 12:10:36.415718: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-25 12:10:36.422844: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-25 12:10:36.422873: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-25 12:10:36.422897: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ideapad320): /proc/driver/nvidia/version does not exist\n",
      "2022-06-25 12:10:36.422953: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools    \n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF version:\", tf.version)\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Is GPU backend?\\n\", device_lib.list_local_devices())\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, CondensedNearestNeighbour\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Downloading Training Dataset\n",
    "\n",
    "The first step is the download of dataset and transform it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset\n",
      "Tranform to pandas dataframe\n",
      "Shape: (3772, 24)\n",
      "Head\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.146</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00190</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.085</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.153</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  14  15       16     17  \\\n",
       "0  0.73   0   1   0   0   0   0   0   1   0  ...   0   0  0.00060  0.015   \n",
       "1  0.24   0   0   0   0   0   0   0   0   0  ...   0   0  0.00025  0.030   \n",
       "2  0.47   0   0   0   0   0   0   0   0   0  ...   0   0  0.00190  0.024   \n",
       "3  0.64   1   0   0   0   0   0   0   0   0  ...   0   0  0.00090  0.017   \n",
       "4  0.23   0   0   0   0   0   0   0   0   0  ...   0   0  0.00025  0.026   \n",
       "\n",
       "      18     19     20  21  22  23  \n",
       "0  0.120  0.082  0.146   3 NaN NaN  \n",
       "1  0.143  0.133  0.108   3 NaN NaN  \n",
       "2  0.102  0.131  0.078   3 NaN NaN  \n",
       "3  0.077  0.090  0.085   3 NaN NaN  \n",
       "4  0.139  0.090  0.153   3 NaN NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Downloading the dataset\")\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/ann-train.data\"\n",
    "s = requests.get(url).contents=requests.get(url).content\n",
    "print(\"Tranform to pandas dataframe\")\n",
    "dataTrain=pd.read_csv(io.StringIO(s.decode('utf-8')),delimiter=' ',header=None)\n",
    "\n",
    "\n",
    "print(\"Shape:\", dataTrain.shape)\n",
    "print(\"Head\")\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1627161045688,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "WUYWQzfIA894",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Removing NaN columns\n",
    "del dataTrain[22]\n",
    "del dataTrain[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1627161045689,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "9sUGNCb1A895",
    "outputId": "ab00fa7b-52cb-4a00-e61d-dd0120e6b1f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.146</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00190</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.085</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.153</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15       16  \\\n",
       "0  0.73   0   1   0   0   0   0   0   1   0  ...   0   0   0   0  0.00060   \n",
       "1  0.24   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00025   \n",
       "2  0.47   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00190   \n",
       "3  0.64   1   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00090   \n",
       "4  0.23   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00025   \n",
       "\n",
       "      17     18     19     20  21  \n",
       "0  0.015  0.120  0.082  0.146   3  \n",
       "1  0.030  0.143  0.133  0.108   3  \n",
       "2  0.024  0.102  0.131  0.078   3  \n",
       "3  0.017  0.077  0.090  0.085   3  \n",
       "4  0.026  0.139  0.090  0.153   3  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1627161045691,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "H0clK1EmA896",
    "outputId": "fae44f5a-5abf-4c3a-dfec-baf772c15902",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00190</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  11  12  13  14  15       16  \\\n",
       "0  0.73   0   1   0   0   0   0   0   1   0  ...   0   0   0   0   0  0.00060   \n",
       "1  0.24   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00025   \n",
       "2  0.47   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00190   \n",
       "3  0.64   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00090   \n",
       "4  0.23   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00025   \n",
       "\n",
       "      17     18     19     20  \n",
       "0  0.015  0.120  0.082  0.146  \n",
       "1  0.030  0.143  0.133  0.108  \n",
       "2  0.024  0.102  0.131  0.078  \n",
       "3  0.017  0.077  0.090  0.085  \n",
       "4  0.026  0.139  0.090  0.153  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictor data\n",
    "inputTrain = dataTrain.drop([21], axis=1)\n",
    "inputTrain.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1627161045692,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "O6cawaraA897",
    "outputId": "00c9b163-75b8-4213-a9ab-d8aea1357b77",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Counter({2: 3488, 1: 191, 0: 93})\n"
     ]
    }
   ],
   "source": [
    "# Target data\n",
    "outputTrain = dataTrain[21] - 1\n",
    "\n",
    "print(\"Labels\", Counter(outputTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1627161047007,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "wXClhA2jA897",
    "outputId": "c2fb0649-da66-466d-b7e5-dc5914e9494c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3428, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.085</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.107</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.239</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.099</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.099</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3   4   5   6   7   8   9   ...  14  15      16     17  \\\n",
       "0  0.29   0   0   0   0   0   0   0   0   0  ...   0   0  0.0061  0.028   \n",
       "1  0.32   0   0   0   0   0   0   0   0   0  ...   0   0  0.0013  0.019   \n",
       "2  0.35   0   0   0   0   0   0   0   0   0  ...   0   0  0.0000  0.031   \n",
       "3  0.21   0   0   0   0   0   0   0   0   0  ...   0   0  0.0010  0.018   \n",
       "4  0.22   0   0   0   0   1   0   0   0   0  ...   0   0  0.0004  0.022   \n",
       "\n",
       "      18     19     20  21  22  23  \n",
       "0  0.111  0.131  0.085   2 NaN NaN  \n",
       "1  0.084  0.078  0.107   3 NaN NaN  \n",
       "2  0.239  0.100  0.239   3 NaN NaN  \n",
       "3  0.087  0.088  0.099   3 NaN NaN  \n",
       "4  0.134  0.135  0.099   3 NaN NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Downloading test data\n",
    "#\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/ann-test.data\"\n",
    "s = requests.get(url).contents=requests.get(url).content\n",
    "dataTest=pd.read_csv(io.StringIO(s.decode('utf-8')),delimiter=' ',header=None)\n",
    "\n",
    "dataTest.head()\n",
    "\n",
    "print(dataTest.shape)\n",
    "dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1627161047010,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "MBJZQH0fA898",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del dataTest[22]\n",
    "del dataTest[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1627161047012,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "R2SEl2KZA899",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputTest = dataTest.drop([21], axis=1)\n",
    "outputTest = dataTest[21] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "In this section, we add a feature selection step, using $\\chi^2$ test, which was not required to the assignment.\n",
    "\n",
    "We try some values of features to be selected ($k$) and check the $k$ that produces the highest macro recall in the validation set.\n",
    "\n",
    "One can see that with 13 features, the recall metric is significantly better than using almost all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10, selected_features: ['x1' 'x2' 'x5' 'x6' 'x7' 'x9' 'x15' 'x16' 'x18' 'x20']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trdp/anaconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18   0   1]\n",
      " [  0  30   8]\n",
      " [  2   2 694]]\n",
      "k = 13, selected_features: ['x1' 'x2' 'x4' 'x5' 'x6' 'x7' 'x9' 'x10' 'x12' 'x15' 'x16' 'x18' 'x20']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trdp/anaconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19   0   0]\n",
      " [  0  34   4]\n",
      " [  2   1 695]]\n",
      "k = 15, selected_features: ['x1' 'x2' 'x3' 'x4' 'x5' 'x6' 'x7' 'x8' 'x9' 'x10' 'x12' 'x15' 'x16'\n",
      " 'x18' 'x20']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trdp/anaconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18   1   0]\n",
      " [  2  35   1]\n",
      " [  2  11 685]]\n",
      "k = 20, selected_features: ['x1' 'x2' 'x3' 'x4' 'x5' 'x6' 'x7' 'x8' 'x9' 'x10' 'x11' 'x12' 'x13'\n",
      " 'x14' 'x15' 'x16' 'x17' 'x18' 'x19' 'x20']\n",
      "[[ 18   1   0]\n",
      " [  0  33   5]\n",
      " [  1   3 694]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trdp/anaconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "recalls = []\n",
    "ks = [10, 13, 15, 20]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(inputTrain, outputTrain, test_size=0.2, shuffle=True, stratify=outputTrain)\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train)\n",
    "y_val_one_hot = keras.utils.to_categorical(y_val)\n",
    "\n",
    "for k in ks:\n",
    "   \n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=chi2, k=k)\n",
    "\n",
    "    # learn relationship from training data\n",
    "    fs.fit(x_train, y_train)\n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(x_train)\n",
    "    # transform test input data\n",
    "    X_val_fs = fs.transform(x_val)\n",
    "\n",
    "    print(\"k = %d, selected_features: %s\"% (k, str(fs.get_feature_names_out())))\n",
    "    model = KerasClassifier(build_fn=create_model, input_shape=X_train_fs.shape[1], epochs=200, verbose=0, hidden_layer_sizes=(256,256,256,))\n",
    "    model.fit(X_train_fs,y_train_one_hot)\n",
    "\n",
    "    y_pred = model.predict(X_val_fs)\n",
    "\n",
    "    recall_value = recall_score(y_val,y_pred, average=\"macro\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    recalls.append(recall_value)\n",
    "\n",
    "plt.title(\"Feature selection results\")\n",
    "plt.xlabel(\"Number of Features (k)\")\n",
    "plt.ylabel(\"Macro recall\")\n",
    "plt.plot(ks, recalls)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1627161047019,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "HFsXbrdMA899",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "# fit using the train set\n",
    "scaler.fit(inputTrain)\n",
    "# transform the test test\n",
    "xtrainN = scaler.transform(inputTrain)\n",
    "xtestN = scaler.transform(inputTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1627161047024,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "i7PYjIIomZFl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputTrain_one_hot = keras.utils.to_categorical(outputTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1627161047026,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "S1_jcOG0A89-",
    "outputId": "fa4f877c-2e5e-40a0-96cc-2d529523de73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1 2]\n",
      "Class weights: [13.51971326  6.58289703  0.36047401]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Calculating class weights\n",
    "#\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes = np.unique(outputTrain), y=outputTrain)\n",
    "print(\"Labels:\", np.unique(outputTrain))\n",
    "print(\"Class weights:\", class_weights)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1627161047055,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "d7vAF0TFA89_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (3017, 21) Counter({2: 2790, 1: 153, 0: 74})\n",
      "Validation shape (755, 21) Counter({2: 698, 1: 38, 0: 19})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    xtrainN, \n",
    "    outputTrain_one_hot, \n",
    "    test_size = 0.2, \n",
    "    random_state = 1, \n",
    "    stratify=outputTrain\n",
    ")  \n",
    "\n",
    "print(\"Train shape\", X_train.shape, Counter(np.argmax(y_train, axis=1)))\n",
    "print(\"Validation shape\", X_validation.shape, Counter(np.argmax(y_validation, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1627161047058,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "e7xiLTRyA89_",
    "outputId": "43fc955d-29c7-440d-937e-6a1b649fcbdc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               5632      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 72,195\n",
      "Trainable params: 72,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 12:11:21.957908: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-25 12:11:21.958152: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(256, activation=\"relu\", input_shape=(X_train.shape[-1],)\n",
    "        ),\n",
    "        Dropout(0.3),\n",
    "        #Dense(256, activation=\"relu\"),\n",
    "        #Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(3, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 158938,
     "status": "ok",
     "timestamp": 1627161205929,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "UuQ4Jg9oA8-A",
    "outputId": "f2742d8b-8819-4961-aab1-86a2c525f3b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 10:26:12.212020: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-25 10:26:12.228645: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4096\n",
      "24/24 - 2s - loss: 0.6420 - fn: 2767.0000 - fp: 428.0000 - tn: 5606.0000 - tp: 250.0000 - precision: 0.3687 - recall: 0.0829 - val_loss: 0.5748 - val_fn: 755.0000 - val_fp: 0.0000e+00 - val_tn: 1510.0000 - val_tp: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/4096\n",
      "24/24 - 0s - loss: 0.5834 - fn: 2877.0000 - fp: 8.0000 - tn: 6026.0000 - tp: 140.0000 - precision: 0.9459 - recall: 0.0464 - val_loss: 0.5189 - val_fn: 547.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 208.0000 - val_precision: 0.9327 - val_recall: 0.2755\n",
      "Epoch 3/4096\n",
      "24/24 - 0s - loss: 0.5163 - fn: 1739.0000 - fp: 101.0000 - tn: 5933.0000 - tp: 1278.0000 - precision: 0.9268 - recall: 0.4236 - val_loss: 0.4727 - val_fn: 419.0000 - val_fp: 126.0000 - val_tn: 1384.0000 - val_tp: 336.0000 - val_precision: 0.7273 - val_recall: 0.4450\n",
      "Epoch 4/4096\n",
      "24/24 - 0s - loss: 0.4372 - fn: 1416.0000 - fp: 608.0000 - tn: 5426.0000 - tp: 1601.0000 - precision: 0.7248 - recall: 0.5307 - val_loss: 0.4469 - val_fn: 286.0000 - val_fp: 340.0000 - val_tn: 1170.0000 - val_tp: 469.0000 - val_precision: 0.5797 - val_recall: 0.6212\n",
      "Epoch 5/4096\n",
      "24/24 - 0s - loss: 0.3831 - fn: 1105.0000 - fp: 973.0000 - tn: 5061.0000 - tp: 1912.0000 - precision: 0.6627 - recall: 0.6337 - val_loss: 0.4587 - val_fn: 367.0000 - val_fp: 267.0000 - val_tn: 1243.0000 - val_tp: 388.0000 - val_precision: 0.5924 - val_recall: 0.5139\n",
      "Epoch 6/4096\n",
      "24/24 - 0s - loss: 0.3624 - fn: 1099.0000 - fp: 884.0000 - tn: 5150.0000 - tp: 1918.0000 - precision: 0.6845 - recall: 0.6357 - val_loss: 0.4050 - val_fn: 253.0000 - val_fp: 186.0000 - val_tn: 1324.0000 - val_tp: 502.0000 - val_precision: 0.7297 - val_recall: 0.6649\n",
      "Epoch 7/4096\n",
      "24/24 - 0s - loss: 0.3376 - fn: 867.0000 - fp: 940.0000 - tn: 5094.0000 - tp: 2150.0000 - precision: 0.6958 - recall: 0.7126 - val_loss: 0.3771 - val_fn: 212.0000 - val_fp: 185.0000 - val_tn: 1325.0000 - val_tp: 543.0000 - val_precision: 0.7459 - val_recall: 0.7192\n",
      "Epoch 8/4096\n",
      "24/24 - 0s - loss: 0.3199 - fn: 875.0000 - fp: 689.0000 - tn: 5345.0000 - tp: 2142.0000 - precision: 0.7566 - recall: 0.7100 - val_loss: 0.3309 - val_fn: 130.0000 - val_fp: 152.0000 - val_tn: 1358.0000 - val_tp: 625.0000 - val_precision: 0.8044 - val_recall: 0.8278\n",
      "Epoch 9/4096\n",
      "24/24 - 0s - loss: 0.3123 - fn: 878.0000 - fp: 772.0000 - tn: 5262.0000 - tp: 2139.0000 - precision: 0.7348 - recall: 0.7090 - val_loss: 0.3398 - val_fn: 134.0000 - val_fp: 225.0000 - val_tn: 1285.0000 - val_tp: 621.0000 - val_precision: 0.7340 - val_recall: 0.8225\n",
      "Epoch 10/4096\n",
      "24/24 - 0s - loss: 0.3141 - fn: 835.0000 - fp: 905.0000 - tn: 5129.0000 - tp: 2182.0000 - precision: 0.7068 - recall: 0.7232 - val_loss: 0.3147 - val_fn: 120.0000 - val_fp: 170.0000 - val_tn: 1340.0000 - val_tp: 635.0000 - val_precision: 0.7888 - val_recall: 0.8411\n",
      "Epoch 11/4096\n",
      "24/24 - 0s - loss: 0.3110 - fn: 901.0000 - fp: 731.0000 - tn: 5303.0000 - tp: 2116.0000 - precision: 0.7432 - recall: 0.7014 - val_loss: 0.3492 - val_fn: 181.0000 - val_fp: 136.0000 - val_tn: 1374.0000 - val_tp: 574.0000 - val_precision: 0.8085 - val_recall: 0.7603\n",
      "Epoch 12/4096\n",
      "24/24 - 0s - loss: 0.2943 - fn: 709.0000 - fp: 653.0000 - tn: 5381.0000 - tp: 2308.0000 - precision: 0.7795 - recall: 0.7650 - val_loss: 0.3704 - val_fn: 198.0000 - val_fp: 191.0000 - val_tn: 1319.0000 - val_tp: 557.0000 - val_precision: 0.7447 - val_recall: 0.7377\n",
      "Epoch 13/4096\n",
      "24/24 - 0s - loss: 0.2875 - fn: 819.0000 - fp: 832.0000 - tn: 5202.0000 - tp: 2198.0000 - precision: 0.7254 - recall: 0.7285 - val_loss: 0.3228 - val_fn: 184.0000 - val_fp: 98.0000 - val_tn: 1412.0000 - val_tp: 571.0000 - val_precision: 0.8535 - val_recall: 0.7563\n",
      "Epoch 14/4096\n",
      "24/24 - 0s - loss: 0.2968 - fn: 717.0000 - fp: 607.0000 - tn: 5427.0000 - tp: 2300.0000 - precision: 0.7912 - recall: 0.7623 - val_loss: 0.4205 - val_fn: 226.0000 - val_fp: 367.0000 - val_tn: 1143.0000 - val_tp: 529.0000 - val_precision: 0.5904 - val_recall: 0.7007\n",
      "Epoch 15/4096\n",
      "24/24 - 0s - loss: 0.2809 - fn: 784.0000 - fp: 732.0000 - tn: 5302.0000 - tp: 2233.0000 - precision: 0.7531 - recall: 0.7401 - val_loss: 0.3645 - val_fn: 220.0000 - val_fp: 163.0000 - val_tn: 1347.0000 - val_tp: 535.0000 - val_precision: 0.7665 - val_recall: 0.7086\n",
      "Epoch 16/4096\n",
      "24/24 - 0s - loss: 0.2714 - fn: 749.0000 - fp: 797.0000 - tn: 5237.0000 - tp: 2268.0000 - precision: 0.7400 - recall: 0.7517 - val_loss: 0.3630 - val_fn: 182.0000 - val_fp: 226.0000 - val_tn: 1284.0000 - val_tp: 573.0000 - val_precision: 0.7171 - val_recall: 0.7589\n",
      "Epoch 17/4096\n",
      "24/24 - 0s - loss: 0.2692 - fn: 830.0000 - fp: 843.0000 - tn: 5191.0000 - tp: 2187.0000 - precision: 0.7218 - recall: 0.7249 - val_loss: 0.3049 - val_fn: 163.0000 - val_fp: 115.0000 - val_tn: 1395.0000 - val_tp: 592.0000 - val_precision: 0.8373 - val_recall: 0.7841\n",
      "Epoch 18/4096\n",
      "24/24 - 0s - loss: 0.2795 - fn: 750.0000 - fp: 705.0000 - tn: 5329.0000 - tp: 2267.0000 - precision: 0.7628 - recall: 0.7514 - val_loss: 0.3780 - val_fn: 196.0000 - val_fp: 255.0000 - val_tn: 1255.0000 - val_tp: 559.0000 - val_precision: 0.6867 - val_recall: 0.7404\n",
      "Epoch 19/4096\n",
      "24/24 - 0s - loss: 0.2645 - fn: 715.0000 - fp: 696.0000 - tn: 5338.0000 - tp: 2302.0000 - precision: 0.7678 - recall: 0.7630 - val_loss: 0.3525 - val_fn: 186.0000 - val_fp: 192.0000 - val_tn: 1318.0000 - val_tp: 569.0000 - val_precision: 0.7477 - val_recall: 0.7536\n",
      "Epoch 20/4096\n",
      "24/24 - 0s - loss: 0.2649 - fn: 724.0000 - fp: 679.0000 - tn: 5355.0000 - tp: 2293.0000 - precision: 0.7715 - recall: 0.7600 - val_loss: 0.4154 - val_fn: 269.0000 - val_fp: 231.0000 - val_tn: 1279.0000 - val_tp: 486.0000 - val_precision: 0.6778 - val_recall: 0.6437\n",
      "Epoch 21/4096\n",
      "24/24 - 0s - loss: 0.2740 - fn: 698.0000 - fp: 737.0000 - tn: 5297.0000 - tp: 2319.0000 - precision: 0.7588 - recall: 0.7686 - val_loss: 0.3291 - val_fn: 176.0000 - val_fp: 158.0000 - val_tn: 1352.0000 - val_tp: 579.0000 - val_precision: 0.7856 - val_recall: 0.7669\n",
      "Epoch 22/4096\n",
      "24/24 - 0s - loss: 0.2550 - fn: 645.0000 - fp: 663.0000 - tn: 5371.0000 - tp: 2372.0000 - precision: 0.7815 - recall: 0.7862 - val_loss: 0.3119 - val_fn: 153.0000 - val_fp: 147.0000 - val_tn: 1363.0000 - val_tp: 602.0000 - val_precision: 0.8037 - val_recall: 0.7974\n",
      "Epoch 23/4096\n",
      "24/24 - 0s - loss: 0.2655 - fn: 697.0000 - fp: 686.0000 - tn: 5348.0000 - tp: 2320.0000 - precision: 0.7718 - recall: 0.7690 - val_loss: 0.3025 - val_fn: 141.0000 - val_fp: 147.0000 - val_tn: 1363.0000 - val_tp: 614.0000 - val_precision: 0.8068 - val_recall: 0.8132\n",
      "Epoch 24/4096\n",
      "24/24 - 0s - loss: 0.2511 - fn: 695.0000 - fp: 743.0000 - tn: 5291.0000 - tp: 2322.0000 - precision: 0.7576 - recall: 0.7696 - val_loss: 0.4079 - val_fn: 249.0000 - val_fp: 234.0000 - val_tn: 1276.0000 - val_tp: 506.0000 - val_precision: 0.6838 - val_recall: 0.6702\n",
      "Epoch 25/4096\n",
      "24/24 - 0s - loss: 0.2478 - fn: 749.0000 - fp: 705.0000 - tn: 5329.0000 - tp: 2268.0000 - precision: 0.7629 - recall: 0.7517 - val_loss: 0.3047 - val_fn: 148.0000 - val_fp: 144.0000 - val_tn: 1366.0000 - val_tp: 607.0000 - val_precision: 0.8083 - val_recall: 0.8040\n",
      "Epoch 26/4096\n",
      "24/24 - 0s - loss: 0.2503 - fn: 678.0000 - fp: 685.0000 - tn: 5349.0000 - tp: 2339.0000 - precision: 0.7735 - recall: 0.7753 - val_loss: 0.2876 - val_fn: 139.0000 - val_fp: 128.0000 - val_tn: 1382.0000 - val_tp: 616.0000 - val_precision: 0.8280 - val_recall: 0.8159\n",
      "Epoch 27/4096\n",
      "24/24 - 0s - loss: 0.2499 - fn: 655.0000 - fp: 648.0000 - tn: 5386.0000 - tp: 2362.0000 - precision: 0.7847 - recall: 0.7829 - val_loss: 0.2559 - val_fn: 108.0000 - val_fp: 108.0000 - val_tn: 1402.0000 - val_tp: 647.0000 - val_precision: 0.8570 - val_recall: 0.8570\n",
      "Epoch 28/4096\n",
      "24/24 - 0s - loss: 0.2474 - fn: 694.0000 - fp: 709.0000 - tn: 5325.0000 - tp: 2323.0000 - precision: 0.7662 - recall: 0.7700 - val_loss: 0.3079 - val_fn: 155.0000 - val_fp: 153.0000 - val_tn: 1357.0000 - val_tp: 600.0000 - val_precision: 0.7968 - val_recall: 0.7947\n",
      "Epoch 29/4096\n",
      "24/24 - 0s - loss: 0.2418 - fn: 712.0000 - fp: 724.0000 - tn: 5310.0000 - tp: 2305.0000 - precision: 0.7610 - recall: 0.7640 - val_loss: 0.3083 - val_fn: 155.0000 - val_fp: 151.0000 - val_tn: 1359.0000 - val_tp: 600.0000 - val_precision: 0.7989 - val_recall: 0.7947\n",
      "Epoch 30/4096\n",
      "24/24 - 0s - loss: 0.2353 - fn: 637.0000 - fp: 664.0000 - tn: 5370.0000 - tp: 2380.0000 - precision: 0.7819 - recall: 0.7889 - val_loss: 0.2906 - val_fn: 142.0000 - val_fp: 137.0000 - val_tn: 1373.0000 - val_tp: 613.0000 - val_precision: 0.8173 - val_recall: 0.8119\n",
      "Epoch 31/4096\n",
      "24/24 - 0s - loss: 0.2451 - fn: 733.0000 - fp: 674.0000 - tn: 5360.0000 - tp: 2284.0000 - precision: 0.7721 - recall: 0.7570 - val_loss: 0.2490 - val_fn: 94.0000 - val_fp: 99.0000 - val_tn: 1411.0000 - val_tp: 661.0000 - val_precision: 0.8697 - val_recall: 0.8755\n",
      "Epoch 32/4096\n",
      "24/24 - 0s - loss: 0.2401 - fn: 602.0000 - fp: 681.0000 - tn: 5353.0000 - tp: 2415.0000 - precision: 0.7800 - recall: 0.8005 - val_loss: 0.2915 - val_fn: 145.0000 - val_fp: 126.0000 - val_tn: 1384.0000 - val_tp: 610.0000 - val_precision: 0.8288 - val_recall: 0.8079\n",
      "Epoch 33/4096\n",
      "24/24 - 0s - loss: 0.2296 - fn: 606.0000 - fp: 534.0000 - tn: 5500.0000 - tp: 2411.0000 - precision: 0.8187 - recall: 0.7991 - val_loss: 0.2708 - val_fn: 128.0000 - val_fp: 117.0000 - val_tn: 1393.0000 - val_tp: 627.0000 - val_precision: 0.8427 - val_recall: 0.8305\n",
      "Epoch 34/4096\n",
      "24/24 - 0s - loss: 0.2320 - fn: 600.0000 - fp: 607.0000 - tn: 5427.0000 - tp: 2417.0000 - precision: 0.7993 - recall: 0.8011 - val_loss: 0.3576 - val_fn: 200.0000 - val_fp: 192.0000 - val_tn: 1318.0000 - val_tp: 555.0000 - val_precision: 0.7430 - val_recall: 0.7351\n",
      "Epoch 35/4096\n",
      "24/24 - 0s - loss: 0.2293 - fn: 600.0000 - fp: 568.0000 - tn: 5466.0000 - tp: 2417.0000 - precision: 0.8097 - recall: 0.8011 - val_loss: 0.4250 - val_fn: 243.0000 - val_fp: 282.0000 - val_tn: 1228.0000 - val_tp: 512.0000 - val_precision: 0.6448 - val_recall: 0.6781\n",
      "Epoch 36/4096\n",
      "24/24 - 0s - loss: 0.2311 - fn: 668.0000 - fp: 748.0000 - tn: 5286.0000 - tp: 2349.0000 - precision: 0.7585 - recall: 0.7786 - val_loss: 0.3500 - val_fn: 189.0000 - val_fp: 176.0000 - val_tn: 1334.0000 - val_tp: 566.0000 - val_precision: 0.7628 - val_recall: 0.7497\n",
      "Epoch 37/4096\n",
      "24/24 - 0s - loss: 0.2242 - fn: 588.0000 - fp: 571.0000 - tn: 5463.0000 - tp: 2429.0000 - precision: 0.8097 - recall: 0.8051 - val_loss: 0.3654 - val_fn: 194.0000 - val_fp: 209.0000 - val_tn: 1301.0000 - val_tp: 561.0000 - val_precision: 0.7286 - val_recall: 0.7430\n",
      "Epoch 38/4096\n",
      "24/24 - 0s - loss: 0.2238 - fn: 609.0000 - fp: 645.0000 - tn: 5389.0000 - tp: 2408.0000 - precision: 0.7887 - recall: 0.7981 - val_loss: 0.2979 - val_fn: 149.0000 - val_fp: 127.0000 - val_tn: 1383.0000 - val_tp: 606.0000 - val_precision: 0.8267 - val_recall: 0.8026\n",
      "Epoch 39/4096\n",
      "24/24 - 0s - loss: 0.2153 - fn: 568.0000 - fp: 572.0000 - tn: 5462.0000 - tp: 2449.0000 - precision: 0.8107 - recall: 0.8117 - val_loss: 0.3213 - val_fn: 152.0000 - val_fp: 163.0000 - val_tn: 1347.0000 - val_tp: 603.0000 - val_precision: 0.7872 - val_recall: 0.7987\n",
      "Epoch 40/4096\n",
      "24/24 - 0s - loss: 0.2036 - fn: 541.0000 - fp: 529.0000 - tn: 5505.0000 - tp: 2476.0000 - precision: 0.8240 - recall: 0.8207 - val_loss: 0.2757 - val_fn: 141.0000 - val_fp: 100.0000 - val_tn: 1410.0000 - val_tp: 614.0000 - val_precision: 0.8599 - val_recall: 0.8132\n",
      "Epoch 41/4096\n",
      "24/24 - 0s - loss: 0.2137 - fn: 603.0000 - fp: 580.0000 - tn: 5454.0000 - tp: 2414.0000 - precision: 0.8063 - recall: 0.8001 - val_loss: 0.2809 - val_fn: 123.0000 - val_fp: 136.0000 - val_tn: 1374.0000 - val_tp: 632.0000 - val_precision: 0.8229 - val_recall: 0.8371\n",
      "Epoch 42/4096\n",
      "24/24 - 0s - loss: 0.2097 - fn: 595.0000 - fp: 559.0000 - tn: 5475.0000 - tp: 2422.0000 - precision: 0.8125 - recall: 0.8028 - val_loss: 0.2429 - val_fn: 97.0000 - val_fp: 96.0000 - val_tn: 1414.0000 - val_tp: 658.0000 - val_precision: 0.8727 - val_recall: 0.8715\n",
      "Epoch 43/4096\n",
      "24/24 - 0s - loss: 0.2100 - fn: 520.0000 - fp: 527.0000 - tn: 5507.0000 - tp: 2497.0000 - precision: 0.8257 - recall: 0.8276 - val_loss: 0.2379 - val_fn: 105.0000 - val_fp: 88.0000 - val_tn: 1422.0000 - val_tp: 650.0000 - val_precision: 0.8808 - val_recall: 0.8609\n",
      "Epoch 44/4096\n",
      "24/24 - 0s - loss: 0.1957 - fn: 511.0000 - fp: 450.0000 - tn: 5584.0000 - tp: 2506.0000 - precision: 0.8478 - recall: 0.8306 - val_loss: 0.3544 - val_fn: 181.0000 - val_fp: 202.0000 - val_tn: 1308.0000 - val_tp: 574.0000 - val_precision: 0.7397 - val_recall: 0.7603\n",
      "Epoch 45/4096\n",
      "24/24 - 0s - loss: 0.1996 - fn: 538.0000 - fp: 561.0000 - tn: 5473.0000 - tp: 2479.0000 - precision: 0.8155 - recall: 0.8217 - val_loss: 0.2763 - val_fn: 136.0000 - val_fp: 120.0000 - val_tn: 1390.0000 - val_tp: 619.0000 - val_precision: 0.8376 - val_recall: 0.8199\n",
      "Epoch 46/4096\n",
      "24/24 - 0s - loss: 0.1913 - fn: 589.0000 - fp: 569.0000 - tn: 5465.0000 - tp: 2428.0000 - precision: 0.8101 - recall: 0.8048 - val_loss: 0.2861 - val_fn: 129.0000 - val_fp: 128.0000 - val_tn: 1382.0000 - val_tp: 626.0000 - val_precision: 0.8302 - val_recall: 0.8291\n",
      "Epoch 47/4096\n",
      "24/24 - 0s - loss: 0.1868 - fn: 484.0000 - fp: 454.0000 - tn: 5580.0000 - tp: 2533.0000 - precision: 0.8480 - recall: 0.8396 - val_loss: 0.3031 - val_fn: 146.0000 - val_fp: 149.0000 - val_tn: 1361.0000 - val_tp: 609.0000 - val_precision: 0.8034 - val_recall: 0.8066\n",
      "Epoch 48/4096\n",
      "24/24 - 0s - loss: 0.1772 - fn: 459.0000 - fp: 447.0000 - tn: 5587.0000 - tp: 2558.0000 - precision: 0.8512 - recall: 0.8479 - val_loss: 0.2707 - val_fn: 127.0000 - val_fp: 111.0000 - val_tn: 1399.0000 - val_tp: 628.0000 - val_precision: 0.8498 - val_recall: 0.8318\n",
      "Epoch 49/4096\n",
      "24/24 - 0s - loss: 0.1917 - fn: 513.0000 - fp: 468.0000 - tn: 5566.0000 - tp: 2504.0000 - precision: 0.8425 - recall: 0.8300 - val_loss: 0.2875 - val_fn: 137.0000 - val_fp: 103.0000 - val_tn: 1407.0000 - val_tp: 618.0000 - val_precision: 0.8571 - val_recall: 0.8185\n",
      "Epoch 50/4096\n",
      "24/24 - 0s - loss: 0.1852 - fn: 437.0000 - fp: 436.0000 - tn: 5598.0000 - tp: 2580.0000 - precision: 0.8554 - recall: 0.8552 - val_loss: 0.1977 - val_fn: 65.0000 - val_fp: 61.0000 - val_tn: 1449.0000 - val_tp: 690.0000 - val_precision: 0.9188 - val_recall: 0.9139\n",
      "Epoch 51/4096\n",
      "24/24 - 0s - loss: 0.1786 - fn: 455.0000 - fp: 408.0000 - tn: 5626.0000 - tp: 2562.0000 - precision: 0.8626 - recall: 0.8492 - val_loss: 0.2253 - val_fn: 87.0000 - val_fp: 77.0000 - val_tn: 1433.0000 - val_tp: 668.0000 - val_precision: 0.8966 - val_recall: 0.8848\n",
      "Epoch 52/4096\n",
      "24/24 - 0s - loss: 0.1765 - fn: 444.0000 - fp: 433.0000 - tn: 5601.0000 - tp: 2573.0000 - precision: 0.8560 - recall: 0.8528 - val_loss: 0.2416 - val_fn: 100.0000 - val_fp: 76.0000 - val_tn: 1434.0000 - val_tp: 655.0000 - val_precision: 0.8960 - val_recall: 0.8675\n",
      "Epoch 53/4096\n",
      "24/24 - 0s - loss: 0.1838 - fn: 459.0000 - fp: 433.0000 - tn: 5601.0000 - tp: 2558.0000 - precision: 0.8552 - recall: 0.8479 - val_loss: 0.1907 - val_fn: 59.0000 - val_fp: 58.0000 - val_tn: 1452.0000 - val_tp: 696.0000 - val_precision: 0.9231 - val_recall: 0.9219\n",
      "Epoch 54/4096\n",
      "24/24 - 0s - loss: 0.1684 - fn: 386.0000 - fp: 355.0000 - tn: 5679.0000 - tp: 2631.0000 - precision: 0.8811 - recall: 0.8721 - val_loss: 0.1970 - val_fn: 54.0000 - val_fp: 51.0000 - val_tn: 1459.0000 - val_tp: 701.0000 - val_precision: 0.9322 - val_recall: 0.9285\n",
      "Epoch 55/4096\n",
      "24/24 - 0s - loss: 0.1495 - fn: 359.0000 - fp: 356.0000 - tn: 5678.0000 - tp: 2658.0000 - precision: 0.8819 - recall: 0.8810 - val_loss: 0.1987 - val_fn: 61.0000 - val_fp: 53.0000 - val_tn: 1457.0000 - val_tp: 694.0000 - val_precision: 0.9290 - val_recall: 0.9192\n",
      "Epoch 56/4096\n",
      "24/24 - 0s - loss: 0.1447 - fn: 357.0000 - fp: 335.0000 - tn: 5699.0000 - tp: 2660.0000 - precision: 0.8881 - recall: 0.8817 - val_loss: 0.1924 - val_fn: 55.0000 - val_fp: 53.0000 - val_tn: 1457.0000 - val_tp: 700.0000 - val_precision: 0.9296 - val_recall: 0.9272\n",
      "Epoch 57/4096\n",
      "24/24 - 0s - loss: 0.1570 - fn: 404.0000 - fp: 342.0000 - tn: 5692.0000 - tp: 2613.0000 - precision: 0.8843 - recall: 0.8661 - val_loss: 0.1630 - val_fn: 45.0000 - val_fp: 40.0000 - val_tn: 1470.0000 - val_tp: 710.0000 - val_precision: 0.9467 - val_recall: 0.9404\n",
      "Epoch 58/4096\n",
      "24/24 - 0s - loss: 0.1546 - fn: 351.0000 - fp: 334.0000 - tn: 5700.0000 - tp: 2666.0000 - precision: 0.8887 - recall: 0.8837 - val_loss: 0.1825 - val_fn: 54.0000 - val_fp: 40.0000 - val_tn: 1470.0000 - val_tp: 701.0000 - val_precision: 0.9460 - val_recall: 0.9285\n",
      "Epoch 59/4096\n",
      "24/24 - 0s - loss: 0.1436 - fn: 311.0000 - fp: 271.0000 - tn: 5763.0000 - tp: 2706.0000 - precision: 0.9090 - recall: 0.8969 - val_loss: 0.2604 - val_fn: 96.0000 - val_fp: 95.0000 - val_tn: 1415.0000 - val_tp: 659.0000 - val_precision: 0.8740 - val_recall: 0.8728\n",
      "Epoch 60/4096\n",
      "24/24 - 0s - loss: 0.1380 - fn: 321.0000 - fp: 303.0000 - tn: 5731.0000 - tp: 2696.0000 - precision: 0.8990 - recall: 0.8936 - val_loss: 0.1945 - val_fn: 60.0000 - val_fp: 39.0000 - val_tn: 1471.0000 - val_tp: 695.0000 - val_precision: 0.9469 - val_recall: 0.9205\n",
      "Epoch 61/4096\n",
      "24/24 - 0s - loss: 0.1362 - fn: 316.0000 - fp: 278.0000 - tn: 5756.0000 - tp: 2701.0000 - precision: 0.9067 - recall: 0.8953 - val_loss: 0.1261 - val_fn: 27.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 728.0000 - val_precision: 0.9720 - val_recall: 0.9642\n",
      "Epoch 62/4096\n",
      "24/24 - 0s - loss: 0.1547 - fn: 326.0000 - fp: 300.0000 - tn: 5734.0000 - tp: 2691.0000 - precision: 0.8997 - recall: 0.8919 - val_loss: 0.2278 - val_fn: 73.0000 - val_fp: 65.0000 - val_tn: 1445.0000 - val_tp: 682.0000 - val_precision: 0.9130 - val_recall: 0.9033\n",
      "Epoch 63/4096\n",
      "24/24 - 0s - loss: 0.1292 - fn: 264.0000 - fp: 260.0000 - tn: 5774.0000 - tp: 2753.0000 - precision: 0.9137 - recall: 0.9125 - val_loss: 0.1408 - val_fn: 33.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 722.0000 - val_precision: 0.9717 - val_recall: 0.9563\n",
      "Epoch 64/4096\n",
      "24/24 - 0s - loss: 0.1223 - fn: 249.0000 - fp: 227.0000 - tn: 5807.0000 - tp: 2768.0000 - precision: 0.9242 - recall: 0.9175 - val_loss: 0.1516 - val_fn: 42.0000 - val_fp: 31.0000 - val_tn: 1479.0000 - val_tp: 713.0000 - val_precision: 0.9583 - val_recall: 0.9444\n",
      "Epoch 65/4096\n",
      "24/24 - 0s - loss: 0.1170 - fn: 239.0000 - fp: 225.0000 - tn: 5809.0000 - tp: 2778.0000 - precision: 0.9251 - recall: 0.9208 - val_loss: 0.1817 - val_fn: 49.0000 - val_fp: 42.0000 - val_tn: 1468.0000 - val_tp: 706.0000 - val_precision: 0.9439 - val_recall: 0.9351\n",
      "Epoch 66/4096\n",
      "24/24 - 0s - loss: 0.1196 - fn: 279.0000 - fp: 272.0000 - tn: 5762.0000 - tp: 2738.0000 - precision: 0.9096 - recall: 0.9075 - val_loss: 0.1486 - val_fn: 33.0000 - val_fp: 27.0000 - val_tn: 1483.0000 - val_tp: 722.0000 - val_precision: 0.9640 - val_recall: 0.9563\n",
      "Epoch 67/4096\n",
      "24/24 - 0s - loss: 0.1248 - fn: 227.0000 - fp: 201.0000 - tn: 5833.0000 - tp: 2790.0000 - precision: 0.9328 - recall: 0.9248 - val_loss: 0.2529 - val_fn: 87.0000 - val_fp: 83.0000 - val_tn: 1427.0000 - val_tp: 668.0000 - val_precision: 0.8895 - val_recall: 0.8848\n",
      "Epoch 68/4096\n",
      "24/24 - 0s - loss: 0.1307 - fn: 301.0000 - fp: 280.0000 - tn: 5754.0000 - tp: 2716.0000 - precision: 0.9065 - recall: 0.9002 - val_loss: 0.1406 - val_fn: 30.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 725.0000 - val_precision: 0.9705 - val_recall: 0.9603\n",
      "Epoch 69/4096\n",
      "24/24 - 0s - loss: 0.1136 - fn: 197.0000 - fp: 177.0000 - tn: 5857.0000 - tp: 2820.0000 - precision: 0.9409 - recall: 0.9347 - val_loss: 0.1875 - val_fn: 52.0000 - val_fp: 42.0000 - val_tn: 1468.0000 - val_tp: 703.0000 - val_precision: 0.9436 - val_recall: 0.9311\n",
      "Epoch 70/4096\n",
      "24/24 - 0s - loss: 0.1233 - fn: 330.0000 - fp: 285.0000 - tn: 5749.0000 - tp: 2687.0000 - precision: 0.9041 - recall: 0.8906 - val_loss: 0.1255 - val_fn: 23.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 732.0000 - val_precision: 0.9721 - val_recall: 0.9695\n",
      "Epoch 71/4096\n",
      "24/24 - 0s - loss: 0.1217 - fn: 238.0000 - fp: 230.0000 - tn: 5804.0000 - tp: 2779.0000 - precision: 0.9236 - recall: 0.9211 - val_loss: 0.1389 - val_fn: 26.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 729.0000 - val_precision: 0.9720 - val_recall: 0.9656\n",
      "Epoch 72/4096\n",
      "24/24 - 0s - loss: 0.1089 - fn: 242.0000 - fp: 235.0000 - tn: 5799.0000 - tp: 2775.0000 - precision: 0.9219 - recall: 0.9198 - val_loss: 0.1503 - val_fn: 34.0000 - val_fp: 26.0000 - val_tn: 1484.0000 - val_tp: 721.0000 - val_precision: 0.9652 - val_recall: 0.9550\n",
      "Epoch 73/4096\n",
      "24/24 - 0s - loss: 0.1026 - fn: 208.0000 - fp: 181.0000 - tn: 5853.0000 - tp: 2809.0000 - precision: 0.9395 - recall: 0.9311 - val_loss: 0.1229 - val_fn: 22.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 733.0000 - val_precision: 0.9734 - val_recall: 0.9709\n",
      "Epoch 74/4096\n",
      "24/24 - 0s - loss: 0.0986 - fn: 165.0000 - fp: 164.0000 - tn: 5870.0000 - tp: 2852.0000 - precision: 0.9456 - recall: 0.9453 - val_loss: 0.1472 - val_fn: 31.0000 - val_fp: 25.0000 - val_tn: 1485.0000 - val_tp: 724.0000 - val_precision: 0.9666 - val_recall: 0.9589\n",
      "Epoch 75/4096\n",
      "24/24 - 0s - loss: 0.1072 - fn: 211.0000 - fp: 192.0000 - tn: 5842.0000 - tp: 2806.0000 - precision: 0.9360 - recall: 0.9301 - val_loss: 0.1827 - val_fn: 44.0000 - val_fp: 38.0000 - val_tn: 1472.0000 - val_tp: 711.0000 - val_precision: 0.9493 - val_recall: 0.9417\n",
      "Epoch 76/4096\n",
      "24/24 - 0s - loss: 0.0952 - fn: 189.0000 - fp: 179.0000 - tn: 5855.0000 - tp: 2828.0000 - precision: 0.9405 - recall: 0.9374 - val_loss: 0.1239 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 77/4096\n",
      "24/24 - 0s - loss: 0.1019 - fn: 186.0000 - fp: 179.0000 - tn: 5855.0000 - tp: 2831.0000 - precision: 0.9405 - recall: 0.9383 - val_loss: 0.1431 - val_fn: 30.0000 - val_fp: 26.0000 - val_tn: 1484.0000 - val_tp: 725.0000 - val_precision: 0.9654 - val_recall: 0.9603\n",
      "Epoch 78/4096\n",
      "24/24 - 0s - loss: 0.1078 - fn: 188.0000 - fp: 171.0000 - tn: 5863.0000 - tp: 2829.0000 - precision: 0.9430 - recall: 0.9377 - val_loss: 0.1184 - val_fn: 21.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 734.0000 - val_precision: 0.9761 - val_recall: 0.9722\n",
      "Epoch 79/4096\n",
      "24/24 - 0s - loss: 0.0869 - fn: 194.0000 - fp: 176.0000 - tn: 5858.0000 - tp: 2823.0000 - precision: 0.9413 - recall: 0.9357 - val_loss: 0.1834 - val_fn: 46.0000 - val_fp: 45.0000 - val_tn: 1465.0000 - val_tp: 709.0000 - val_precision: 0.9403 - val_recall: 0.9391\n",
      "Epoch 80/4096\n",
      "24/24 - 0s - loss: 0.0826 - fn: 153.0000 - fp: 146.0000 - tn: 5888.0000 - tp: 2864.0000 - precision: 0.9515 - recall: 0.9493 - val_loss: 0.1413 - val_fn: 30.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 725.0000 - val_precision: 0.9680 - val_recall: 0.9603\n",
      "Epoch 81/4096\n",
      "24/24 - 0s - loss: 0.0857 - fn: 172.0000 - fp: 153.0000 - tn: 5881.0000 - tp: 2845.0000 - precision: 0.9490 - recall: 0.9430 - val_loss: 0.1147 - val_fn: 18.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 737.0000 - val_precision: 0.9801 - val_recall: 0.9762\n",
      "Epoch 82/4096\n",
      "24/24 - 0s - loss: 0.0975 - fn: 186.0000 - fp: 176.0000 - tn: 5858.0000 - tp: 2831.0000 - precision: 0.9415 - recall: 0.9383 - val_loss: 0.1073 - val_fn: 19.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 736.0000 - val_precision: 0.9800 - val_recall: 0.9748\n",
      "Epoch 83/4096\n",
      "24/24 - 0s - loss: 0.0858 - fn: 146.0000 - fp: 149.0000 - tn: 5885.0000 - tp: 2871.0000 - precision: 0.9507 - recall: 0.9516 - val_loss: 0.1373 - val_fn: 27.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 728.0000 - val_precision: 0.9694 - val_recall: 0.9642\n",
      "Epoch 84/4096\n",
      "24/24 - 0s - loss: 0.0859 - fn: 124.0000 - fp: 103.0000 - tn: 5931.0000 - tp: 2893.0000 - precision: 0.9656 - recall: 0.9589 - val_loss: 0.1376 - val_fn: 32.0000 - val_fp: 27.0000 - val_tn: 1483.0000 - val_tp: 723.0000 - val_precision: 0.9640 - val_recall: 0.9576\n",
      "Epoch 85/4096\n",
      "24/24 - 0s - loss: 0.0880 - fn: 161.0000 - fp: 135.0000 - tn: 5899.0000 - tp: 2856.0000 - precision: 0.9549 - recall: 0.9466 - val_loss: 0.2036 - val_fn: 54.0000 - val_fp: 50.0000 - val_tn: 1460.0000 - val_tp: 701.0000 - val_precision: 0.9334 - val_recall: 0.9285\n",
      "Epoch 86/4096\n",
      "24/24 - 0s - loss: 0.0855 - fn: 155.0000 - fp: 149.0000 - tn: 5885.0000 - tp: 2862.0000 - precision: 0.9505 - recall: 0.9486 - val_loss: 0.1319 - val_fn: 27.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 728.0000 - val_precision: 0.9681 - val_recall: 0.9642\n",
      "Epoch 87/4096\n",
      "24/24 - 0s - loss: 0.0717 - fn: 122.0000 - fp: 113.0000 - tn: 5921.0000 - tp: 2895.0000 - precision: 0.9624 - recall: 0.9596 - val_loss: 0.1312 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 1485.0000 - val_tp: 729.0000 - val_precision: 0.9668 - val_recall: 0.9656\n",
      "Epoch 88/4096\n",
      "24/24 - 0s - loss: 0.0702 - fn: 128.0000 - fp: 127.0000 - tn: 5907.0000 - tp: 2889.0000 - precision: 0.9579 - recall: 0.9576 - val_loss: 0.1170 - val_fn: 22.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 733.0000 - val_precision: 0.9734 - val_recall: 0.9709\n",
      "Epoch 89/4096\n",
      "24/24 - 0s - loss: 0.0735 - fn: 127.0000 - fp: 127.0000 - tn: 5907.0000 - tp: 2890.0000 - precision: 0.9579 - recall: 0.9579 - val_loss: 0.1100 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 90/4096\n",
      "24/24 - 0s - loss: 0.0651 - fn: 121.0000 - fp: 115.0000 - tn: 5919.0000 - tp: 2896.0000 - precision: 0.9618 - recall: 0.9599 - val_loss: 0.1235 - val_fn: 22.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 733.0000 - val_precision: 0.9734 - val_recall: 0.9709\n",
      "Epoch 91/4096\n",
      "24/24 - 0s - loss: 0.0618 - fn: 135.0000 - fp: 130.0000 - tn: 5904.0000 - tp: 2882.0000 - precision: 0.9568 - recall: 0.9553 - val_loss: 0.1189 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 92/4096\n",
      "24/24 - 0s - loss: 0.0750 - fn: 120.0000 - fp: 122.0000 - tn: 5912.0000 - tp: 2897.0000 - precision: 0.9596 - recall: 0.9602 - val_loss: 0.1232 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 93/4096\n",
      "24/24 - 0s - loss: 0.0621 - fn: 109.0000 - fp: 104.0000 - tn: 5930.0000 - tp: 2908.0000 - precision: 0.9655 - recall: 0.9639 - val_loss: 0.1189 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 94/4096\n",
      "24/24 - 0s - loss: 0.0678 - fn: 128.0000 - fp: 119.0000 - tn: 5915.0000 - tp: 2889.0000 - precision: 0.9604 - recall: 0.9576 - val_loss: 0.1273 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 95/4096\n",
      "24/24 - 0s - loss: 0.0645 - fn: 115.0000 - fp: 105.0000 - tn: 5929.0000 - tp: 2902.0000 - precision: 0.9651 - recall: 0.9619 - val_loss: 0.1295 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 1482.0000 - val_tp: 727.0000 - val_precision: 0.9629 - val_recall: 0.9629\n",
      "Epoch 96/4096\n",
      "24/24 - 0s - loss: 0.0694 - fn: 142.0000 - fp: 145.0000 - tn: 5889.0000 - tp: 2875.0000 - precision: 0.9520 - recall: 0.9529 - val_loss: 0.1212 - val_fn: 21.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 734.0000 - val_precision: 0.9709 - val_recall: 0.9722\n",
      "Epoch 97/4096\n",
      "24/24 - 0s - loss: 0.0701 - fn: 124.0000 - fp: 118.0000 - tn: 5916.0000 - tp: 2893.0000 - precision: 0.9608 - recall: 0.9589 - val_loss: 0.1191 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 98/4096\n",
      "24/24 - 0s - loss: 0.0711 - fn: 129.0000 - fp: 121.0000 - tn: 5913.0000 - tp: 2888.0000 - precision: 0.9598 - recall: 0.9572 - val_loss: 0.1224 - val_fn: 20.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 735.0000 - val_precision: 0.9709 - val_recall: 0.9735\n",
      "Epoch 99/4096\n",
      "24/24 - 0s - loss: 0.0549 - fn: 106.0000 - fp: 92.0000 - tn: 5942.0000 - tp: 2911.0000 - precision: 0.9694 - recall: 0.9649 - val_loss: 0.1180 - val_fn: 20.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 735.0000 - val_precision: 0.9722 - val_recall: 0.9735\n",
      "Epoch 100/4096\n",
      "24/24 - 0s - loss: 0.0557 - fn: 90.0000 - fp: 88.0000 - tn: 5946.0000 - tp: 2927.0000 - precision: 0.9708 - recall: 0.9702 - val_loss: 0.1314 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 730.0000 - val_precision: 0.9682 - val_recall: 0.9669\n",
      "Epoch 101/4096\n",
      "24/24 - 0s - loss: 0.0530 - fn: 120.0000 - fp: 108.0000 - tn: 5926.0000 - tp: 2897.0000 - precision: 0.9641 - recall: 0.9602 - val_loss: 0.1257 - val_fn: 23.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 732.0000 - val_precision: 0.9734 - val_recall: 0.9695\n",
      "Epoch 102/4096\n",
      "24/24 - 0s - loss: 0.0627 - fn: 110.0000 - fp: 106.0000 - tn: 5928.0000 - tp: 2907.0000 - precision: 0.9648 - recall: 0.9635 - val_loss: 0.1284 - val_fn: 23.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 732.0000 - val_precision: 0.9721 - val_recall: 0.9695\n",
      "Epoch 103/4096\n",
      "24/24 - 0s - loss: 0.0656 - fn: 94.0000 - fp: 86.0000 - tn: 5948.0000 - tp: 2923.0000 - precision: 0.9714 - recall: 0.9688 - val_loss: 0.1311 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 732.0000 - val_precision: 0.9708 - val_recall: 0.9695\n",
      "Epoch 104/4096\n",
      "24/24 - 0s - loss: 0.0580 - fn: 123.0000 - fp: 119.0000 - tn: 5915.0000 - tp: 2894.0000 - precision: 0.9605 - recall: 0.9592 - val_loss: 0.1171 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 105/4096\n",
      "24/24 - 0s - loss: 0.0608 - fn: 130.0000 - fp: 124.0000 - tn: 5910.0000 - tp: 2887.0000 - precision: 0.9588 - recall: 0.9569 - val_loss: 0.1140 - val_fn: 16.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 739.0000 - val_precision: 0.9814 - val_recall: 0.9788\n",
      "Epoch 106/4096\n",
      "24/24 - 0s - loss: 0.0561 - fn: 116.0000 - fp: 119.0000 - tn: 5915.0000 - tp: 2901.0000 - precision: 0.9606 - recall: 0.9616 - val_loss: 0.1345 - val_fn: 26.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 729.0000 - val_precision: 0.9694 - val_recall: 0.9656\n",
      "Epoch 107/4096\n",
      "24/24 - 0s - loss: 0.0509 - fn: 118.0000 - fp: 105.0000 - tn: 5929.0000 - tp: 2899.0000 - precision: 0.9650 - recall: 0.9609 - val_loss: 0.1369 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 1484.0000 - val_tp: 728.0000 - val_precision: 0.9655 - val_recall: 0.9642\n",
      "Epoch 108/4096\n",
      "24/24 - 0s - loss: 0.0604 - fn: 96.0000 - fp: 89.0000 - tn: 5945.0000 - tp: 2921.0000 - precision: 0.9704 - recall: 0.9682 - val_loss: 0.1194 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 109/4096\n",
      "24/24 - 0s - loss: 0.0511 - fn: 94.0000 - fp: 88.0000 - tn: 5946.0000 - tp: 2923.0000 - precision: 0.9708 - recall: 0.9688 - val_loss: 0.1211 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 110/4096\n",
      "24/24 - 0s - loss: 0.0508 - fn: 94.0000 - fp: 87.0000 - tn: 5947.0000 - tp: 2923.0000 - precision: 0.9711 - recall: 0.9688 - val_loss: 0.1240 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 111/4096\n",
      "24/24 - 0s - loss: 0.0483 - fn: 96.0000 - fp: 96.0000 - tn: 5938.0000 - tp: 2921.0000 - precision: 0.9682 - recall: 0.9682 - val_loss: 0.1309 - val_fn: 23.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 732.0000 - val_precision: 0.9734 - val_recall: 0.9695\n",
      "Epoch 112/4096\n",
      "24/24 - 0s - loss: 0.0556 - fn: 110.0000 - fp: 98.0000 - tn: 5936.0000 - tp: 2907.0000 - precision: 0.9674 - recall: 0.9635 - val_loss: 0.1400 - val_fn: 29.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 726.0000 - val_precision: 0.9680 - val_recall: 0.9616\n",
      "Epoch 113/4096\n",
      "24/24 - 0s - loss: 0.0508 - fn: 98.0000 - fp: 90.0000 - tn: 5944.0000 - tp: 2919.0000 - precision: 0.9701 - recall: 0.9675 - val_loss: 0.1244 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 114/4096\n",
      "24/24 - 0s - loss: 0.0510 - fn: 93.0000 - fp: 91.0000 - tn: 5943.0000 - tp: 2924.0000 - precision: 0.9698 - recall: 0.9692 - val_loss: 0.1302 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 115/4096\n",
      "24/24 - 0s - loss: 0.0428 - fn: 85.0000 - fp: 83.0000 - tn: 5951.0000 - tp: 2932.0000 - precision: 0.9725 - recall: 0.9718 - val_loss: 0.1421 - val_fn: 30.0000 - val_fp: 27.0000 - val_tn: 1483.0000 - val_tp: 725.0000 - val_precision: 0.9641 - val_recall: 0.9603\n",
      "Epoch 116/4096\n",
      "24/24 - 0s - loss: 0.0499 - fn: 93.0000 - fp: 87.0000 - tn: 5947.0000 - tp: 2924.0000 - precision: 0.9711 - recall: 0.9692 - val_loss: 0.1231 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 117/4096\n",
      "24/24 - 0s - loss: 0.0566 - fn: 99.0000 - fp: 88.0000 - tn: 5946.0000 - tp: 2918.0000 - precision: 0.9707 - recall: 0.9672 - val_loss: 0.1356 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 731.0000 - val_precision: 0.9695 - val_recall: 0.9682\n",
      "Epoch 118/4096\n",
      "24/24 - 0s - loss: 0.0519 - fn: 112.0000 - fp: 103.0000 - tn: 5931.0000 - tp: 2905.0000 - precision: 0.9658 - recall: 0.9629 - val_loss: 0.1637 - val_fn: 32.0000 - val_fp: 34.0000 - val_tn: 1476.0000 - val_tp: 723.0000 - val_precision: 0.9551 - val_recall: 0.9576\n",
      "Epoch 119/4096\n",
      "24/24 - 0s - loss: 0.0461 - fn: 99.0000 - fp: 93.0000 - tn: 5941.0000 - tp: 2918.0000 - precision: 0.9691 - recall: 0.9672 - val_loss: 0.1242 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 120/4096\n",
      "24/24 - 0s - loss: 0.0402 - fn: 75.0000 - fp: 79.0000 - tn: 5955.0000 - tp: 2942.0000 - precision: 0.9738 - recall: 0.9751 - val_loss: 0.1245 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 121/4096\n",
      "24/24 - 0s - loss: 0.0504 - fn: 90.0000 - fp: 83.0000 - tn: 5951.0000 - tp: 2927.0000 - precision: 0.9724 - recall: 0.9702 - val_loss: 0.1229 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 122/4096\n",
      "24/24 - 0s - loss: 0.0583 - fn: 106.0000 - fp: 107.0000 - tn: 5927.0000 - tp: 2911.0000 - precision: 0.9645 - recall: 0.9649 - val_loss: 0.1226 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 123/4096\n",
      "24/24 - 0s - loss: 0.0558 - fn: 84.0000 - fp: 83.0000 - tn: 5951.0000 - tp: 2933.0000 - precision: 0.9725 - recall: 0.9722 - val_loss: 0.1322 - val_fn: 21.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 734.0000 - val_precision: 0.9735 - val_recall: 0.9722\n",
      "Epoch 124/4096\n",
      "24/24 - 0s - loss: 0.0583 - fn: 135.0000 - fp: 126.0000 - tn: 5908.0000 - tp: 2882.0000 - precision: 0.9581 - recall: 0.9553 - val_loss: 0.1433 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 1484.0000 - val_tp: 727.0000 - val_precision: 0.9655 - val_recall: 0.9629\n",
      "Epoch 125/4096\n",
      "24/24 - 0s - loss: 0.0489 - fn: 101.0000 - fp: 94.0000 - tn: 5940.0000 - tp: 2916.0000 - precision: 0.9688 - recall: 0.9665 - val_loss: 0.1263 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 126/4096\n",
      "24/24 - 0s - loss: 0.0553 - fn: 98.0000 - fp: 93.0000 - tn: 5941.0000 - tp: 2919.0000 - precision: 0.9691 - recall: 0.9675 - val_loss: 0.1377 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 1484.0000 - val_tp: 728.0000 - val_precision: 0.9655 - val_recall: 0.9642\n",
      "Epoch 127/4096\n",
      "24/24 - 0s - loss: 0.0414 - fn: 86.0000 - fp: 83.0000 - tn: 5951.0000 - tp: 2931.0000 - precision: 0.9725 - recall: 0.9715 - val_loss: 0.1543 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 1481.0000 - val_tp: 724.0000 - val_precision: 0.9615 - val_recall: 0.9589\n",
      "Epoch 128/4096\n",
      "24/24 - 0s - loss: 0.0361 - fn: 67.0000 - fp: 66.0000 - tn: 5968.0000 - tp: 2950.0000 - precision: 0.9781 - recall: 0.9778 - val_loss: 0.1283 - val_fn: 18.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 737.0000 - val_precision: 0.9801 - val_recall: 0.9762\n",
      "Epoch 129/4096\n",
      "24/24 - 0s - loss: 0.0366 - fn: 81.0000 - fp: 85.0000 - tn: 5949.0000 - tp: 2936.0000 - precision: 0.9719 - recall: 0.9732 - val_loss: 0.1298 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 130/4096\n",
      "24/24 - 0s - loss: 0.0356 - fn: 75.0000 - fp: 71.0000 - tn: 5963.0000 - tp: 2942.0000 - precision: 0.9764 - recall: 0.9751 - val_loss: 0.1465 - val_fn: 27.0000 - val_fp: 29.0000 - val_tn: 1481.0000 - val_tp: 728.0000 - val_precision: 0.9617 - val_recall: 0.9642\n",
      "Epoch 131/4096\n",
      "24/24 - 0s - loss: 0.0400 - fn: 87.0000 - fp: 85.0000 - tn: 5949.0000 - tp: 2930.0000 - precision: 0.9718 - recall: 0.9712 - val_loss: 0.1249 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 132/4096\n",
      "24/24 - 0s - loss: 0.0412 - fn: 77.0000 - fp: 80.0000 - tn: 5954.0000 - tp: 2940.0000 - precision: 0.9735 - recall: 0.9745 - val_loss: 0.1405 - val_fn: 21.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 734.0000 - val_precision: 0.9735 - val_recall: 0.9722\n",
      "Epoch 133/4096\n",
      "24/24 - 0s - loss: 0.0372 - fn: 87.0000 - fp: 89.0000 - tn: 5945.0000 - tp: 2930.0000 - precision: 0.9705 - recall: 0.9712 - val_loss: 0.1391 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 134/4096\n",
      "24/24 - 0s - loss: 0.0366 - fn: 72.0000 - fp: 80.0000 - tn: 5954.0000 - tp: 2945.0000 - precision: 0.9736 - recall: 0.9761 - val_loss: 0.1427 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 135/4096\n",
      "24/24 - 0s - loss: 0.0393 - fn: 81.0000 - fp: 78.0000 - tn: 5956.0000 - tp: 2936.0000 - precision: 0.9741 - recall: 0.9732 - val_loss: 0.1300 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 136/4096\n",
      "24/24 - 0s - loss: 0.0381 - fn: 77.0000 - fp: 76.0000 - tn: 5958.0000 - tp: 2940.0000 - precision: 0.9748 - recall: 0.9745 - val_loss: 0.1293 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 137/4096\n",
      "24/24 - 0s - loss: 0.0369 - fn: 75.0000 - fp: 74.0000 - tn: 5960.0000 - tp: 2942.0000 - precision: 0.9755 - recall: 0.9751 - val_loss: 0.1290 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 138/4096\n",
      "24/24 - 0s - loss: 0.0387 - fn: 85.0000 - fp: 73.0000 - tn: 5961.0000 - tp: 2932.0000 - precision: 0.9757 - recall: 0.9718 - val_loss: 0.1305 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 139/4096\n",
      "24/24 - 0s - loss: 0.0409 - fn: 66.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2951.0000 - precision: 0.9794 - recall: 0.9781 - val_loss: 0.1305 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 140/4096\n",
      "24/24 - 0s - loss: 0.0366 - fn: 65.0000 - fp: 65.0000 - tn: 5969.0000 - tp: 2952.0000 - precision: 0.9785 - recall: 0.9785 - val_loss: 0.1308 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 141/4096\n",
      "24/24 - 0s - loss: 0.0360 - fn: 66.0000 - fp: 70.0000 - tn: 5964.0000 - tp: 2951.0000 - precision: 0.9768 - recall: 0.9781 - val_loss: 0.1367 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 142/4096\n",
      "24/24 - 0s - loss: 0.0354 - fn: 66.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2951.0000 - precision: 0.9801 - recall: 0.9781 - val_loss: 0.1365 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 143/4096\n",
      "24/24 - 0s - loss: 0.0449 - fn: 73.0000 - fp: 73.0000 - tn: 5961.0000 - tp: 2944.0000 - precision: 0.9758 - recall: 0.9758 - val_loss: 0.1343 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 144/4096\n",
      "24/24 - 0s - loss: 0.0441 - fn: 79.0000 - fp: 79.0000 - tn: 5955.0000 - tp: 2938.0000 - precision: 0.9738 - recall: 0.9738 - val_loss: 0.1318 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 145/4096\n",
      "24/24 - 0s - loss: 0.0364 - fn: 70.0000 - fp: 76.0000 - tn: 5958.0000 - tp: 2947.0000 - precision: 0.9749 - recall: 0.9768 - val_loss: 0.1335 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 146/4096\n",
      "24/24 - 0s - loss: 0.0395 - fn: 70.0000 - fp: 58.0000 - tn: 5976.0000 - tp: 2947.0000 - precision: 0.9807 - recall: 0.9768 - val_loss: 0.1353 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 147/4096\n",
      "24/24 - 0s - loss: 0.0468 - fn: 83.0000 - fp: 78.0000 - tn: 5956.0000 - tp: 2934.0000 - precision: 0.9741 - recall: 0.9725 - val_loss: 0.1421 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 148/4096\n",
      "24/24 - 0s - loss: 0.0400 - fn: 72.0000 - fp: 68.0000 - tn: 5966.0000 - tp: 2945.0000 - precision: 0.9774 - recall: 0.9761 - val_loss: 0.1401 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 149/4096\n",
      "24/24 - 0s - loss: 0.0410 - fn: 95.0000 - fp: 90.0000 - tn: 5944.0000 - tp: 2922.0000 - precision: 0.9701 - recall: 0.9685 - val_loss: 0.1531 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 1482.0000 - val_tp: 725.0000 - val_precision: 0.9628 - val_recall: 0.9603\n",
      "Epoch 150/4096\n",
      "24/24 - 0s - loss: 0.0439 - fn: 95.0000 - fp: 97.0000 - tn: 5937.0000 - tp: 2922.0000 - precision: 0.9679 - recall: 0.9685 - val_loss: 0.1356 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 151/4096\n",
      "24/24 - 0s - loss: 0.0382 - fn: 68.0000 - fp: 70.0000 - tn: 5964.0000 - tp: 2949.0000 - precision: 0.9768 - recall: 0.9775 - val_loss: 0.1324 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 152/4096\n",
      "24/24 - 0s - loss: 0.0334 - fn: 71.0000 - fp: 70.0000 - tn: 5964.0000 - tp: 2946.0000 - precision: 0.9768 - recall: 0.9765 - val_loss: 0.1390 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 153/4096\n",
      "24/24 - 0s - loss: 0.0387 - fn: 81.0000 - fp: 78.0000 - tn: 5956.0000 - tp: 2936.0000 - precision: 0.9741 - recall: 0.9732 - val_loss: 0.1370 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 154/4096\n",
      "24/24 - 0s - loss: 0.0388 - fn: 77.0000 - fp: 81.0000 - tn: 5953.0000 - tp: 2940.0000 - precision: 0.9732 - recall: 0.9745 - val_loss: 0.1367 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 155/4096\n",
      "24/24 - 0s - loss: 0.0355 - fn: 75.0000 - fp: 71.0000 - tn: 5963.0000 - tp: 2942.0000 - precision: 0.9764 - recall: 0.9751 - val_loss: 0.1361 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 156/4096\n",
      "24/24 - 0s - loss: 0.0335 - fn: 67.0000 - fp: 64.0000 - tn: 5970.0000 - tp: 2950.0000 - precision: 0.9788 - recall: 0.9778 - val_loss: 0.1436 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 157/4096\n",
      "24/24 - 0s - loss: 0.0306 - fn: 60.0000 - fp: 59.0000 - tn: 5975.0000 - tp: 2957.0000 - precision: 0.9804 - recall: 0.9801 - val_loss: 0.1355 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 158/4096\n",
      "24/24 - 0s - loss: 0.0278 - fn: 61.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2956.0000 - precision: 0.9830 - recall: 0.9798 - val_loss: 0.1340 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 159/4096\n",
      "24/24 - 0s - loss: 0.0358 - fn: 69.0000 - fp: 58.0000 - tn: 5976.0000 - tp: 2948.0000 - precision: 0.9807 - recall: 0.9771 - val_loss: 0.1416 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 160/4096\n",
      "24/24 - 0s - loss: 0.0361 - fn: 67.0000 - fp: 66.0000 - tn: 5968.0000 - tp: 2950.0000 - precision: 0.9781 - recall: 0.9778 - val_loss: 0.1403 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 161/4096\n",
      "24/24 - 0s - loss: 0.0348 - fn: 61.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2956.0000 - precision: 0.9821 - recall: 0.9798 - val_loss: 0.1384 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 162/4096\n",
      "24/24 - 0s - loss: 0.0287 - fn: 59.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2958.0000 - precision: 0.9811 - recall: 0.9804 - val_loss: 0.1589 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 1484.0000 - val_tp: 729.0000 - val_precision: 0.9656 - val_recall: 0.9656\n",
      "Epoch 163/4096\n",
      "24/24 - 0s - loss: 0.0362 - fn: 69.0000 - fp: 65.0000 - tn: 5969.0000 - tp: 2948.0000 - precision: 0.9784 - recall: 0.9771 - val_loss: 0.1440 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 164/4096\n",
      "24/24 - 0s - loss: 0.0350 - fn: 80.0000 - fp: 66.0000 - tn: 5968.0000 - tp: 2937.0000 - precision: 0.9780 - recall: 0.9735 - val_loss: 0.1383 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 165/4096\n",
      "24/24 - 0s - loss: 0.0372 - fn: 63.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2954.0000 - precision: 0.9798 - recall: 0.9791 - val_loss: 0.1410 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 166/4096\n",
      "24/24 - 0s - loss: 0.0334 - fn: 71.0000 - fp: 65.0000 - tn: 5969.0000 - tp: 2946.0000 - precision: 0.9784 - recall: 0.9765 - val_loss: 0.1491 - val_fn: 20.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 735.0000 - val_precision: 0.9774 - val_recall: 0.9735\n",
      "Epoch 167/4096\n",
      "24/24 - 0s - loss: 0.0322 - fn: 59.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2958.0000 - precision: 0.9811 - recall: 0.9804 - val_loss: 0.1519 - val_fn: 21.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 734.0000 - val_precision: 0.9735 - val_recall: 0.9722\n",
      "Epoch 168/4096\n",
      "24/24 - 0s - loss: 0.0385 - fn: 87.0000 - fp: 83.0000 - tn: 5951.0000 - tp: 2930.0000 - precision: 0.9725 - recall: 0.9712 - val_loss: 0.1484 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 169/4096\n",
      "24/24 - 0s - loss: 0.0330 - fn: 73.0000 - fp: 68.0000 - tn: 5966.0000 - tp: 2944.0000 - precision: 0.9774 - recall: 0.9758 - val_loss: 0.1387 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 170/4096\n",
      "24/24 - 0s - loss: 0.0309 - fn: 69.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2948.0000 - precision: 0.9794 - recall: 0.9771 - val_loss: 0.1461 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 171/4096\n",
      "24/24 - 0s - loss: 0.0344 - fn: 59.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2958.0000 - precision: 0.9811 - recall: 0.9804 - val_loss: 0.1400 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 172/4096\n",
      "24/24 - 0s - loss: 0.0319 - fn: 70.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2947.0000 - precision: 0.9800 - recall: 0.9768 - val_loss: 0.1376 - val_fn: 15.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 740.0000 - val_precision: 0.9827 - val_recall: 0.9801\n",
      "Epoch 173/4096\n",
      "24/24 - 0s - loss: 0.0418 - fn: 60.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2957.0000 - precision: 0.9824 - recall: 0.9801 - val_loss: 0.1464 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 174/4096\n",
      "24/24 - 0s - loss: 0.0280 - fn: 65.0000 - fp: 63.0000 - tn: 5971.0000 - tp: 2952.0000 - precision: 0.9791 - recall: 0.9785 - val_loss: 0.1543 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 175/4096\n",
      "24/24 - 0s - loss: 0.0267 - fn: 66.0000 - fp: 66.0000 - tn: 5968.0000 - tp: 2951.0000 - precision: 0.9781 - recall: 0.9781 - val_loss: 0.1423 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 176/4096\n",
      "24/24 - 0s - loss: 0.0282 - fn: 62.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2955.0000 - precision: 0.9801 - recall: 0.9794 - val_loss: 0.1518 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 177/4096\n",
      "24/24 - 0s - loss: 0.0292 - fn: 70.0000 - fp: 70.0000 - tn: 5964.0000 - tp: 2947.0000 - precision: 0.9768 - recall: 0.9768 - val_loss: 0.1435 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 178/4096\n",
      "24/24 - 0s - loss: 0.0289 - fn: 71.0000 - fp: 73.0000 - tn: 5961.0000 - tp: 2946.0000 - precision: 0.9758 - recall: 0.9765 - val_loss: 0.1401 - val_fn: 12.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 743.0000 - val_precision: 0.9828 - val_recall: 0.9841\n",
      "Epoch 179/4096\n",
      "24/24 - 0s - loss: 0.0301 - fn: 61.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2956.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.1469 - val_fn: 16.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 739.0000 - val_precision: 0.9814 - val_recall: 0.9788\n",
      "Epoch 180/4096\n",
      "24/24 - 0s - loss: 0.0227 - fn: 54.0000 - fp: 59.0000 - tn: 5975.0000 - tp: 2963.0000 - precision: 0.9805 - recall: 0.9821 - val_loss: 0.1458 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 181/4096\n",
      "24/24 - 0s - loss: 0.0287 - fn: 58.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2959.0000 - precision: 0.9795 - recall: 0.9808 - val_loss: 0.1471 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 182/4096\n",
      "24/24 - 0s - loss: 0.0256 - fn: 56.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2961.0000 - precision: 0.9837 - recall: 0.9814 - val_loss: 0.1475 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 183/4096\n",
      "24/24 - 0s - loss: 0.0240 - fn: 51.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2966.0000 - precision: 0.9837 - recall: 0.9831 - val_loss: 0.1554 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 184/4096\n",
      "24/24 - 0s - loss: 0.0262 - fn: 57.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2960.0000 - precision: 0.9798 - recall: 0.9811 - val_loss: 0.1576 - val_fn: 21.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 734.0000 - val_precision: 0.9709 - val_recall: 0.9722\n",
      "Epoch 185/4096\n",
      "24/24 - 0s - loss: 0.0294 - fn: 63.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2954.0000 - precision: 0.9801 - recall: 0.9791 - val_loss: 0.1634 - val_fn: 21.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 734.0000 - val_precision: 0.9709 - val_recall: 0.9722\n",
      "Epoch 186/4096\n",
      "24/24 - 0s - loss: 0.0342 - fn: 78.0000 - fp: 73.0000 - tn: 5961.0000 - tp: 2939.0000 - precision: 0.9758 - recall: 0.9741 - val_loss: 0.1524 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 187/4096\n",
      "24/24 - 0s - loss: 0.0298 - fn: 60.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2957.0000 - precision: 0.9824 - recall: 0.9801 - val_loss: 0.1606 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 188/4096\n",
      "24/24 - 0s - loss: 0.0358 - fn: 76.0000 - fp: 64.0000 - tn: 5970.0000 - tp: 2941.0000 - precision: 0.9787 - recall: 0.9748 - val_loss: 0.1558 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 189/4096\n",
      "24/24 - 0s - loss: 0.0369 - fn: 71.0000 - fp: 63.0000 - tn: 5971.0000 - tp: 2946.0000 - precision: 0.9791 - recall: 0.9765 - val_loss: 0.1591 - val_fn: 21.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 734.0000 - val_precision: 0.9748 - val_recall: 0.9722\n",
      "Epoch 190/4096\n",
      "24/24 - 0s - loss: 0.0302 - fn: 69.0000 - fp: 63.0000 - tn: 5971.0000 - tp: 2948.0000 - precision: 0.9791 - recall: 0.9771 - val_loss: 0.1476 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 191/4096\n",
      "24/24 - 0s - loss: 0.0217 - fn: 47.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2970.0000 - precision: 0.9857 - recall: 0.9844 - val_loss: 0.1547 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 192/4096\n",
      "24/24 - 0s - loss: 0.0230 - fn: 54.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2963.0000 - precision: 0.9828 - recall: 0.9821 - val_loss: 0.1498 - val_fn: 16.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 739.0000 - val_precision: 0.9814 - val_recall: 0.9788\n",
      "Epoch 193/4096\n",
      "24/24 - 0s - loss: 0.0214 - fn: 47.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2970.0000 - precision: 0.9870 - recall: 0.9844 - val_loss: 0.1543 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 194/4096\n",
      "24/24 - 0s - loss: 0.0253 - fn: 52.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2965.0000 - precision: 0.9821 - recall: 0.9828 - val_loss: 0.1538 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 195/4096\n",
      "24/24 - 0s - loss: 0.0281 - fn: 59.0000 - fp: 58.0000 - tn: 5976.0000 - tp: 2958.0000 - precision: 0.9808 - recall: 0.9804 - val_loss: 0.1617 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 196/4096\n",
      "24/24 - 0s - loss: 0.0232 - fn: 56.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2961.0000 - precision: 0.9795 - recall: 0.9814 - val_loss: 0.1507 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 197/4096\n",
      "24/24 - 0s - loss: 0.0439 - fn: 70.0000 - fp: 75.0000 - tn: 5959.0000 - tp: 2947.0000 - precision: 0.9752 - recall: 0.9768 - val_loss: 0.1581 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 198/4096\n",
      "24/24 - 0s - loss: 0.0405 - fn: 68.0000 - fp: 72.0000 - tn: 5962.0000 - tp: 2949.0000 - precision: 0.9762 - recall: 0.9775 - val_loss: 0.1551 - val_fn: 17.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 738.0000 - val_precision: 0.9814 - val_recall: 0.9775\n",
      "Epoch 199/4096\n",
      "24/24 - 0s - loss: 0.0284 - fn: 58.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2959.0000 - precision: 0.9840 - recall: 0.9808 - val_loss: 0.1823 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 1485.0000 - val_tp: 729.0000 - val_precision: 0.9668 - val_recall: 0.9656\n",
      "Epoch 200/4096\n",
      "24/24 - 0s - loss: 0.0278 - fn: 55.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2962.0000 - precision: 0.9811 - recall: 0.9818 - val_loss: 0.1694 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 732.0000 - val_precision: 0.9708 - val_recall: 0.9695\n",
      "Epoch 201/4096\n",
      "24/24 - 0s - loss: 0.0252 - fn: 58.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2959.0000 - precision: 0.9798 - recall: 0.9808 - val_loss: 0.1562 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 202/4096\n",
      "24/24 - 0s - loss: 0.0308 - fn: 49.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2968.0000 - precision: 0.9831 - recall: 0.9838 - val_loss: 0.1670 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 203/4096\n",
      "24/24 - 0s - loss: 0.0350 - fn: 83.0000 - fp: 82.0000 - tn: 5952.0000 - tp: 2934.0000 - precision: 0.9728 - recall: 0.9725 - val_loss: 0.1590 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 204/4096\n",
      "24/24 - 0s - loss: 0.0211 - fn: 48.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2969.0000 - precision: 0.9841 - recall: 0.9841 - val_loss: 0.1622 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 205/4096\n",
      "24/24 - 0s - loss: 0.0225 - fn: 46.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2971.0000 - precision: 0.9857 - recall: 0.9848 - val_loss: 0.1635 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 206/4096\n",
      "24/24 - 0s - loss: 0.0255 - fn: 61.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2956.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.1585 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 207/4096\n",
      "24/24 - 0s - loss: 0.0280 - fn: 62.0000 - fp: 56.0000 - tn: 5978.0000 - tp: 2955.0000 - precision: 0.9814 - recall: 0.9794 - val_loss: 0.1649 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 208/4096\n",
      "24/24 - 0s - loss: 0.0276 - fn: 65.0000 - fp: 64.0000 - tn: 5970.0000 - tp: 2952.0000 - precision: 0.9788 - recall: 0.9785 - val_loss: 0.1715 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 209/4096\n",
      "24/24 - 0s - loss: 0.0270 - fn: 53.0000 - fp: 55.0000 - tn: 5979.0000 - tp: 2964.0000 - precision: 0.9818 - recall: 0.9824 - val_loss: 0.1638 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 210/4096\n",
      "24/24 - 0s - loss: 0.0340 - fn: 62.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2955.0000 - precision: 0.9801 - recall: 0.9794 - val_loss: 0.1662 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 211/4096\n",
      "24/24 - 0s - loss: 0.0291 - fn: 63.0000 - fp: 67.0000 - tn: 5967.0000 - tp: 2954.0000 - precision: 0.9778 - recall: 0.9791 - val_loss: 0.1613 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 212/4096\n",
      "24/24 - 0s - loss: 0.0258 - fn: 56.0000 - fp: 56.0000 - tn: 5978.0000 - tp: 2961.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.1664 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 213/4096\n",
      "24/24 - 0s - loss: 0.0244 - fn: 51.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2966.0000 - precision: 0.9844 - recall: 0.9831 - val_loss: 0.1605 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 214/4096\n",
      "24/24 - 0s - loss: 0.0234 - fn: 43.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2974.0000 - precision: 0.9851 - recall: 0.9857 - val_loss: 0.1571 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 215/4096\n",
      "24/24 - 0s - loss: 0.0283 - fn: 64.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2953.0000 - precision: 0.9794 - recall: 0.9788 - val_loss: 0.1663 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 216/4096\n",
      "24/24 - 0s - loss: 0.0400 - fn: 84.0000 - fp: 83.0000 - tn: 5951.0000 - tp: 2933.0000 - precision: 0.9725 - recall: 0.9722 - val_loss: 0.1763 - val_fn: 21.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 734.0000 - val_precision: 0.9683 - val_recall: 0.9722\n",
      "Epoch 217/4096\n",
      "24/24 - 0s - loss: 0.0238 - fn: 47.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2970.0000 - precision: 0.9821 - recall: 0.9844 - val_loss: 0.1661 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 218/4096\n",
      "24/24 - 0s - loss: 0.0219 - fn: 60.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2957.0000 - precision: 0.9811 - recall: 0.9801 - val_loss: 0.1634 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 219/4096\n",
      "24/24 - 0s - loss: 0.0204 - fn: 42.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2975.0000 - precision: 0.9874 - recall: 0.9861 - val_loss: 0.1686 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 220/4096\n",
      "24/24 - 0s - loss: 0.0262 - fn: 61.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2956.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.1743 - val_fn: 21.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 734.0000 - val_precision: 0.9748 - val_recall: 0.9722\n",
      "Epoch 221/4096\n",
      "24/24 - 0s - loss: 0.0230 - fn: 49.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2968.0000 - precision: 0.9834 - recall: 0.9838 - val_loss: 0.1650 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 222/4096\n",
      "24/24 - 0s - loss: 0.0357 - fn: 86.0000 - fp: 84.0000 - tn: 5950.0000 - tp: 2931.0000 - precision: 0.9721 - recall: 0.9715 - val_loss: 0.1622 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 223/4096\n",
      "24/24 - 0s - loss: 0.0396 - fn: 68.0000 - fp: 56.0000 - tn: 5978.0000 - tp: 2949.0000 - precision: 0.9814 - recall: 0.9775 - val_loss: 0.1704 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 224/4096\n",
      "24/24 - 0s - loss: 0.0296 - fn: 84.0000 - fp: 77.0000 - tn: 5957.0000 - tp: 2933.0000 - precision: 0.9744 - recall: 0.9722 - val_loss: 0.1659 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 225/4096\n",
      "24/24 - 0s - loss: 0.0289 - fn: 72.0000 - fp: 68.0000 - tn: 5966.0000 - tp: 2945.0000 - precision: 0.9774 - recall: 0.9761 - val_loss: 0.1609 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 226/4096\n",
      "24/24 - 0s - loss: 0.0223 - fn: 55.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2962.0000 - precision: 0.9834 - recall: 0.9818 - val_loss: 0.1681 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 227/4096\n",
      "24/24 - 0s - loss: 0.0291 - fn: 55.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2962.0000 - precision: 0.9821 - recall: 0.9818 - val_loss: 0.1680 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 228/4096\n",
      "24/24 - 0s - loss: 0.0228 - fn: 55.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2962.0000 - precision: 0.9831 - recall: 0.9818 - val_loss: 0.1691 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 229/4096\n",
      "24/24 - 0s - loss: 0.0231 - fn: 63.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2954.0000 - precision: 0.9801 - recall: 0.9791 - val_loss: 0.1596 - val_fn: 13.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 742.0000 - val_precision: 0.9841 - val_recall: 0.9828\n",
      "Epoch 230/4096\n",
      "24/24 - 0s - loss: 0.0245 - fn: 55.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2962.0000 - precision: 0.9801 - recall: 0.9818 - val_loss: 0.1708 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 231/4096\n",
      "24/24 - 0s - loss: 0.0218 - fn: 53.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2964.0000 - precision: 0.9828 - recall: 0.9824 - val_loss: 0.1681 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 232/4096\n",
      "24/24 - 0s - loss: 0.0198 - fn: 37.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2980.0000 - precision: 0.9874 - recall: 0.9877 - val_loss: 0.1688 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 233/4096\n",
      "24/24 - 0s - loss: 0.0210 - fn: 51.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2966.0000 - precision: 0.9867 - recall: 0.9831 - val_loss: 0.1699 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 234/4096\n",
      "24/24 - 0s - loss: 0.0200 - fn: 45.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2972.0000 - precision: 0.9877 - recall: 0.9851 - val_loss: 0.1861 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 235/4096\n",
      "24/24 - 0s - loss: 0.0212 - fn: 54.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2963.0000 - precision: 0.9828 - recall: 0.9821 - val_loss: 0.1743 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 236/4096\n",
      "24/24 - 0s - loss: 0.0208 - fn: 54.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2963.0000 - precision: 0.9834 - recall: 0.9821 - val_loss: 0.1733 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 237/4096\n",
      "24/24 - 0s - loss: 0.0241 - fn: 46.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2971.0000 - precision: 0.9867 - recall: 0.9848 - val_loss: 0.1769 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 238/4096\n",
      "24/24 - 0s - loss: 0.0228 - fn: 57.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2960.0000 - precision: 0.9840 - recall: 0.9811 - val_loss: 0.1712 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 239/4096\n",
      "24/24 - 0s - loss: 0.0216 - fn: 47.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2970.0000 - precision: 0.9861 - recall: 0.9844 - val_loss: 0.1715 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 240/4096\n",
      "24/24 - 0s - loss: 0.0241 - fn: 55.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2962.0000 - precision: 0.9821 - recall: 0.9818 - val_loss: 0.1927 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 731.0000 - val_precision: 0.9682 - val_recall: 0.9682\n",
      "Epoch 241/4096\n",
      "24/24 - 0s - loss: 0.0208 - fn: 57.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2960.0000 - precision: 0.9824 - recall: 0.9811 - val_loss: 0.1706 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 242/4096\n",
      "24/24 - 0s - loss: 0.0214 - fn: 44.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2973.0000 - precision: 0.9880 - recall: 0.9854 - val_loss: 0.1800 - val_fn: 18.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 737.0000 - val_precision: 0.9801 - val_recall: 0.9762\n",
      "Epoch 243/4096\n",
      "24/24 - 0s - loss: 0.0340 - fn: 43.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2974.0000 - precision: 0.9864 - recall: 0.9857 - val_loss: 0.1777 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 244/4096\n",
      "24/24 - 0s - loss: 0.0231 - fn: 54.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2963.0000 - precision: 0.9844 - recall: 0.9821 - val_loss: 0.1831 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 245/4096\n",
      "24/24 - 0s - loss: 0.0206 - fn: 49.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2968.0000 - precision: 0.9860 - recall: 0.9838 - val_loss: 0.1808 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 246/4096\n",
      "24/24 - 0s - loss: 0.0285 - fn: 49.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2968.0000 - precision: 0.9851 - recall: 0.9838 - val_loss: 0.1764 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 247/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 46.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2971.0000 - precision: 0.9857 - recall: 0.9848 - val_loss: 0.1818 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 248/4096\n",
      "24/24 - 0s - loss: 0.0301 - fn: 55.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2962.0000 - precision: 0.9827 - recall: 0.9818 - val_loss: 0.1870 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 249/4096\n",
      "24/24 - 0s - loss: 0.0251 - fn: 71.0000 - fp: 73.0000 - tn: 5961.0000 - tp: 2946.0000 - precision: 0.9758 - recall: 0.9765 - val_loss: 0.1733 - val_fn: 13.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 742.0000 - val_precision: 0.9828 - val_recall: 0.9828\n",
      "Epoch 250/4096\n",
      "24/24 - 0s - loss: 0.0227 - fn: 43.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2974.0000 - precision: 0.9851 - recall: 0.9857 - val_loss: 0.1793 - val_fn: 14.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 741.0000 - val_precision: 0.9802 - val_recall: 0.9815\n",
      "Epoch 251/4096\n",
      "24/24 - 0s - loss: 0.0294 - fn: 80.0000 - fp: 79.0000 - tn: 5955.0000 - tp: 2937.0000 - precision: 0.9738 - recall: 0.9735 - val_loss: 0.1795 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 252/4096\n",
      "24/24 - 0s - loss: 0.0169 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.1956 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 253/4096\n",
      "24/24 - 0s - loss: 0.0255 - fn: 53.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2964.0000 - precision: 0.9821 - recall: 0.9824 - val_loss: 0.1866 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 254/4096\n",
      "24/24 - 0s - loss: 0.0173 - fn: 42.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2975.0000 - precision: 0.9880 - recall: 0.9861 - val_loss: 0.1805 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 255/4096\n",
      "24/24 - 0s - loss: 0.0180 - fn: 43.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2974.0000 - precision: 0.9864 - recall: 0.9857 - val_loss: 0.1801 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 256/4096\n",
      "24/24 - 0s - loss: 0.0317 - fn: 66.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2951.0000 - precision: 0.9794 - recall: 0.9781 - val_loss: 0.1764 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 257/4096\n",
      "24/24 - 0s - loss: 0.0182 - fn: 43.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2974.0000 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.1789 - val_fn: 15.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 740.0000 - val_precision: 0.9840 - val_recall: 0.9801\n",
      "Epoch 258/4096\n",
      "24/24 - 0s - loss: 0.0217 - fn: 53.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2964.0000 - precision: 0.9841 - recall: 0.9824 - val_loss: 0.1842 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 259/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 51.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2966.0000 - precision: 0.9828 - recall: 0.9831 - val_loss: 0.1808 - val_fn: 20.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 735.0000 - val_precision: 0.9774 - val_recall: 0.9735\n",
      "Epoch 260/4096\n",
      "24/24 - 0s - loss: 0.0245 - fn: 65.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2952.0000 - precision: 0.9811 - recall: 0.9785 - val_loss: 0.1742 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 261/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 57.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2960.0000 - precision: 0.9840 - recall: 0.9811 - val_loss: 0.1869 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 262/4096\n",
      "24/24 - 0s - loss: 0.0148 - fn: 39.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2978.0000 - precision: 0.9867 - recall: 0.9871 - val_loss: 0.1795 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 263/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 42.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2975.0000 - precision: 0.9864 - recall: 0.9861 - val_loss: 0.1801 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 264/4096\n",
      "24/24 - 0s - loss: 0.0205 - fn: 63.0000 - fp: 67.0000 - tn: 5967.0000 - tp: 2954.0000 - precision: 0.9778 - recall: 0.9791 - val_loss: 0.1824 - val_fn: 15.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 740.0000 - val_precision: 0.9775 - val_recall: 0.9801\n",
      "Epoch 265/4096\n",
      "24/24 - 0s - loss: 0.0188 - fn: 46.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2971.0000 - precision: 0.9841 - recall: 0.9848 - val_loss: 0.1787 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 266/4096\n",
      "24/24 - 0s - loss: 0.0174 - fn: 47.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2970.0000 - precision: 0.9864 - recall: 0.9844 - val_loss: 0.1916 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 267/4096\n",
      "24/24 - 0s - loss: 0.0210 - fn: 72.0000 - fp: 66.0000 - tn: 5968.0000 - tp: 2945.0000 - precision: 0.9781 - recall: 0.9761 - val_loss: 0.1853 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 268/4096\n",
      "24/24 - 0s - loss: 0.0277 - fn: 65.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2952.0000 - precision: 0.9811 - recall: 0.9785 - val_loss: 0.1849 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 269/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 52.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2965.0000 - precision: 0.9847 - recall: 0.9828 - val_loss: 0.1837 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 270/4096\n",
      "24/24 - 0s - loss: 0.0206 - fn: 54.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2963.0000 - precision: 0.9841 - recall: 0.9821 - val_loss: 0.1891 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 271/4096\n",
      "24/24 - 0s - loss: 0.0192 - fn: 55.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2962.0000 - precision: 0.9850 - recall: 0.9818 - val_loss: 0.1839 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 272/4096\n",
      "24/24 - 0s - loss: 0.0223 - fn: 56.0000 - fp: 56.0000 - tn: 5978.0000 - tp: 2961.0000 - precision: 0.9814 - recall: 0.9814 - val_loss: 0.1833 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 273/4096\n",
      "24/24 - 0s - loss: 0.0315 - fn: 56.0000 - fp: 58.0000 - tn: 5976.0000 - tp: 2961.0000 - precision: 0.9808 - recall: 0.9814 - val_loss: 0.1860 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 274/4096\n",
      "24/24 - 0s - loss: 0.0180 - fn: 50.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2967.0000 - precision: 0.9851 - recall: 0.9834 - val_loss: 0.1846 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 275/4096\n",
      "24/24 - 0s - loss: 0.0149 - fn: 43.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2974.0000 - precision: 0.9871 - recall: 0.9857 - val_loss: 0.1842 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 276/4096\n",
      "24/24 - 0s - loss: 0.0144 - fn: 43.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2974.0000 - precision: 0.9861 - recall: 0.9857 - val_loss: 0.1864 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 277/4096\n",
      "24/24 - 0s - loss: 0.0196 - fn: 52.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2965.0000 - precision: 0.9831 - recall: 0.9828 - val_loss: 0.1887 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 278/4096\n",
      "24/24 - 0s - loss: 0.0169 - fn: 32.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2985.0000 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.1959 - val_fn: 20.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 735.0000 - val_precision: 0.9787 - val_recall: 0.9735\n",
      "Epoch 279/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 46.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2971.0000 - precision: 0.9857 - recall: 0.9848 - val_loss: 0.1868 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 280/4096\n",
      "24/24 - 0s - loss: 0.0206 - fn: 57.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2960.0000 - precision: 0.9821 - recall: 0.9811 - val_loss: 0.1857 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 281/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 46.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2971.0000 - precision: 0.9870 - recall: 0.9848 - val_loss: 0.1990 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 282/4096\n",
      "24/24 - 0s - loss: 0.0268 - fn: 66.0000 - fp: 63.0000 - tn: 5971.0000 - tp: 2951.0000 - precision: 0.9791 - recall: 0.9781 - val_loss: 0.2087 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 731.0000 - val_precision: 0.9682 - val_recall: 0.9682\n",
      "Epoch 283/4096\n",
      "24/24 - 0s - loss: 0.0209 - fn: 46.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2971.0000 - precision: 0.9851 - recall: 0.9848 - val_loss: 0.1928 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 284/4096\n",
      "24/24 - 0s - loss: 0.0194 - fn: 40.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2977.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.2001 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 285/4096\n",
      "24/24 - 0s - loss: 0.0156 - fn: 43.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2974.0000 - precision: 0.9854 - recall: 0.9857 - val_loss: 0.1938 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 286/4096\n",
      "24/24 - 0s - loss: 0.0141 - fn: 42.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2975.0000 - precision: 0.9867 - recall: 0.9861 - val_loss: 0.1958 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 287/4096\n",
      "24/24 - 0s - loss: 0.0157 - fn: 40.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2977.0000 - precision: 0.9861 - recall: 0.9867 - val_loss: 0.1925 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 288/4096\n",
      "24/24 - 0s - loss: 0.0222 - fn: 41.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2976.0000 - precision: 0.9858 - recall: 0.9864 - val_loss: 0.1913 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 289/4096\n",
      "24/24 - 0s - loss: 0.0447 - fn: 38.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2979.0000 - precision: 0.9858 - recall: 0.9874 - val_loss: 0.2042 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 290/4096\n",
      "24/24 - 0s - loss: 0.0163 - fn: 46.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2971.0000 - precision: 0.9864 - recall: 0.9848 - val_loss: 0.1904 - val_fn: 13.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 742.0000 - val_precision: 0.9841 - val_recall: 0.9828\n",
      "Epoch 291/4096\n",
      "24/24 - 0s - loss: 0.0223 - fn: 48.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2969.0000 - precision: 0.9851 - recall: 0.9841 - val_loss: 0.1902 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 292/4096\n",
      "24/24 - 0s - loss: 0.0184 - fn: 42.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2975.0000 - precision: 0.9858 - recall: 0.9861 - val_loss: 0.1982 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 293/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 50.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2967.0000 - precision: 0.9831 - recall: 0.9834 - val_loss: 0.2100 - val_fn: 21.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 734.0000 - val_precision: 0.9735 - val_recall: 0.9722\n",
      "Epoch 294/4096\n",
      "24/24 - 0s - loss: 0.0183 - fn: 45.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2972.0000 - precision: 0.9854 - recall: 0.9851 - val_loss: 0.1956 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 295/4096\n",
      "24/24 - 0s - loss: 0.0214 - fn: 51.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2966.0000 - precision: 0.9834 - recall: 0.9831 - val_loss: 0.1985 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 296/4096\n",
      "24/24 - 0s - loss: 0.0204 - fn: 42.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2975.0000 - precision: 0.9858 - recall: 0.9861 - val_loss: 0.1991 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 297/4096\n",
      "24/24 - 0s - loss: 0.0131 - fn: 30.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2987.0000 - precision: 0.9904 - recall: 0.9901 - val_loss: 0.1943 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 298/4096\n",
      "24/24 - 0s - loss: 0.0143 - fn: 40.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2977.0000 - precision: 0.9894 - recall: 0.9867 - val_loss: 0.1982 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 299/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 30.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2987.0000 - precision: 0.9907 - recall: 0.9901 - val_loss: 0.1979 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 300/4096\n",
      "24/24 - 0s - loss: 0.0130 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.1955 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 301/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 40.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2977.0000 - precision: 0.9884 - recall: 0.9867 - val_loss: 0.1991 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 302/4096\n",
      "24/24 - 0s - loss: 0.0225 - fn: 57.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2960.0000 - precision: 0.9827 - recall: 0.9811 - val_loss: 0.2095 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 303/4096\n",
      "24/24 - 0s - loss: 0.0239 - fn: 65.0000 - fp: 69.0000 - tn: 5965.0000 - tp: 2952.0000 - precision: 0.9772 - recall: 0.9785 - val_loss: 0.2214 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 731.0000 - val_precision: 0.9695 - val_recall: 0.9682\n",
      "Epoch 304/4096\n",
      "24/24 - 0s - loss: 0.0223 - fn: 68.0000 - fp: 68.0000 - tn: 5966.0000 - tp: 2949.0000 - precision: 0.9775 - recall: 0.9775 - val_loss: 0.1988 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 305/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 60.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2957.0000 - precision: 0.9798 - recall: 0.9801 - val_loss: 0.1972 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 306/4096\n",
      "24/24 - 0s - loss: 0.0180 - fn: 42.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2975.0000 - precision: 0.9858 - recall: 0.9861 - val_loss: 0.2045 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 307/4096\n",
      "24/24 - 0s - loss: 0.0282 - fn: 58.0000 - fp: 59.0000 - tn: 5975.0000 - tp: 2959.0000 - precision: 0.9805 - recall: 0.9808 - val_loss: 0.2041 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 308/4096\n",
      "24/24 - 0s - loss: 0.0200 - fn: 40.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2977.0000 - precision: 0.9881 - recall: 0.9867 - val_loss: 0.2103 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 309/4096\n",
      "24/24 - 0s - loss: 0.0282 - fn: 53.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2964.0000 - precision: 0.9831 - recall: 0.9824 - val_loss: 0.2258 - val_fn: 25.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 730.0000 - val_precision: 0.9695 - val_recall: 0.9669\n",
      "Epoch 310/4096\n",
      "24/24 - 0s - loss: 0.0330 - fn: 64.0000 - fp: 63.0000 - tn: 5971.0000 - tp: 2953.0000 - precision: 0.9791 - recall: 0.9788 - val_loss: 0.2335 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 1485.0000 - val_tp: 729.0000 - val_precision: 0.9668 - val_recall: 0.9656\n",
      "Epoch 311/4096\n",
      "24/24 - 0s - loss: 0.0302 - fn: 67.0000 - fp: 64.0000 - tn: 5970.0000 - tp: 2950.0000 - precision: 0.9788 - recall: 0.9778 - val_loss: 0.2010 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 312/4096\n",
      "24/24 - 0s - loss: 0.0195 - fn: 49.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2968.0000 - precision: 0.9834 - recall: 0.9838 - val_loss: 0.2107 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 313/4096\n",
      "24/24 - 0s - loss: 0.0246 - fn: 52.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2965.0000 - precision: 0.9831 - recall: 0.9828 - val_loss: 0.2040 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 314/4096\n",
      "24/24 - 0s - loss: 0.0215 - fn: 43.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2974.0000 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2004 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 315/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 44.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2973.0000 - precision: 0.9861 - recall: 0.9854 - val_loss: 0.2023 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 316/4096\n",
      "24/24 - 0s - loss: 0.0148 - fn: 30.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2987.0000 - precision: 0.9904 - recall: 0.9901 - val_loss: 0.2020 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 317/4096\n",
      "24/24 - 0s - loss: 0.0214 - fn: 29.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2988.0000 - precision: 0.9914 - recall: 0.9904 - val_loss: 0.2163 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 318/4096\n",
      "24/24 - 0s - loss: 0.0173 - fn: 40.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2977.0000 - precision: 0.9871 - recall: 0.9867 - val_loss: 0.2095 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 319/4096\n",
      "24/24 - 0s - loss: 0.0179 - fn: 41.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2976.0000 - precision: 0.9874 - recall: 0.9864 - val_loss: 0.2057 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 320/4096\n",
      "24/24 - 0s - loss: 0.0136 - fn: 47.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2970.0000 - precision: 0.9864 - recall: 0.9844 - val_loss: 0.2030 - val_fn: 12.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 743.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 321/4096\n",
      "24/24 - 0s - loss: 0.0174 - fn: 38.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2979.0000 - precision: 0.9877 - recall: 0.9874 - val_loss: 0.2062 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 322/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 41.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2976.0000 - precision: 0.9874 - recall: 0.9864 - val_loss: 0.2049 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 323/4096\n",
      "24/24 - 0s - loss: 0.0187 - fn: 35.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2982.0000 - precision: 0.9887 - recall: 0.9884 - val_loss: 0.2108 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 324/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 42.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2975.0000 - precision: 0.9867 - recall: 0.9861 - val_loss: 0.2075 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 325/4096\n",
      "24/24 - 0s - loss: 0.0199 - fn: 51.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2966.0000 - precision: 0.9834 - recall: 0.9831 - val_loss: 0.2123 - val_fn: 16.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 739.0000 - val_precision: 0.9840 - val_recall: 0.9788\n",
      "Epoch 326/4096\n",
      "24/24 - 0s - loss: 0.0167 - fn: 31.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2986.0000 - precision: 0.9914 - recall: 0.9897 - val_loss: 0.2120 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 327/4096\n",
      "24/24 - 0s - loss: 0.0194 - fn: 49.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2968.0000 - precision: 0.9831 - recall: 0.9838 - val_loss: 0.2240 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 328/4096\n",
      "24/24 - 0s - loss: 0.0216 - fn: 54.0000 - fp: 54.0000 - tn: 5980.0000 - tp: 2963.0000 - precision: 0.9821 - recall: 0.9821 - val_loss: 0.2124 - val_fn: 16.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 739.0000 - val_precision: 0.9814 - val_recall: 0.9788\n",
      "Epoch 329/4096\n",
      "24/24 - 0s - loss: 0.0249 - fn: 51.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2966.0000 - precision: 0.9837 - recall: 0.9831 - val_loss: 0.2132 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 330/4096\n",
      "24/24 - 0s - loss: 0.0297 - fn: 51.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2966.0000 - precision: 0.9834 - recall: 0.9831 - val_loss: 0.2017 - val_fn: 14.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 741.0000 - val_precision: 0.9802 - val_recall: 0.9815\n",
      "Epoch 331/4096\n",
      "24/24 - 0s - loss: 0.0272 - fn: 48.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2969.0000 - precision: 0.9847 - recall: 0.9841 - val_loss: 0.2279 - val_fn: 26.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 729.0000 - val_precision: 0.9694 - val_recall: 0.9656\n",
      "Epoch 332/4096\n",
      "24/24 - 0s - loss: 0.0236 - fn: 50.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2967.0000 - precision: 0.9851 - recall: 0.9834 - val_loss: 0.2110 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 333/4096\n",
      "24/24 - 0s - loss: 0.0193 - fn: 56.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2961.0000 - precision: 0.9844 - recall: 0.9814 - val_loss: 0.1993 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 334/4096\n",
      "24/24 - 0s - loss: 0.0247 - fn: 41.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2976.0000 - precision: 0.9851 - recall: 0.9864 - val_loss: 0.2083 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 335/4096\n",
      "24/24 - 0s - loss: 0.0228 - fn: 40.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2977.0000 - precision: 0.9864 - recall: 0.9867 - val_loss: 0.2104 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 336/4096\n",
      "24/24 - 0s - loss: 0.0194 - fn: 42.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2975.0000 - precision: 0.9864 - recall: 0.9861 - val_loss: 0.2103 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 337/4096\n",
      "24/24 - 0s - loss: 0.0187 - fn: 46.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2971.0000 - precision: 0.9857 - recall: 0.9848 - val_loss: 0.2067 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 338/4096\n",
      "24/24 - 0s - loss: 0.0178 - fn: 53.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2964.0000 - precision: 0.9831 - recall: 0.9824 - val_loss: 0.2133 - val_fn: 13.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 742.0000 - val_precision: 0.9841 - val_recall: 0.9828\n",
      "Epoch 339/4096\n",
      "24/24 - 0s - loss: 0.0149 - fn: 36.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2981.0000 - precision: 0.9891 - recall: 0.9881 - val_loss: 0.2133 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 340/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 36.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2981.0000 - precision: 0.9877 - recall: 0.9881 - val_loss: 0.2149 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 341/4096\n",
      "24/24 - 0s - loss: 0.0106 - fn: 30.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2987.0000 - precision: 0.9910 - recall: 0.9901 - val_loss: 0.2145 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 342/4096\n",
      "24/24 - 0s - loss: 0.0208 - fn: 39.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2978.0000 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.2130 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 343/4096\n",
      "24/24 - 0s - loss: 0.0196 - fn: 45.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2972.0000 - precision: 0.9857 - recall: 0.9851 - val_loss: 0.2165 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 344/4096\n",
      "24/24 - 0s - loss: 0.0105 - fn: 30.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2987.0000 - precision: 0.9897 - recall: 0.9901 - val_loss: 0.2123 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 345/4096\n",
      "24/24 - 0s - loss: 0.0184 - fn: 39.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2978.0000 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.2135 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 346/4096\n",
      "24/24 - 0s - loss: 0.0120 - fn: 31.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2986.0000 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.2172 - val_fn: 14.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 741.0000 - val_precision: 0.9841 - val_recall: 0.9815\n",
      "Epoch 347/4096\n",
      "24/24 - 0s - loss: 0.0183 - fn: 38.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2979.0000 - precision: 0.9861 - recall: 0.9874 - val_loss: 0.2177 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 348/4096\n",
      "24/24 - 0s - loss: 0.0161 - fn: 39.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2978.0000 - precision: 0.9864 - recall: 0.9871 - val_loss: 0.2134 - val_fn: 13.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 742.0000 - val_precision: 0.9841 - val_recall: 0.9828\n",
      "Epoch 349/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 40.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2977.0000 - precision: 0.9881 - recall: 0.9867 - val_loss: 0.2166 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 350/4096\n",
      "24/24 - 0s - loss: 0.0104 - fn: 27.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2990.0000 - precision: 0.9904 - recall: 0.9911 - val_loss: 0.2148 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 351/4096\n",
      "24/24 - 0s - loss: 0.0119 - fn: 31.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2986.0000 - precision: 0.9891 - recall: 0.9897 - val_loss: 0.2187 - val_fn: 12.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 743.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 352/4096\n",
      "24/24 - 0s - loss: 0.0132 - fn: 36.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2981.0000 - precision: 0.9887 - recall: 0.9881 - val_loss: 0.2205 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 353/4096\n",
      "24/24 - 0s - loss: 0.0144 - fn: 45.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2972.0000 - precision: 0.9854 - recall: 0.9851 - val_loss: 0.2241 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 354/4096\n",
      "24/24 - 0s - loss: 0.0152 - fn: 49.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2968.0000 - precision: 0.9847 - recall: 0.9838 - val_loss: 0.2189 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 355/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 32.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2985.0000 - precision: 0.9881 - recall: 0.9894 - val_loss: 0.2251 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 356/4096\n",
      "24/24 - 0s - loss: 0.0095 - fn: 27.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2990.0000 - precision: 0.9907 - recall: 0.9911 - val_loss: 0.2246 - val_fn: 16.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 739.0000 - val_precision: 0.9762 - val_recall: 0.9788\n",
      "Epoch 357/4096\n",
      "24/24 - 0s - loss: 0.0123 - fn: 20.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2997.0000 - precision: 0.9914 - recall: 0.9934 - val_loss: 0.2199 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 358/4096\n",
      "24/24 - 0s - loss: 0.0077 - fn: 15.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 3002.0000 - precision: 0.9931 - recall: 0.9950 - val_loss: 0.2301 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 359/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.2208 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 360/4096\n",
      "24/24 - 0s - loss: 0.0113 - fn: 30.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2987.0000 - precision: 0.9904 - recall: 0.9901 - val_loss: 0.2234 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 361/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 34.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2983.0000 - precision: 0.9884 - recall: 0.9887 - val_loss: 0.2286 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 362/4096\n",
      "24/24 - 0s - loss: 0.0130 - fn: 28.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2989.0000 - precision: 0.9901 - recall: 0.9907 - val_loss: 0.2274 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 363/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 27.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2990.0000 - precision: 0.9907 - recall: 0.9911 - val_loss: 0.2258 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 364/4096\n",
      "24/24 - 0s - loss: 0.0152 - fn: 45.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2972.0000 - precision: 0.9867 - recall: 0.9851 - val_loss: 0.2183 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 365/4096\n",
      "24/24 - 0s - loss: 0.0161 - fn: 43.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2974.0000 - precision: 0.9864 - recall: 0.9857 - val_loss: 0.2280 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 366/4096\n",
      "24/24 - 0s - loss: 0.0166 - fn: 45.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2972.0000 - precision: 0.9861 - recall: 0.9851 - val_loss: 0.2305 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 367/4096\n",
      "24/24 - 0s - loss: 0.0141 - fn: 43.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2974.0000 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2284 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 368/4096\n",
      "24/24 - 0s - loss: 0.0174 - fn: 51.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2966.0000 - precision: 0.9847 - recall: 0.9831 - val_loss: 0.2243 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 369/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 42.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2975.0000 - precision: 0.9858 - recall: 0.9861 - val_loss: 0.2224 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 370/4096\n",
      "24/24 - 0s - loss: 0.0135 - fn: 41.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2976.0000 - precision: 0.9874 - recall: 0.9864 - val_loss: 0.2191 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 371/4096\n",
      "24/24 - 0s - loss: 0.0111 - fn: 35.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2982.0000 - precision: 0.9900 - recall: 0.9884 - val_loss: 0.2354 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 372/4096\n",
      "24/24 - 0s - loss: 0.0160 - fn: 48.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2969.0000 - precision: 0.9857 - recall: 0.9841 - val_loss: 0.2475 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 732.0000 - val_precision: 0.9708 - val_recall: 0.9695\n",
      "Epoch 373/4096\n",
      "24/24 - 0s - loss: 0.0109 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.2265 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 374/4096\n",
      "24/24 - 0s - loss: 0.0124 - fn: 35.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2982.0000 - precision: 0.9891 - recall: 0.9884 - val_loss: 0.2200 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 375/4096\n",
      "24/24 - 0s - loss: 0.0170 - fn: 44.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2973.0000 - precision: 0.9848 - recall: 0.9854 - val_loss: 0.2207 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 376/4096\n",
      "24/24 - 0s - loss: 0.0110 - fn: 33.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2984.0000 - precision: 0.9900 - recall: 0.9891 - val_loss: 0.2319 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 377/4096\n",
      "24/24 - 0s - loss: 0.0120 - fn: 34.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2983.0000 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.2339 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 378/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 40.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2977.0000 - precision: 0.9877 - recall: 0.9867 - val_loss: 0.2292 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 379/4096\n",
      "24/24 - 0s - loss: 0.0163 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.2282 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 380/4096\n",
      "24/24 - 0s - loss: 0.0249 - fn: 47.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2970.0000 - precision: 0.9847 - recall: 0.9844 - val_loss: 0.2705 - val_fn: 28.0000 - val_fp: 29.0000 - val_tn: 1481.0000 - val_tp: 727.0000 - val_precision: 0.9616 - val_recall: 0.9629\n",
      "Epoch 381/4096\n",
      "24/24 - 0s - loss: 0.0296 - fn: 64.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2953.0000 - precision: 0.9801 - recall: 0.9788 - val_loss: 0.2348 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 733.0000 - val_precision: 0.9721 - val_recall: 0.9709\n",
      "Epoch 382/4096\n",
      "24/24 - 0s - loss: 0.0178 - fn: 45.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2972.0000 - precision: 0.9857 - recall: 0.9851 - val_loss: 0.2289 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 383/4096\n",
      "24/24 - 0s - loss: 0.0212 - fn: 41.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2976.0000 - precision: 0.9848 - recall: 0.9864 - val_loss: 0.2241 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 384/4096\n",
      "24/24 - 0s - loss: 0.0219 - fn: 32.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2985.0000 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2311 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 385/4096\n",
      "24/24 - 0s - loss: 0.0195 - fn: 48.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2969.0000 - precision: 0.9854 - recall: 0.9841 - val_loss: 0.2381 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 386/4096\n",
      "24/24 - 0s - loss: 0.0162 - fn: 38.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2979.0000 - precision: 0.9864 - recall: 0.9874 - val_loss: 0.2286 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 387/4096\n",
      "24/24 - 0s - loss: 0.0227 - fn: 51.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2966.0000 - precision: 0.9841 - recall: 0.9831 - val_loss: 0.2527 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 1485.0000 - val_tp: 730.0000 - val_precision: 0.9669 - val_recall: 0.9669\n",
      "Epoch 388/4096\n",
      "24/24 - 0s - loss: 0.0180 - fn: 37.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2980.0000 - precision: 0.9881 - recall: 0.9877 - val_loss: 0.2340 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 389/4096\n",
      "24/24 - 0s - loss: 0.0155 - fn: 42.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2975.0000 - precision: 0.9874 - recall: 0.9861 - val_loss: 0.2254 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 390/4096\n",
      "24/24 - 0s - loss: 0.0142 - fn: 45.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2972.0000 - precision: 0.9857 - recall: 0.9851 - val_loss: 0.2230 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 391/4096\n",
      "24/24 - 0s - loss: 0.0122 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.2258 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 392/4096\n",
      "24/24 - 0s - loss: 0.0087 - fn: 24.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2993.0000 - precision: 0.9924 - recall: 0.9920 - val_loss: 0.2237 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 393/4096\n",
      "24/24 - 0s - loss: 0.0082 - fn: 23.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2994.0000 - precision: 0.9924 - recall: 0.9924 - val_loss: 0.2249 - val_fn: 12.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 743.0000 - val_precision: 0.9828 - val_recall: 0.9841\n",
      "Epoch 394/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 27.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2990.0000 - precision: 0.9917 - recall: 0.9911 - val_loss: 0.2283 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 395/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.2424 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 396/4096\n",
      "24/24 - 0s - loss: 0.0107 - fn: 43.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2974.0000 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2420 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 397/4096\n",
      "24/24 - 0s - loss: 0.0130 - fn: 40.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2977.0000 - precision: 0.9871 - recall: 0.9867 - val_loss: 0.2396 - val_fn: 16.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 739.0000 - val_precision: 0.9814 - val_recall: 0.9788\n",
      "Epoch 398/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 24.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2993.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.2288 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 399/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 29.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2988.0000 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.2436 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 400/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 36.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2981.0000 - precision: 0.9877 - recall: 0.9881 - val_loss: 0.2323 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 401/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 37.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2980.0000 - precision: 0.9884 - recall: 0.9877 - val_loss: 0.2372 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 402/4096\n",
      "24/24 - 0s - loss: 0.0113 - fn: 37.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2980.0000 - precision: 0.9871 - recall: 0.9877 - val_loss: 0.2364 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 403/4096\n",
      "24/24 - 0s - loss: 0.0202 - fn: 54.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2963.0000 - precision: 0.9824 - recall: 0.9821 - val_loss: 0.2448 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 404/4096\n",
      "24/24 - 0s - loss: 0.0147 - fn: 44.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2973.0000 - precision: 0.9848 - recall: 0.9854 - val_loss: 0.2361 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 405/4096\n",
      "24/24 - 0s - loss: 0.0159 - fn: 37.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2980.0000 - precision: 0.9871 - recall: 0.9877 - val_loss: 0.2326 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 406/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 33.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2984.0000 - precision: 0.9910 - recall: 0.9891 - val_loss: 0.2277 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 407/4096\n",
      "24/24 - 0s - loss: 0.0112 - fn: 25.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2992.0000 - precision: 0.9904 - recall: 0.9917 - val_loss: 0.2508 - val_fn: 22.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 733.0000 - val_precision: 0.9696 - val_recall: 0.9709\n",
      "Epoch 408/4096\n",
      "24/24 - 0s - loss: 0.0147 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.2350 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 409/4096\n",
      "24/24 - 0s - loss: 0.0111 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.2348 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 410/4096\n",
      "24/24 - 0s - loss: 0.0093 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.2354 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 411/4096\n",
      "24/24 - 0s - loss: 0.0124 - fn: 32.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2985.0000 - precision: 0.9897 - recall: 0.9894 - val_loss: 0.2428 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 412/4096\n",
      "24/24 - 0s - loss: 0.0144 - fn: 43.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2974.0000 - precision: 0.9877 - recall: 0.9857 - val_loss: 0.2255 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 413/4096\n",
      "24/24 - 0s - loss: 0.0089 - fn: 22.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2995.0000 - precision: 0.9934 - recall: 0.9927 - val_loss: 0.2311 - val_fn: 13.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 742.0000 - val_precision: 0.9841 - val_recall: 0.9828\n",
      "Epoch 414/4096\n",
      "24/24 - 0s - loss: 0.0117 - fn: 30.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2987.0000 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.2358 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 415/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 26.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2991.0000 - precision: 0.9907 - recall: 0.9914 - val_loss: 0.2342 - val_fn: 14.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 741.0000 - val_precision: 0.9841 - val_recall: 0.9815\n",
      "Epoch 416/4096\n",
      "24/24 - 0s - loss: 0.0129 - fn: 34.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2983.0000 - precision: 0.9891 - recall: 0.9887 - val_loss: 0.2393 - val_fn: 12.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 743.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 417/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 21.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2996.0000 - precision: 0.9934 - recall: 0.9930 - val_loss: 0.2363 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 418/4096\n",
      "24/24 - 0s - loss: 0.0138 - fn: 41.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2976.0000 - precision: 0.9887 - recall: 0.9864 - val_loss: 0.2385 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 419/4096\n",
      "24/24 - 0s - loss: 0.0160 - fn: 37.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2980.0000 - precision: 0.9884 - recall: 0.9877 - val_loss: 0.2381 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 420/4096\n",
      "24/24 - 0s - loss: 0.0191 - fn: 42.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2975.0000 - precision: 0.9867 - recall: 0.9861 - val_loss: 0.2398 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 421/4096\n",
      "24/24 - 0s - loss: 0.0200 - fn: 46.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2971.0000 - precision: 0.9851 - recall: 0.9848 - val_loss: 0.2391 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 422/4096\n",
      "24/24 - 0s - loss: 0.0171 - fn: 39.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2978.0000 - precision: 0.9874 - recall: 0.9871 - val_loss: 0.2342 - val_fn: 11.0000 - val_fp: 11.0000 - val_tn: 1499.0000 - val_tp: 744.0000 - val_precision: 0.9854 - val_recall: 0.9854\n",
      "Epoch 423/4096\n",
      "24/24 - 0s - loss: 0.0124 - fn: 33.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2984.0000 - precision: 0.9900 - recall: 0.9891 - val_loss: 0.2319 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 424/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 32.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2985.0000 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2368 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 425/4096\n",
      "24/24 - 0s - loss: 0.0130 - fn: 25.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2992.0000 - precision: 0.9914 - recall: 0.9917 - val_loss: 0.2377 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 426/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 38.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2979.0000 - precision: 0.9874 - recall: 0.9874 - val_loss: 0.2502 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 427/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 28.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2989.0000 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.2360 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 428/4096\n",
      "24/24 - 0s - loss: 0.0124 - fn: 31.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2986.0000 - precision: 0.9907 - recall: 0.9897 - val_loss: 0.2461 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 429/4096\n",
      "24/24 - 0s - loss: 0.0220 - fn: 50.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2967.0000 - precision: 0.9851 - recall: 0.9834 - val_loss: 0.2541 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 430/4096\n",
      "24/24 - 0s - loss: 0.0169 - fn: 51.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2966.0000 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.2363 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 431/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 34.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2983.0000 - precision: 0.9884 - recall: 0.9887 - val_loss: 0.2372 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 432/4096\n",
      "24/24 - 0s - loss: 0.0237 - fn: 45.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2972.0000 - precision: 0.9867 - recall: 0.9851 - val_loss: 0.2327 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 433/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 41.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2976.0000 - precision: 0.9861 - recall: 0.9864 - val_loss: 0.2365 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 434/4096\n",
      "24/24 - 0s - loss: 0.0318 - fn: 62.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2955.0000 - precision: 0.9798 - recall: 0.9794 - val_loss: 0.2414 - val_fn: 17.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 738.0000 - val_precision: 0.9814 - val_recall: 0.9775\n",
      "Epoch 435/4096\n",
      "24/24 - 0s - loss: 0.0449 - fn: 47.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2970.0000 - precision: 0.9864 - recall: 0.9844 - val_loss: 0.2433 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 436/4096\n",
      "24/24 - 0s - loss: 0.0199 - fn: 29.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2988.0000 - precision: 0.9897 - recall: 0.9904 - val_loss: 0.2388 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 437/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 29.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2988.0000 - precision: 0.9891 - recall: 0.9904 - val_loss: 0.2344 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 438/4096\n",
      "24/24 - 0s - loss: 0.0125 - fn: 34.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2983.0000 - precision: 0.9881 - recall: 0.9887 - val_loss: 0.2419 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 439/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 31.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2986.0000 - precision: 0.9914 - recall: 0.9897 - val_loss: 0.2416 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 440/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 31.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2986.0000 - precision: 0.9887 - recall: 0.9897 - val_loss: 0.2486 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 441/4096\n",
      "24/24 - 0s - loss: 0.0139 - fn: 37.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2980.0000 - precision: 0.9890 - recall: 0.9877 - val_loss: 0.2554 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 442/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 22.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2995.0000 - precision: 0.9924 - recall: 0.9927 - val_loss: 0.2430 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 443/4096\n",
      "24/24 - 0s - loss: 0.0261 - fn: 27.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2990.0000 - precision: 0.9914 - recall: 0.9911 - val_loss: 0.2428 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 444/4096\n",
      "24/24 - 0s - loss: 0.0347 - fn: 32.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2985.0000 - precision: 0.9900 - recall: 0.9894 - val_loss: 0.2536 - val_fn: 18.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 737.0000 - val_precision: 0.9736 - val_recall: 0.9762\n",
      "Epoch 445/4096\n",
      "24/24 - 0s - loss: 0.0456 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.2500 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 446/4096\n",
      "24/24 - 0s - loss: 0.0218 - fn: 27.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2990.0000 - precision: 0.9897 - recall: 0.9911 - val_loss: 0.2507 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 447/4096\n",
      "24/24 - 0s - loss: 0.0131 - fn: 35.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2982.0000 - precision: 0.9891 - recall: 0.9884 - val_loss: 0.2461 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 448/4096\n",
      "24/24 - 0s - loss: 0.0157 - fn: 35.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2982.0000 - precision: 0.9897 - recall: 0.9884 - val_loss: 0.2727 - val_fn: 23.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 732.0000 - val_precision: 0.9721 - val_recall: 0.9695\n",
      "Epoch 449/4096\n",
      "24/24 - 0s - loss: 0.0139 - fn: 41.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2976.0000 - precision: 0.9871 - recall: 0.9864 - val_loss: 0.2469 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 450/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.2515 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 451/4096\n",
      "24/24 - 0s - loss: 0.0170 - fn: 48.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2969.0000 - precision: 0.9838 - recall: 0.9841 - val_loss: 0.2538 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 452/4096\n",
      "24/24 - 0s - loss: 0.0160 - fn: 33.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2984.0000 - precision: 0.9881 - recall: 0.9891 - val_loss: 0.2515 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 453/4096\n",
      "24/24 - 0s - loss: 0.0171 - fn: 33.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2984.0000 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.2515 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 454/4096\n",
      "24/24 - 0s - loss: 0.0157 - fn: 41.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2976.0000 - precision: 0.9845 - recall: 0.9864 - val_loss: 0.2608 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 455/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 43.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2974.0000 - precision: 0.9851 - recall: 0.9857 - val_loss: 0.2557 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 456/4096\n",
      "24/24 - 0s - loss: 0.0078 - fn: 26.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2991.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.2536 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 457/4096\n",
      "24/24 - 0s - loss: 0.0115 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.2596 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 458/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 29.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2988.0000 - precision: 0.9887 - recall: 0.9904 - val_loss: 0.2452 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 459/4096\n",
      "24/24 - 0s - loss: 0.0127 - fn: 40.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2977.0000 - precision: 0.9877 - recall: 0.9867 - val_loss: 0.2573 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 460/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 34.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2983.0000 - precision: 0.9884 - recall: 0.9887 - val_loss: 0.2555 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 461/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 41.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2976.0000 - precision: 0.9854 - recall: 0.9864 - val_loss: 0.2622 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 462/4096\n",
      "24/24 - 0s - loss: 0.0131 - fn: 29.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2988.0000 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.2560 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 463/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.2524 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 464/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 23.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2994.0000 - precision: 0.9914 - recall: 0.9924 - val_loss: 0.2555 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 465/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 14.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3003.0000 - precision: 0.9944 - recall: 0.9954 - val_loss: 0.2590 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 466/4096\n",
      "24/24 - 0s - loss: 0.0077 - fn: 18.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2999.0000 - precision: 0.9927 - recall: 0.9940 - val_loss: 0.2530 - val_fn: 15.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 740.0000 - val_precision: 0.9775 - val_recall: 0.9801\n",
      "Epoch 467/4096\n",
      "24/24 - 0s - loss: 0.0131 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.2556 - val_fn: 13.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 742.0000 - val_precision: 0.9815 - val_recall: 0.9828\n",
      "Epoch 468/4096\n",
      "24/24 - 0s - loss: 0.0163 - fn: 35.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2982.0000 - precision: 0.9900 - recall: 0.9884 - val_loss: 0.2621 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 469/4096\n",
      "24/24 - 0s - loss: 0.0331 - fn: 83.0000 - fp: 86.0000 - tn: 5948.0000 - tp: 2934.0000 - precision: 0.9715 - recall: 0.9725 - val_loss: 0.2973 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 1482.0000 - val_tp: 725.0000 - val_precision: 0.9628 - val_recall: 0.9603\n",
      "Epoch 470/4096\n",
      "24/24 - 0s - loss: 0.0245 - fn: 61.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2956.0000 - precision: 0.9798 - recall: 0.9798 - val_loss: 0.2662 - val_fn: 18.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 737.0000 - val_precision: 0.9736 - val_recall: 0.9762\n",
      "Epoch 471/4096\n",
      "24/24 - 0s - loss: 0.0129 - fn: 37.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2980.0000 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.2591 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 472/4096\n",
      "24/24 - 0s - loss: 0.0132 - fn: 30.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2987.0000 - precision: 0.9891 - recall: 0.9901 - val_loss: 0.2662 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 473/4096\n",
      "24/24 - 0s - loss: 0.0104 - fn: 27.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2990.0000 - precision: 0.9897 - recall: 0.9911 - val_loss: 0.2687 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 474/4096\n",
      "24/24 - 0s - loss: 0.0157 - fn: 44.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2973.0000 - precision: 0.9844 - recall: 0.9854 - val_loss: 0.2559 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 475/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 31.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2986.0000 - precision: 0.9891 - recall: 0.9897 - val_loss: 0.2577 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 476/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 45.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2972.0000 - precision: 0.9838 - recall: 0.9851 - val_loss: 0.2652 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 477/4096\n",
      "24/24 - 0s - loss: 0.0160 - fn: 52.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2965.0000 - precision: 0.9841 - recall: 0.9828 - val_loss: 0.2584 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 478/4096\n",
      "24/24 - 0s - loss: 0.0169 - fn: 53.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2964.0000 - precision: 0.9824 - recall: 0.9824 - val_loss: 0.2592 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 479/4096\n",
      "24/24 - 0s - loss: 0.0119 - fn: 26.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2991.0000 - precision: 0.9907 - recall: 0.9914 - val_loss: 0.2718 - val_fn: 20.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 735.0000 - val_precision: 0.9709 - val_recall: 0.9735\n",
      "Epoch 480/4096\n",
      "24/24 - 0s - loss: 0.0119 - fn: 40.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2977.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.2784 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 481/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 28.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2989.0000 - precision: 0.9897 - recall: 0.9907 - val_loss: 0.2621 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 482/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 39.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2978.0000 - precision: 0.9867 - recall: 0.9871 - val_loss: 0.2774 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 483/4096\n",
      "24/24 - 0s - loss: 0.0163 - fn: 54.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2963.0000 - precision: 0.9831 - recall: 0.9821 - val_loss: 0.2623 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 484/4096\n",
      "24/24 - 0s - loss: 0.0139 - fn: 35.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2982.0000 - precision: 0.9868 - recall: 0.9884 - val_loss: 0.2537 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 485/4096\n",
      "24/24 - 0s - loss: 0.0135 - fn: 40.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2977.0000 - precision: 0.9871 - recall: 0.9867 - val_loss: 0.2684 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 486/4096\n",
      "24/24 - 0s - loss: 0.0162 - fn: 43.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2974.0000 - precision: 0.9851 - recall: 0.9857 - val_loss: 0.2764 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 487/4096\n",
      "24/24 - 0s - loss: 0.0136 - fn: 38.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2979.0000 - precision: 0.9871 - recall: 0.9874 - val_loss: 0.2679 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 488/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 38.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2979.0000 - precision: 0.9877 - recall: 0.9874 - val_loss: 0.2626 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 489/4096\n",
      "24/24 - 0s - loss: 0.0163 - fn: 46.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2971.0000 - precision: 0.9851 - recall: 0.9848 - val_loss: 0.2593 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 490/4096\n",
      "24/24 - 0s - loss: 0.0132 - fn: 34.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2983.0000 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.2566 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 491/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 36.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2981.0000 - precision: 0.9887 - recall: 0.9881 - val_loss: 0.2598 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 492/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 22.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2995.0000 - precision: 0.9930 - recall: 0.9927 - val_loss: 0.2569 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 493/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 32.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2985.0000 - precision: 0.9884 - recall: 0.9894 - val_loss: 0.2548 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 494/4096\n",
      "24/24 - 0s - loss: 0.0078 - fn: 25.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2992.0000 - precision: 0.9914 - recall: 0.9917 - val_loss: 0.2602 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 495/4096\n",
      "24/24 - 0s - loss: 0.0164 - fn: 48.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2969.0000 - precision: 0.9838 - recall: 0.9841 - val_loss: 0.2624 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 496/4096\n",
      "24/24 - 0s - loss: 0.0150 - fn: 32.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2985.0000 - precision: 0.9884 - recall: 0.9894 - val_loss: 0.2613 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 497/4096\n",
      "24/24 - 0s - loss: 0.0125 - fn: 34.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2983.0000 - precision: 0.9868 - recall: 0.9887 - val_loss: 0.2618 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 498/4096\n",
      "24/24 - 0s - loss: 0.0125 - fn: 32.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2985.0000 - precision: 0.9887 - recall: 0.9894 - val_loss: 0.2700 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 499/4096\n",
      "24/24 - 0s - loss: 0.0107 - fn: 34.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2983.0000 - precision: 0.9871 - recall: 0.9887 - val_loss: 0.2603 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 500/4096\n",
      "24/24 - 0s - loss: 0.0095 - fn: 32.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2985.0000 - precision: 0.9900 - recall: 0.9894 - val_loss: 0.2578 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 501/4096\n",
      "24/24 - 0s - loss: 0.0082 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.2653 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 502/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 27.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2990.0000 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.2684 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 503/4096\n",
      "24/24 - 0s - loss: 0.0232 - fn: 77.0000 - fp: 76.0000 - tn: 5958.0000 - tp: 2940.0000 - precision: 0.9748 - recall: 0.9745 - val_loss: 0.2699 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 504/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 37.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2980.0000 - precision: 0.9871 - recall: 0.9877 - val_loss: 0.2645 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 505/4096\n",
      "24/24 - 0s - loss: 0.0094 - fn: 31.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2986.0000 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.2610 - val_fn: 13.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 742.0000 - val_precision: 0.9828 - val_recall: 0.9828\n",
      "Epoch 506/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 27.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2990.0000 - precision: 0.9904 - recall: 0.9911 - val_loss: 0.2616 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 507/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.2580 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 508/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 26.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2991.0000 - precision: 0.9904 - recall: 0.9914 - val_loss: 0.2591 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 509/4096\n",
      "24/24 - 0s - loss: 0.0112 - fn: 35.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2982.0000 - precision: 0.9884 - recall: 0.9884 - val_loss: 0.2607 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 510/4096\n",
      "24/24 - 0s - loss: 0.0104 - fn: 25.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2992.0000 - precision: 0.9907 - recall: 0.9917 - val_loss: 0.2534 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 511/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 34.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2983.0000 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.2594 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 512/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 30.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2987.0000 - precision: 0.9904 - recall: 0.9901 - val_loss: 0.2633 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 513/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 19.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2998.0000 - precision: 0.9927 - recall: 0.9937 - val_loss: 0.2594 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 514/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 19.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2998.0000 - precision: 0.9944 - recall: 0.9937 - val_loss: 0.2644 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 515/4096\n",
      "24/24 - 0s - loss: 0.0050 - fn: 14.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3003.0000 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.2649 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 516/4096\n",
      "24/24 - 0s - loss: 0.0058 - fn: 25.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2992.0000 - precision: 0.9920 - recall: 0.9917 - val_loss: 0.2645 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 517/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 20.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2997.0000 - precision: 0.9944 - recall: 0.9934 - val_loss: 0.2662 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 518/4096\n",
      "24/24 - 0s - loss: 0.0090 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2628 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 519/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 23.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2994.0000 - precision: 0.9917 - recall: 0.9924 - val_loss: 0.2667 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 520/4096\n",
      "24/24 - 0s - loss: 0.0068 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2730 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 521/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.2740 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 522/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.2623 - val_fn: 14.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 741.0000 - val_precision: 0.9789 - val_recall: 0.9815\n",
      "Epoch 523/4096\n",
      "24/24 - 0s - loss: 0.0064 - fn: 21.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2996.0000 - precision: 0.9937 - recall: 0.9930 - val_loss: 0.2670 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 524/4096\n",
      "24/24 - 0s - loss: 0.0078 - fn: 26.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2991.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.2700 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 525/4096\n",
      "24/24 - 0s - loss: 0.0071 - fn: 22.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2995.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.2690 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 526/4096\n",
      "24/24 - 0s - loss: 0.0048 - fn: 15.0000 - fp: 13.0000 - tn: 6021.0000 - tp: 3002.0000 - precision: 0.9957 - recall: 0.9950 - val_loss: 0.2673 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 527/4096\n",
      "24/24 - 0s - loss: 0.0074 - fn: 19.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2998.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.2700 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 528/4096\n",
      "24/24 - 0s - loss: 0.0045 - fn: 16.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3001.0000 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.2751 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 529/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 28.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2989.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.2765 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 530/4096\n",
      "24/24 - 0s - loss: 0.0093 - fn: 21.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2996.0000 - precision: 0.9934 - recall: 0.9930 - val_loss: 0.2745 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 531/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 20.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2997.0000 - precision: 0.9930 - recall: 0.9934 - val_loss: 0.2754 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 532/4096\n",
      "24/24 - 0s - loss: 0.0217 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2738 - val_fn: 17.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 738.0000 - val_precision: 0.9827 - val_recall: 0.9775\n",
      "Epoch 533/4096\n",
      "24/24 - 0s - loss: 0.0363 - fn: 38.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2979.0000 - precision: 0.9890 - recall: 0.9874 - val_loss: 0.2826 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 534/4096\n",
      "24/24 - 0s - loss: 0.0286 - fn: 21.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2996.0000 - precision: 0.9924 - recall: 0.9930 - val_loss: 0.2712 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 535/4096\n",
      "24/24 - 0s - loss: 0.0355 - fn: 19.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2998.0000 - precision: 0.9940 - recall: 0.9937 - val_loss: 0.2759 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 536/4096\n",
      "24/24 - 0s - loss: 0.0242 - fn: 35.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2982.0000 - precision: 0.9884 - recall: 0.9884 - val_loss: 0.2752 - val_fn: 18.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 737.0000 - val_precision: 0.9736 - val_recall: 0.9762\n",
      "Epoch 537/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 34.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2983.0000 - precision: 0.9897 - recall: 0.9887 - val_loss: 0.2716 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 538/4096\n",
      "24/24 - 0s - loss: 0.0149 - fn: 24.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2993.0000 - precision: 0.9940 - recall: 0.9920 - val_loss: 0.2660 - val_fn: 13.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 742.0000 - val_precision: 0.9815 - val_recall: 0.9828\n",
      "Epoch 539/4096\n",
      "24/24 - 0s - loss: 0.0138 - fn: 20.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 2997.0000 - precision: 0.9947 - recall: 0.9934 - val_loss: 0.2700 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 540/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 20.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2997.0000 - precision: 0.9927 - recall: 0.9934 - val_loss: 0.2681 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 541/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.2676 - val_fn: 14.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 741.0000 - val_precision: 0.9841 - val_recall: 0.9815\n",
      "Epoch 542/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 20.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2997.0000 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.2734 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 543/4096\n",
      "24/24 - 0s - loss: 0.0202 - fn: 42.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2975.0000 - precision: 0.9851 - recall: 0.9861 - val_loss: 0.2740 - val_fn: 14.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 741.0000 - val_precision: 0.9789 - val_recall: 0.9815\n",
      "Epoch 544/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 34.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2983.0000 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.2595 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 545/4096\n",
      "24/24 - 0s - loss: 0.0409 - fn: 63.0000 - fp: 68.0000 - tn: 5966.0000 - tp: 2954.0000 - precision: 0.9775 - recall: 0.9791 - val_loss: 0.2714 - val_fn: 13.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 742.0000 - val_precision: 0.9815 - val_recall: 0.9828\n",
      "Epoch 546/4096\n",
      "24/24 - 0s - loss: 0.0385 - fn: 30.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2987.0000 - precision: 0.9891 - recall: 0.9901 - val_loss: 0.2772 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 547/4096\n",
      "24/24 - 0s - loss: 0.0381 - fn: 46.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2971.0000 - precision: 0.9851 - recall: 0.9848 - val_loss: 0.2604 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 548/4096\n",
      "24/24 - 0s - loss: 0.0188 - fn: 36.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2981.0000 - precision: 0.9897 - recall: 0.9881 - val_loss: 0.2598 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 549/4096\n",
      "24/24 - 0s - loss: 0.0232 - fn: 41.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2976.0000 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.2656 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 550/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 25.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2992.0000 - precision: 0.9924 - recall: 0.9917 - val_loss: 0.2682 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 551/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 24.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2993.0000 - precision: 0.9917 - recall: 0.9920 - val_loss: 0.2694 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 552/4096\n",
      "24/24 - 0s - loss: 0.0104 - fn: 37.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2980.0000 - precision: 0.9890 - recall: 0.9877 - val_loss: 0.2597 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 553/4096\n",
      "24/24 - 0s - loss: 0.0130 - fn: 41.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2976.0000 - precision: 0.9880 - recall: 0.9864 - val_loss: 0.2668 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 554/4096\n",
      "24/24 - 0s - loss: 0.0303 - fn: 67.0000 - fp: 69.0000 - tn: 5965.0000 - tp: 2950.0000 - precision: 0.9771 - recall: 0.9778 - val_loss: 0.2734 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 555/4096\n",
      "24/24 - 0s - loss: 0.0204 - fn: 56.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2961.0000 - precision: 0.9827 - recall: 0.9814 - val_loss: 0.2760 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 556/4096\n",
      "24/24 - 0s - loss: 0.0194 - fn: 56.0000 - fp: 57.0000 - tn: 5977.0000 - tp: 2961.0000 - precision: 0.9811 - recall: 0.9814 - val_loss: 0.2605 - val_fn: 18.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 737.0000 - val_precision: 0.9736 - val_recall: 0.9762\n",
      "Epoch 557/4096\n",
      "24/24 - 0s - loss: 0.0141 - fn: 35.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2982.0000 - precision: 0.9881 - recall: 0.9884 - val_loss: 0.2592 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 558/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 32.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2985.0000 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2645 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 559/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 18.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2999.0000 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.2682 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 560/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 28.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2989.0000 - precision: 0.9901 - recall: 0.9907 - val_loss: 0.2695 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 561/4096\n",
      "24/24 - 0s - loss: 0.0068 - fn: 22.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2995.0000 - precision: 0.9934 - recall: 0.9927 - val_loss: 0.2685 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 562/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 19.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2998.0000 - precision: 0.9930 - recall: 0.9937 - val_loss: 0.2780 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 563/4096\n",
      "24/24 - 0s - loss: 0.0148 - fn: 42.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2975.0000 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.2865 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 731.0000 - val_precision: 0.9682 - val_recall: 0.9682\n",
      "Epoch 564/4096\n",
      "24/24 - 0s - loss: 0.0192 - fn: 51.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2966.0000 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.2736 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 565/4096\n",
      "24/24 - 0s - loss: 0.0177 - fn: 53.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2964.0000 - precision: 0.9828 - recall: 0.9824 - val_loss: 0.2628 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 566/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 48.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2969.0000 - precision: 0.9841 - recall: 0.9841 - val_loss: 0.2600 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 567/4096\n",
      "24/24 - 0s - loss: 0.0123 - fn: 32.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2985.0000 - precision: 0.9887 - recall: 0.9894 - val_loss: 0.2660 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 568/4096\n",
      "24/24 - 0s - loss: 0.0137 - fn: 37.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2980.0000 - precision: 0.9858 - recall: 0.9877 - val_loss: 0.2582 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 569/4096\n",
      "24/24 - 0s - loss: 0.0189 - fn: 60.0000 - fp: 59.0000 - tn: 5975.0000 - tp: 2957.0000 - precision: 0.9804 - recall: 0.9801 - val_loss: 0.2616 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 570/4096\n",
      "24/24 - 0s - loss: 0.0094 - fn: 24.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2993.0000 - precision: 0.9924 - recall: 0.9920 - val_loss: 0.2651 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 571/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 19.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2998.0000 - precision: 0.9934 - recall: 0.9937 - val_loss: 0.2659 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 572/4096\n",
      "24/24 - 0s - loss: 0.0117 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.2701 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 573/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 24.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2993.0000 - precision: 0.9914 - recall: 0.9920 - val_loss: 0.2708 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 574/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 32.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2985.0000 - precision: 0.9884 - recall: 0.9894 - val_loss: 0.2637 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 575/4096\n",
      "24/24 - 0s - loss: 0.0154 - fn: 35.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2982.0000 - precision: 0.9874 - recall: 0.9884 - val_loss: 0.2585 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 576/4096\n",
      "24/24 - 0s - loss: 0.0123 - fn: 32.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2985.0000 - precision: 0.9891 - recall: 0.9894 - val_loss: 0.2615 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 577/4096\n",
      "24/24 - 0s - loss: 0.0137 - fn: 36.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2981.0000 - precision: 0.9871 - recall: 0.9881 - val_loss: 0.2713 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 578/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 29.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2988.0000 - precision: 0.9897 - recall: 0.9904 - val_loss: 0.2712 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 579/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 28.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2989.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.2724 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 580/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 26.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2991.0000 - precision: 0.9907 - recall: 0.9914 - val_loss: 0.2720 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 581/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 27.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2990.0000 - precision: 0.9920 - recall: 0.9911 - val_loss: 0.2918 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 582/4096\n",
      "24/24 - 0s - loss: 0.0106 - fn: 35.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2982.0000 - precision: 0.9891 - recall: 0.9884 - val_loss: 0.2806 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 583/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.2755 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 584/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 22.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2995.0000 - precision: 0.9921 - recall: 0.9927 - val_loss: 0.2673 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 585/4096\n",
      "24/24 - 0s - loss: 0.0090 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.2691 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 586/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 19.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2998.0000 - precision: 0.9934 - recall: 0.9937 - val_loss: 0.2737 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 587/4096\n",
      "24/24 - 0s - loss: 0.0059 - fn: 18.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2999.0000 - precision: 0.9930 - recall: 0.9940 - val_loss: 0.2749 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 588/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 29.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2988.0000 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.2737 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 589/4096\n",
      "24/24 - 0s - loss: 0.0119 - fn: 36.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2981.0000 - precision: 0.9891 - recall: 0.9881 - val_loss: 0.2689 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 590/4096\n",
      "24/24 - 0s - loss: 0.0123 - fn: 34.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2983.0000 - precision: 0.9891 - recall: 0.9887 - val_loss: 0.2689 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 591/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 34.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2983.0000 - precision: 0.9881 - recall: 0.9887 - val_loss: 0.2737 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 592/4096\n",
      "24/24 - 0s - loss: 0.0069 - fn: 19.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2998.0000 - precision: 0.9934 - recall: 0.9937 - val_loss: 0.2720 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 593/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 23.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2994.0000 - precision: 0.9934 - recall: 0.9924 - val_loss: 0.2776 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 594/4096\n",
      "24/24 - 0s - loss: 0.0055 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.2786 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 595/4096\n",
      "24/24 - 0s - loss: 0.0075 - fn: 25.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2992.0000 - precision: 0.9924 - recall: 0.9917 - val_loss: 0.2744 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 596/4096\n",
      "24/24 - 0s - loss: 0.0049 - fn: 13.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3004.0000 - precision: 0.9960 - recall: 0.9957 - val_loss: 0.2730 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 597/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 23.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2994.0000 - precision: 0.9920 - recall: 0.9924 - val_loss: 0.2752 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 598/4096\n",
      "24/24 - 0s - loss: 0.0070 - fn: 16.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3001.0000 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.2788 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 599/4096\n",
      "24/24 - 0s - loss: 0.0109 - fn: 20.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2997.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.2766 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 600/4096\n",
      "24/24 - 0s - loss: 0.0177 - fn: 42.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2975.0000 - precision: 0.9861 - recall: 0.9861 - val_loss: 0.2779 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 601/4096\n",
      "24/24 - 0s - loss: 0.0093 - fn: 29.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2988.0000 - precision: 0.9907 - recall: 0.9904 - val_loss: 0.2740 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 602/4096\n",
      "24/24 - 0s - loss: 0.0196 - fn: 56.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2961.0000 - precision: 0.9827 - recall: 0.9814 - val_loss: 0.2702 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 603/4096\n",
      "24/24 - 0s - loss: 0.0104 - fn: 33.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2984.0000 - precision: 0.9881 - recall: 0.9891 - val_loss: 0.2786 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 604/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 37.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2980.0000 - precision: 0.9881 - recall: 0.9877 - val_loss: 0.2805 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 605/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 43.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2974.0000 - precision: 0.9857 - recall: 0.9857 - val_loss: 0.2664 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 606/4096\n",
      "24/24 - 0s - loss: 0.0143 - fn: 46.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2971.0000 - precision: 0.9854 - recall: 0.9848 - val_loss: 0.2716 - val_fn: 14.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 741.0000 - val_precision: 0.9802 - val_recall: 0.9815\n",
      "Epoch 607/4096\n",
      "24/24 - 0s - loss: 0.0138 - fn: 41.0000 - fp: 43.0000 - tn: 5991.0000 - tp: 2976.0000 - precision: 0.9858 - recall: 0.9864 - val_loss: 0.2657 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 608/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 28.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2989.0000 - precision: 0.9897 - recall: 0.9907 - val_loss: 0.2733 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 609/4096\n",
      "24/24 - 0s - loss: 0.0068 - fn: 16.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 3001.0000 - precision: 0.9937 - recall: 0.9947 - val_loss: 0.2698 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 610/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 28.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2989.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.2688 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 611/4096\n",
      "24/24 - 0s - loss: 0.0177 - fn: 50.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2967.0000 - precision: 0.9828 - recall: 0.9834 - val_loss: 0.2691 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 612/4096\n",
      "24/24 - 0s - loss: 0.0209 - fn: 58.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2959.0000 - precision: 0.9801 - recall: 0.9808 - val_loss: 0.2617 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 613/4096\n",
      "24/24 - 0s - loss: 0.0287 - fn: 63.0000 - fp: 62.0000 - tn: 5972.0000 - tp: 2954.0000 - precision: 0.9794 - recall: 0.9791 - val_loss: 0.2808 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 730.0000 - val_precision: 0.9682 - val_recall: 0.9669\n",
      "Epoch 614/4096\n",
      "24/24 - 0s - loss: 0.0226 - fn: 62.0000 - fp: 63.0000 - tn: 5971.0000 - tp: 2955.0000 - precision: 0.9791 - recall: 0.9794 - val_loss: 0.2664 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 615/4096\n",
      "24/24 - 0s - loss: 0.0170 - fn: 49.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2968.0000 - precision: 0.9828 - recall: 0.9838 - val_loss: 0.2809 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 732.0000 - val_precision: 0.9708 - val_recall: 0.9695\n",
      "Epoch 616/4096\n",
      "24/24 - 0s - loss: 0.0174 - fn: 45.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2972.0000 - precision: 0.9835 - recall: 0.9851 - val_loss: 0.2627 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 617/4096\n",
      "24/24 - 0s - loss: 0.0135 - fn: 45.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2972.0000 - precision: 0.9848 - recall: 0.9851 - val_loss: 0.2697 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 618/4096\n",
      "24/24 - 0s - loss: 0.0129 - fn: 38.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2979.0000 - precision: 0.9877 - recall: 0.9874 - val_loss: 0.2685 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 619/4096\n",
      "24/24 - 0s - loss: 0.0128 - fn: 38.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2979.0000 - precision: 0.9874 - recall: 0.9874 - val_loss: 0.2723 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 620/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 22.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2995.0000 - precision: 0.9924 - recall: 0.9927 - val_loss: 0.2611 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 621/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 26.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2991.0000 - precision: 0.9901 - recall: 0.9914 - val_loss: 0.2627 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 622/4096\n",
      "24/24 - 0s - loss: 0.0231 - fn: 40.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2977.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.2759 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 623/4096\n",
      "24/24 - 0s - loss: 0.0329 - fn: 31.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2986.0000 - precision: 0.9891 - recall: 0.9897 - val_loss: 0.2659 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 624/4096\n",
      "24/24 - 0s - loss: 0.0274 - fn: 36.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2981.0000 - precision: 0.9877 - recall: 0.9881 - val_loss: 0.2678 - val_fn: 14.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 741.0000 - val_precision: 0.9789 - val_recall: 0.9815\n",
      "Epoch 625/4096\n",
      "24/24 - 0s - loss: 0.0254 - fn: 26.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2991.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.2706 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 626/4096\n",
      "24/24 - 0s - loss: 0.0344 - fn: 33.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2984.0000 - precision: 0.9897 - recall: 0.9891 - val_loss: 0.2679 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 627/4096\n",
      "24/24 - 0s - loss: 0.0376 - fn: 26.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2991.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.2757 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 628/4096\n",
      "24/24 - 0s - loss: 0.0269 - fn: 20.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2997.0000 - precision: 0.9921 - recall: 0.9934 - val_loss: 0.2705 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 629/4096\n",
      "24/24 - 0s - loss: 0.0151 - fn: 31.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2986.0000 - precision: 0.9901 - recall: 0.9897 - val_loss: 0.2686 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 630/4096\n",
      "24/24 - 0s - loss: 0.0190 - fn: 19.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2998.0000 - precision: 0.9944 - recall: 0.9937 - val_loss: 0.2728 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 631/4096\n",
      "24/24 - 0s - loss: 0.0117 - fn: 23.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2994.0000 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.2756 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 632/4096\n",
      "24/24 - 0s - loss: 0.0152 - fn: 31.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2986.0000 - precision: 0.9891 - recall: 0.9897 - val_loss: 0.2738 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 633/4096\n",
      "24/24 - 0s - loss: 0.0137 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.2852 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 634/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 49.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2968.0000 - precision: 0.9847 - recall: 0.9838 - val_loss: 0.2964 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 635/4096\n",
      "24/24 - 0s - loss: 0.0184 - fn: 50.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2967.0000 - precision: 0.9834 - recall: 0.9834 - val_loss: 0.2873 - val_fn: 22.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 733.0000 - val_precision: 0.9696 - val_recall: 0.9709\n",
      "Epoch 636/4096\n",
      "24/24 - 0s - loss: 0.0239 - fn: 35.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2982.0000 - precision: 0.9874 - recall: 0.9884 - val_loss: 0.2732 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 637/4096\n",
      "24/24 - 0s - loss: 0.0167 - fn: 32.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2985.0000 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.2841 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 638/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 18.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2999.0000 - precision: 0.9927 - recall: 0.9940 - val_loss: 0.2750 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 639/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2690 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 640/4096\n",
      "24/24 - 0s - loss: 0.0208 - fn: 17.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3000.0000 - precision: 0.9947 - recall: 0.9944 - val_loss: 0.2722 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 641/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 18.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2999.0000 - precision: 0.9930 - recall: 0.9940 - val_loss: 0.2713 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 642/4096\n",
      "24/24 - 0s - loss: 0.0128 - fn: 25.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2992.0000 - precision: 0.9920 - recall: 0.9917 - val_loss: 0.2734 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 643/4096\n",
      "24/24 - 0s - loss: 0.0084 - fn: 19.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2998.0000 - precision: 0.9944 - recall: 0.9937 - val_loss: 0.2723 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 644/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 23.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2994.0000 - precision: 0.9937 - recall: 0.9924 - val_loss: 0.2761 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 645/4096\n",
      "24/24 - 0s - loss: 0.0208 - fn: 55.0000 - fp: 56.0000 - tn: 5978.0000 - tp: 2962.0000 - precision: 0.9814 - recall: 0.9818 - val_loss: 0.2798 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 646/4096\n",
      "24/24 - 0s - loss: 0.0168 - fn: 48.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2969.0000 - precision: 0.9838 - recall: 0.9841 - val_loss: 0.2765 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 647/4096\n",
      "24/24 - 0s - loss: 0.0201 - fn: 46.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2971.0000 - precision: 0.9848 - recall: 0.9848 - val_loss: 0.2731 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 648/4096\n",
      "24/24 - 0s - loss: 0.0119 - fn: 44.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2973.0000 - precision: 0.9848 - recall: 0.9854 - val_loss: 0.2702 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 649/4096\n",
      "24/24 - 0s - loss: 0.0162 - fn: 30.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2987.0000 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.2735 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 650/4096\n",
      "24/24 - 0s - loss: 0.0162 - fn: 32.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2985.0000 - precision: 0.9897 - recall: 0.9894 - val_loss: 0.2691 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 651/4096\n",
      "24/24 - 0s - loss: 0.0164 - fn: 31.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2986.0000 - precision: 0.9901 - recall: 0.9897 - val_loss: 0.2773 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 652/4096\n",
      "24/24 - 0s - loss: 0.0101 - fn: 35.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2982.0000 - precision: 0.9877 - recall: 0.9884 - val_loss: 0.2774 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 653/4096\n",
      "24/24 - 0s - loss: 0.0143 - fn: 32.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2985.0000 - precision: 0.9904 - recall: 0.9894 - val_loss: 0.3160 - val_fn: 25.0000 - val_fp: 27.0000 - val_tn: 1483.0000 - val_tp: 730.0000 - val_precision: 0.9643 - val_recall: 0.9669\n",
      "Epoch 654/4096\n",
      "24/24 - 0s - loss: 0.0236 - fn: 60.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2957.0000 - precision: 0.9801 - recall: 0.9801 - val_loss: 0.2637 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 655/4096\n",
      "24/24 - 0s - loss: 0.0104 - fn: 34.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2983.0000 - precision: 0.9884 - recall: 0.9887 - val_loss: 0.2630 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 656/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 31.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2986.0000 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.2656 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 657/4096\n",
      "24/24 - 0s - loss: 0.0132 - fn: 20.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2997.0000 - precision: 0.9927 - recall: 0.9934 - val_loss: 0.2700 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 658/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 20.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2997.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.2762 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 659/4096\n",
      "24/24 - 0s - loss: 0.0097 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.2686 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 660/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 19.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2998.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.2714 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 661/4096\n",
      "24/24 - 0s - loss: 0.0188 - fn: 21.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2996.0000 - precision: 0.9937 - recall: 0.9930 - val_loss: 0.2727 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 662/4096\n",
      "24/24 - 0s - loss: 0.0110 - fn: 15.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3002.0000 - precision: 0.9947 - recall: 0.9950 - val_loss: 0.2722 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 663/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.2764 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 664/4096\n",
      "24/24 - 0s - loss: 0.0087 - fn: 21.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2996.0000 - precision: 0.9921 - recall: 0.9930 - val_loss: 0.2726 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 665/4096\n",
      "24/24 - 0s - loss: 0.0128 - fn: 32.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2985.0000 - precision: 0.9884 - recall: 0.9894 - val_loss: 0.2774 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 666/4096\n",
      "24/24 - 0s - loss: 0.0128 - fn: 31.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2986.0000 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.2797 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 667/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 39.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2978.0000 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.2828 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 668/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 19.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2998.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.2755 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 669/4096\n",
      "24/24 - 0s - loss: 0.0067 - fn: 15.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3002.0000 - precision: 0.9944 - recall: 0.9950 - val_loss: 0.2753 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 670/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 30.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2987.0000 - precision: 0.9907 - recall: 0.9901 - val_loss: 0.2795 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 671/4096\n",
      "24/24 - 0s - loss: 0.0094 - fn: 27.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2990.0000 - precision: 0.9904 - recall: 0.9911 - val_loss: 0.2793 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 672/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 28.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2989.0000 - precision: 0.9917 - recall: 0.9907 - val_loss: 0.2799 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 673/4096\n",
      "24/24 - 0s - loss: 0.0129 - fn: 38.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2979.0000 - precision: 0.9871 - recall: 0.9874 - val_loss: 0.2738 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 674/4096\n",
      "24/24 - 0s - loss: 0.0149 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.2762 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 675/4096\n",
      "24/24 - 0s - loss: 0.0074 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2804 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 676/4096\n",
      "24/24 - 0s - loss: 0.0071 - fn: 22.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2995.0000 - precision: 0.9921 - recall: 0.9927 - val_loss: 0.2793 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 677/4096\n",
      "24/24 - 0s - loss: 0.0120 - fn: 25.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2992.0000 - precision: 0.9924 - recall: 0.9917 - val_loss: 0.3019 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 1482.0000 - val_tp: 727.0000 - val_precision: 0.9629 - val_recall: 0.9629\n",
      "Epoch 678/4096\n",
      "24/24 - 0s - loss: 0.0244 - fn: 74.0000 - fp: 68.0000 - tn: 5966.0000 - tp: 2943.0000 - precision: 0.9774 - recall: 0.9755 - val_loss: 0.2909 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 732.0000 - val_precision: 0.9708 - val_recall: 0.9695\n",
      "Epoch 679/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 40.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2977.0000 - precision: 0.9861 - recall: 0.9867 - val_loss: 0.2785 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 680/4096\n",
      "24/24 - 0s - loss: 0.0110 - fn: 33.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2984.0000 - precision: 0.9881 - recall: 0.9891 - val_loss: 0.2812 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 681/4096\n",
      "24/24 - 0s - loss: 0.0084 - fn: 24.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2993.0000 - precision: 0.9907 - recall: 0.9920 - val_loss: 0.2770 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 682/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 40.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2977.0000 - precision: 0.9871 - recall: 0.9867 - val_loss: 0.2773 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 683/4096\n",
      "24/24 - 0s - loss: 0.0143 - fn: 38.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2979.0000 - precision: 0.9877 - recall: 0.9874 - val_loss: 0.2697 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 684/4096\n",
      "24/24 - 0s - loss: 0.0150 - fn: 50.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2967.0000 - precision: 0.9847 - recall: 0.9834 - val_loss: 0.2805 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 685/4096\n",
      "24/24 - 0s - loss: 0.0143 - fn: 43.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2974.0000 - precision: 0.9854 - recall: 0.9857 - val_loss: 0.2819 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 686/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 36.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2981.0000 - precision: 0.9877 - recall: 0.9881 - val_loss: 0.2785 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 687/4096\n",
      "24/24 - 0s - loss: 0.0053 - fn: 15.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3002.0000 - precision: 0.9954 - recall: 0.9950 - val_loss: 0.2807 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 688/4096\n",
      "24/24 - 0s - loss: 0.0070 - fn: 20.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2997.0000 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.2791 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 689/4096\n",
      "24/24 - 0s - loss: 0.0056 - fn: 12.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3005.0000 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.2899 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 690/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 26.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2991.0000 - precision: 0.9917 - recall: 0.9914 - val_loss: 0.2849 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 691/4096\n",
      "24/24 - 0s - loss: 0.0119 - fn: 37.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2980.0000 - precision: 0.9881 - recall: 0.9877 - val_loss: 0.2835 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 692/4096\n",
      "24/24 - 0s - loss: 0.0061 - fn: 15.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3002.0000 - precision: 0.9944 - recall: 0.9950 - val_loss: 0.2872 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 693/4096\n",
      "24/24 - 0s - loss: 0.0053 - fn: 14.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3003.0000 - precision: 0.9950 - recall: 0.9954 - val_loss: 0.2836 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 694/4096\n",
      "24/24 - 0s - loss: 0.0044 - fn: 13.0000 - fp: 13.0000 - tn: 6021.0000 - tp: 3004.0000 - precision: 0.9957 - recall: 0.9957 - val_loss: 0.2876 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 695/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 23.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2994.0000 - precision: 0.9934 - recall: 0.9924 - val_loss: 0.2913 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 696/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 29.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2988.0000 - precision: 0.9901 - recall: 0.9904 - val_loss: 0.2972 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 697/4096\n",
      "24/24 - 0s - loss: 0.0106 - fn: 29.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2988.0000 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.2793 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 698/4096\n",
      "24/24 - 0s - loss: 0.0061 - fn: 17.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3000.0000 - precision: 0.9947 - recall: 0.9944 - val_loss: 0.2774 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 699/4096\n",
      "24/24 - 0s - loss: 0.0070 - fn: 20.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2997.0000 - precision: 0.9924 - recall: 0.9934 - val_loss: 0.2835 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 700/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.2806 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 701/4096\n",
      "24/24 - 0s - loss: 0.0069 - fn: 20.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2997.0000 - precision: 0.9927 - recall: 0.9934 - val_loss: 0.2748 - val_fn: 12.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 743.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 702/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 32.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2985.0000 - precision: 0.9891 - recall: 0.9894 - val_loss: 0.2923 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 703/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 43.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2974.0000 - precision: 0.9867 - recall: 0.9857 - val_loss: 0.2994 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 704/4096\n",
      "24/24 - 0s - loss: 0.0127 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.2894 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 705/4096\n",
      "24/24 - 0s - loss: 0.0074 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.2905 - val_fn: 13.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 742.0000 - val_precision: 0.9815 - val_recall: 0.9828\n",
      "Epoch 706/4096\n",
      "24/24 - 0s - loss: 0.0077 - fn: 24.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2993.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.2867 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 707/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 27.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2990.0000 - precision: 0.9914 - recall: 0.9911 - val_loss: 0.3132 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 730.0000 - val_precision: 0.9682 - val_recall: 0.9669\n",
      "Epoch 708/4096\n",
      "24/24 - 0s - loss: 0.0110 - fn: 38.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2979.0000 - precision: 0.9881 - recall: 0.9874 - val_loss: 0.2905 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 709/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 17.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 3000.0000 - precision: 0.9937 - recall: 0.9944 - val_loss: 0.2898 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 710/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 38.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2979.0000 - precision: 0.9877 - recall: 0.9874 - val_loss: 0.2999 - val_fn: 20.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 735.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 711/4096\n",
      "24/24 - 0s - loss: 0.0120 - fn: 41.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2976.0000 - precision: 0.9871 - recall: 0.9864 - val_loss: 0.2901 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 712/4096\n",
      "24/24 - 0s - loss: 0.0207 - fn: 32.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2985.0000 - precision: 0.9891 - recall: 0.9894 - val_loss: 0.3225 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 1486.0000 - val_tp: 730.0000 - val_precision: 0.9682 - val_recall: 0.9669\n",
      "Epoch 713/4096\n",
      "24/24 - 0s - loss: 0.0215 - fn: 59.0000 - fp: 60.0000 - tn: 5974.0000 - tp: 2958.0000 - precision: 0.9801 - recall: 0.9804 - val_loss: 0.3009 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 733.0000 - val_precision: 0.9721 - val_recall: 0.9709\n",
      "Epoch 714/4096\n",
      "24/24 - 0s - loss: 0.0139 - fn: 44.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2973.0000 - precision: 0.9848 - recall: 0.9854 - val_loss: 0.2943 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 715/4096\n",
      "24/24 - 0s - loss: 0.0115 - fn: 25.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2992.0000 - precision: 0.9911 - recall: 0.9917 - val_loss: 0.2850 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 716/4096\n",
      "24/24 - 0s - loss: 0.0115 - fn: 28.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2989.0000 - precision: 0.9904 - recall: 0.9907 - val_loss: 0.2931 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 717/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 32.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2985.0000 - precision: 0.9884 - recall: 0.9894 - val_loss: 0.2921 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 718/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.2857 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 719/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 20.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2997.0000 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.2921 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 720/4096\n",
      "24/24 - 0s - loss: 0.0175 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.2905 - val_fn: 16.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 739.0000 - val_precision: 0.9827 - val_recall: 0.9788\n",
      "Epoch 721/4096\n",
      "24/24 - 0s - loss: 0.0477 - fn: 22.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2995.0000 - precision: 0.9944 - recall: 0.9927 - val_loss: 0.2916 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 722/4096\n",
      "24/24 - 0s - loss: 0.0131 - fn: 16.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3001.0000 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.2953 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 723/4096\n",
      "24/24 - 0s - loss: 0.0441 - fn: 30.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2987.0000 - precision: 0.9894 - recall: 0.9901 - val_loss: 0.3049 - val_fn: 20.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 735.0000 - val_precision: 0.9722 - val_recall: 0.9735\n",
      "Epoch 724/4096\n",
      "24/24 - 0s - loss: 0.0246 - fn: 35.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2982.0000 - precision: 0.9881 - recall: 0.9884 - val_loss: 0.2876 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 725/4096\n",
      "24/24 - 0s - loss: 0.0158 - fn: 27.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2990.0000 - precision: 0.9907 - recall: 0.9911 - val_loss: 0.2858 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 726/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 19.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2998.0000 - precision: 0.9934 - recall: 0.9937 - val_loss: 0.2822 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 727/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 24.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2993.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.2800 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 728/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 12.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3005.0000 - precision: 0.9950 - recall: 0.9960 - val_loss: 0.2800 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 729/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 22.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2995.0000 - precision: 0.9930 - recall: 0.9927 - val_loss: 0.2833 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 730/4096\n",
      "24/24 - 0s - loss: 0.0051 - fn: 10.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3007.0000 - precision: 0.9960 - recall: 0.9967 - val_loss: 0.2854 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 731/4096\n",
      "24/24 - 0s - loss: 0.0190 - fn: 52.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2965.0000 - precision: 0.9834 - recall: 0.9828 - val_loss: 0.2907 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 732/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 22.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2995.0000 - precision: 0.9934 - recall: 0.9927 - val_loss: 0.3039 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 733.0000 - val_precision: 0.9721 - val_recall: 0.9709\n",
      "Epoch 733/4096\n",
      "24/24 - 0s - loss: 0.0153 - fn: 37.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2980.0000 - precision: 0.9864 - recall: 0.9877 - val_loss: 0.2913 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 734/4096\n",
      "24/24 - 0s - loss: 0.0208 - fn: 31.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2986.0000 - precision: 0.9910 - recall: 0.9897 - val_loss: 0.2903 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 735/4096\n",
      "24/24 - 0s - loss: 0.0170 - fn: 36.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2981.0000 - precision: 0.9881 - recall: 0.9881 - val_loss: 0.2905 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 736/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.2933 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 737/4096\n",
      "24/24 - 0s - loss: 0.0134 - fn: 32.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2985.0000 - precision: 0.9887 - recall: 0.9894 - val_loss: 0.2994 - val_fn: 18.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 737.0000 - val_precision: 0.9788 - val_recall: 0.9762\n",
      "Epoch 738/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2997 - val_fn: 18.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 737.0000 - val_precision: 0.9736 - val_recall: 0.9762\n",
      "Epoch 739/4096\n",
      "24/24 - 0s - loss: 0.0200 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.3014 - val_fn: 20.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 735.0000 - val_precision: 0.9722 - val_recall: 0.9735\n",
      "Epoch 740/4096\n",
      "24/24 - 0s - loss: 0.0362 - fn: 34.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2983.0000 - precision: 0.9877 - recall: 0.9887 - val_loss: 0.2932 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 741/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.2956 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 742/4096\n",
      "24/24 - 0s - loss: 0.0325 - fn: 25.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2992.0000 - precision: 0.9914 - recall: 0.9917 - val_loss: 0.2904 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 743/4096\n",
      "24/24 - 0s - loss: 0.0221 - fn: 36.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2981.0000 - precision: 0.9881 - recall: 0.9881 - val_loss: 0.2870 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 744/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 27.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2990.0000 - precision: 0.9914 - recall: 0.9911 - val_loss: 0.2937 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 745/4096\n",
      "24/24 - 0s - loss: 0.0077 - fn: 19.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2998.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.2943 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 746/4096\n",
      "24/24 - 0s - loss: 0.0153 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.2869 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 747/4096\n",
      "24/24 - 0s - loss: 0.0136 - fn: 29.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2988.0000 - precision: 0.9891 - recall: 0.9904 - val_loss: 0.2992 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 748/4096\n",
      "24/24 - 0s - loss: 0.0125 - fn: 35.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2982.0000 - precision: 0.9868 - recall: 0.9884 - val_loss: 0.2957 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 749/4096\n",
      "24/24 - 0s - loss: 0.0153 - fn: 31.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2986.0000 - precision: 0.9887 - recall: 0.9897 - val_loss: 0.2894 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 750/4096\n",
      "24/24 - 0s - loss: 0.0074 - fn: 16.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 3001.0000 - precision: 0.9934 - recall: 0.9947 - val_loss: 0.2958 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 751/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.2947 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 752/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 20.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2997.0000 - precision: 0.9930 - recall: 0.9934 - val_loss: 0.2898 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 753/4096\n",
      "24/24 - 0s - loss: 0.0084 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.2872 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 754/4096\n",
      "24/24 - 0s - loss: 0.0075 - fn: 20.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 2997.0000 - precision: 0.9947 - recall: 0.9934 - val_loss: 0.2887 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 755/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 19.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2998.0000 - precision: 0.9927 - recall: 0.9937 - val_loss: 0.2930 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 756/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 20.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2997.0000 - precision: 0.9944 - recall: 0.9934 - val_loss: 0.2951 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 757/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 17.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3000.0000 - precision: 0.9947 - recall: 0.9944 - val_loss: 0.2942 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 758/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 22.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2995.0000 - precision: 0.9937 - recall: 0.9927 - val_loss: 0.2965 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 759/4096\n",
      "24/24 - 0s - loss: 0.0036 - fn: 14.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3003.0000 - precision: 0.9960 - recall: 0.9954 - val_loss: 0.2951 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 760/4096\n",
      "24/24 - 0s - loss: 0.0040 - fn: 15.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3002.0000 - precision: 0.9954 - recall: 0.9950 - val_loss: 0.2950 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 761/4096\n",
      "24/24 - 0s - loss: 0.0047 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.2959 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 762/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 35.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2982.0000 - precision: 0.9891 - recall: 0.9884 - val_loss: 0.3016 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 763/4096\n",
      "24/24 - 0s - loss: 0.0197 - fn: 56.0000 - fp: 58.0000 - tn: 5976.0000 - tp: 2961.0000 - precision: 0.9808 - recall: 0.9814 - val_loss: 0.2923 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 764/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 23.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2994.0000 - precision: 0.9920 - recall: 0.9924 - val_loss: 0.2939 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 765/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 34.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2983.0000 - precision: 0.9884 - recall: 0.9887 - val_loss: 0.2899 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 766/4096\n",
      "24/24 - 0s - loss: 0.0127 - fn: 34.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2983.0000 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.2882 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 767/4096\n",
      "24/24 - 0s - loss: 0.0067 - fn: 20.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2997.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.2924 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 768/4096\n",
      "24/24 - 0s - loss: 0.0146 - fn: 38.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2979.0000 - precision: 0.9874 - recall: 0.9874 - val_loss: 0.3140 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 769/4096\n",
      "24/24 - 0s - loss: 0.0135 - fn: 37.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2980.0000 - precision: 0.9881 - recall: 0.9877 - val_loss: 0.3034 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 770/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.3045 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 771/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.2959 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 772/4096\n",
      "24/24 - 0s - loss: 0.0054 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.2968 - val_fn: 17.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 738.0000 - val_precision: 0.9814 - val_recall: 0.9775\n",
      "Epoch 773/4096\n",
      "24/24 - 0s - loss: 0.0160 - fn: 43.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2974.0000 - precision: 0.9854 - recall: 0.9857 - val_loss: 0.2998 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 774/4096\n",
      "24/24 - 0s - loss: 0.0061 - fn: 20.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2997.0000 - precision: 0.9940 - recall: 0.9934 - val_loss: 0.2991 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 775/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.2938 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 776/4096\n",
      "24/24 - 0s - loss: 0.0152 - fn: 34.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2983.0000 - precision: 0.9891 - recall: 0.9887 - val_loss: 0.2970 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 777/4096\n",
      "24/24 - 0s - loss: 0.0091 - fn: 21.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2996.0000 - precision: 0.9934 - recall: 0.9930 - val_loss: 0.2979 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 778/4096\n",
      "24/24 - 0s - loss: 0.0169 - fn: 40.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2977.0000 - precision: 0.9861 - recall: 0.9867 - val_loss: 0.3001 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 779/4096\n",
      "24/24 - 0s - loss: 0.0155 - fn: 50.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2967.0000 - precision: 0.9825 - recall: 0.9834 - val_loss: 0.3010 - val_fn: 15.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 740.0000 - val_precision: 0.9775 - val_recall: 0.9801\n",
      "Epoch 780/4096\n",
      "24/24 - 0s - loss: 0.0068 - fn: 22.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2995.0000 - precision: 0.9924 - recall: 0.9927 - val_loss: 0.2997 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 781/4096\n",
      "24/24 - 0s - loss: 0.0061 - fn: 18.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2999.0000 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.3022 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 782/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 19.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2998.0000 - precision: 0.9924 - recall: 0.9937 - val_loss: 0.3021 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 783/4096\n",
      "24/24 - 0s - loss: 0.0268 - fn: 32.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2985.0000 - precision: 0.9891 - recall: 0.9894 - val_loss: 0.3164 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 784/4096\n",
      "24/24 - 0s - loss: 0.0241 - fn: 26.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2991.0000 - precision: 0.9911 - recall: 0.9914 - val_loss: 0.3174 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 785/4096\n",
      "24/24 - 0s - loss: 0.0184 - fn: 25.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2992.0000 - precision: 0.9911 - recall: 0.9917 - val_loss: 0.3104 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 786/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 23.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2994.0000 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.3091 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 787/4096\n",
      "24/24 - 0s - loss: 0.0234 - fn: 38.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2979.0000 - precision: 0.9871 - recall: 0.9874 - val_loss: 0.2947 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 788/4096\n",
      "24/24 - 0s - loss: 0.0128 - fn: 29.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2988.0000 - precision: 0.9897 - recall: 0.9904 - val_loss: 0.2941 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 789/4096\n",
      "24/24 - 0s - loss: 0.0084 - fn: 18.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2999.0000 - precision: 0.9937 - recall: 0.9940 - val_loss: 0.2990 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 790/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 15.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3002.0000 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.2949 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 791/4096\n",
      "24/24 - 0s - loss: 0.0117 - fn: 28.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2989.0000 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.2988 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 792/4096\n",
      "24/24 - 0s - loss: 0.0166 - fn: 49.0000 - fp: 53.0000 - tn: 5981.0000 - tp: 2968.0000 - precision: 0.9825 - recall: 0.9838 - val_loss: 0.3033 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 793/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 38.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2979.0000 - precision: 0.9877 - recall: 0.9874 - val_loss: 0.2965 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 794/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 22.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2995.0000 - precision: 0.9924 - recall: 0.9927 - val_loss: 0.2966 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 795/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 21.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2996.0000 - precision: 0.9921 - recall: 0.9930 - val_loss: 0.3030 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 796/4096\n",
      "24/24 - 0s - loss: 0.0065 - fn: 17.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 3000.0000 - precision: 0.9940 - recall: 0.9944 - val_loss: 0.3015 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 797/4096\n",
      "24/24 - 0s - loss: 0.0229 - fn: 20.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2997.0000 - precision: 0.9924 - recall: 0.9934 - val_loss: 0.2977 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 798/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 21.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2996.0000 - precision: 0.9937 - recall: 0.9930 - val_loss: 0.3001 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 799/4096\n",
      "24/24 - 0s - loss: 0.0110 - fn: 21.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2996.0000 - precision: 0.9940 - recall: 0.9930 - val_loss: 0.3039 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 800/4096\n",
      "24/24 - 0s - loss: 0.0084 - fn: 21.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2996.0000 - precision: 0.9917 - recall: 0.9930 - val_loss: 0.3106 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 801/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.3113 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 802/4096\n",
      "24/24 - 0s - loss: 0.0111 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.3096 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 803/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 27.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2990.0000 - precision: 0.9907 - recall: 0.9911 - val_loss: 0.3022 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 804/4096\n",
      "24/24 - 0s - loss: 0.0059 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.3061 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 805/4096\n",
      "24/24 - 0s - loss: 0.0154 - fn: 39.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2978.0000 - precision: 0.9861 - recall: 0.9871 - val_loss: 0.3012 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 806/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 27.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2990.0000 - precision: 0.9904 - recall: 0.9911 - val_loss: 0.2989 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 807/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.3050 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 808/4096\n",
      "24/24 - 0s - loss: 0.0054 - fn: 23.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2994.0000 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.3029 - val_fn: 15.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 740.0000 - val_precision: 0.9788 - val_recall: 0.9801\n",
      "Epoch 809/4096\n",
      "24/24 - 0s - loss: 0.0068 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.3051 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 810/4096\n",
      "24/24 - 0s - loss: 0.0101 - fn: 24.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2993.0000 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.3027 - val_fn: 15.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 740.0000 - val_precision: 0.9814 - val_recall: 0.9801\n",
      "Epoch 811/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 24.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2993.0000 - precision: 0.9914 - recall: 0.9920 - val_loss: 0.3048 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 812/4096\n",
      "24/24 - 0s - loss: 0.0053 - fn: 17.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3000.0000 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.3078 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 813/4096\n",
      "24/24 - 0s - loss: 0.0042 - fn: 14.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3003.0000 - precision: 0.9960 - recall: 0.9954 - val_loss: 0.3084 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 814/4096\n",
      "24/24 - 0s - loss: 0.0058 - fn: 18.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2999.0000 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.3089 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 815/4096\n",
      "24/24 - 0s - loss: 0.0052 - fn: 12.0000 - fp: 13.0000 - tn: 6021.0000 - tp: 3005.0000 - precision: 0.9957 - recall: 0.9960 - val_loss: 0.3111 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 816/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 16.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3001.0000 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.3144 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 817/4096\n",
      "24/24 - 0s - loss: 0.0059 - fn: 15.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3002.0000 - precision: 0.9944 - recall: 0.9950 - val_loss: 0.3151 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 818/4096\n",
      "24/24 - 0s - loss: 0.0055 - fn: 16.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3001.0000 - precision: 0.9954 - recall: 0.9947 - val_loss: 0.3210 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 819/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 23.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2994.0000 - precision: 0.9920 - recall: 0.9924 - val_loss: 0.3290 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 820/4096\n",
      "24/24 - 0s - loss: 0.0295 - fn: 52.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2965.0000 - precision: 0.9828 - recall: 0.9828 - val_loss: 0.3281 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 821/4096\n",
      "24/24 - 0s - loss: 0.0270 - fn: 75.0000 - fp: 77.0000 - tn: 5957.0000 - tp: 2942.0000 - precision: 0.9745 - recall: 0.9751 - val_loss: 0.3339 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 1485.0000 - val_tp: 730.0000 - val_precision: 0.9669 - val_recall: 0.9669\n",
      "Epoch 822/4096\n",
      "24/24 - 0s - loss: 0.0141 - fn: 44.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2973.0000 - precision: 0.9838 - recall: 0.9854 - val_loss: 0.2982 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 823/4096\n",
      "24/24 - 0s - loss: 0.0120 - fn: 35.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2982.0000 - precision: 0.9877 - recall: 0.9884 - val_loss: 0.3017 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 824/4096\n",
      "24/24 - 0s - loss: 0.0078 - fn: 25.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2992.0000 - precision: 0.9907 - recall: 0.9917 - val_loss: 0.3009 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 825/4096\n",
      "24/24 - 0s - loss: 0.0049 - fn: 19.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2998.0000 - precision: 0.9930 - recall: 0.9937 - val_loss: 0.3077 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 826/4096\n",
      "24/24 - 0s - loss: 0.0055 - fn: 11.0000 - fp: 10.0000 - tn: 6024.0000 - tp: 3006.0000 - precision: 0.9967 - recall: 0.9964 - val_loss: 0.3088 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 827/4096\n",
      "24/24 - 0s - loss: 0.0051 - fn: 15.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3002.0000 - precision: 0.9947 - recall: 0.9950 - val_loss: 0.3112 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 828/4096\n",
      "24/24 - 0s - loss: 0.0112 - fn: 37.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2980.0000 - precision: 0.9884 - recall: 0.9877 - val_loss: 0.3169 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 829/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 18.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 2999.0000 - precision: 0.9947 - recall: 0.9940 - val_loss: 0.3135 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 830/4096\n",
      "24/24 - 0s - loss: 0.0050 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.3138 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 831/4096\n",
      "24/24 - 0s - loss: 0.0074 - fn: 24.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2993.0000 - precision: 0.9924 - recall: 0.9920 - val_loss: 0.3136 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 832/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 18.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2999.0000 - precision: 0.9937 - recall: 0.9940 - val_loss: 0.3112 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 833/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 15.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3002.0000 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.3152 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 834/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 15.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3002.0000 - precision: 0.9944 - recall: 0.9950 - val_loss: 0.3154 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 835/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 27.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2990.0000 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.3223 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 836/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.3096 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 837/4096\n",
      "24/24 - 0s - loss: 0.0091 - fn: 25.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2992.0000 - precision: 0.9920 - recall: 0.9917 - val_loss: 0.3260 - val_fn: 21.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 734.0000 - val_precision: 0.9748 - val_recall: 0.9722\n",
      "Epoch 838/4096\n",
      "24/24 - 0s - loss: 0.0177 - fn: 43.0000 - fp: 45.0000 - tn: 5989.0000 - tp: 2974.0000 - precision: 0.9851 - recall: 0.9857 - val_loss: 0.3660 - val_fn: 34.0000 - val_fp: 33.0000 - val_tn: 1477.0000 - val_tp: 721.0000 - val_precision: 0.9562 - val_recall: 0.9550\n",
      "Epoch 839/4096\n",
      "24/24 - 0s - loss: 0.0181 - fn: 47.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2970.0000 - precision: 0.9841 - recall: 0.9844 - val_loss: 0.3156 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 840/4096\n",
      "24/24 - 0s - loss: 0.0177 - fn: 49.0000 - fp: 52.0000 - tn: 5982.0000 - tp: 2968.0000 - precision: 0.9828 - recall: 0.9838 - val_loss: 0.3237 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 841/4096\n",
      "24/24 - 0s - loss: 0.0180 - fn: 50.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2967.0000 - precision: 0.9834 - recall: 0.9834 - val_loss: 0.3059 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 842/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 35.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2982.0000 - precision: 0.9877 - recall: 0.9884 - val_loss: 0.3076 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 843/4096\n",
      "24/24 - 0s - loss: 0.0095 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.3000 - val_fn: 15.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 740.0000 - val_precision: 0.9827 - val_recall: 0.9801\n",
      "Epoch 844/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 34.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2983.0000 - precision: 0.9884 - recall: 0.9887 - val_loss: 0.3126 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 845/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 17.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 3000.0000 - precision: 0.9937 - recall: 0.9944 - val_loss: 0.3164 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 846/4096\n",
      "24/24 - 0s - loss: 0.0061 - fn: 20.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2997.0000 - precision: 0.9930 - recall: 0.9934 - val_loss: 0.3169 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 847/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 23.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2994.0000 - precision: 0.9920 - recall: 0.9924 - val_loss: 0.3196 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 848/4096\n",
      "24/24 - 0s - loss: 0.0111 - fn: 26.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2991.0000 - precision: 0.9911 - recall: 0.9914 - val_loss: 0.3298 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 849/4096\n",
      "24/24 - 0s - loss: 0.0167 - fn: 38.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2979.0000 - precision: 0.9871 - recall: 0.9874 - val_loss: 0.3563 - val_fn: 27.0000 - val_fp: 29.0000 - val_tn: 1481.0000 - val_tp: 728.0000 - val_precision: 0.9617 - val_recall: 0.9642\n",
      "Epoch 850/4096\n",
      "24/24 - 0s - loss: 0.0158 - fn: 44.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2973.0000 - precision: 0.9831 - recall: 0.9854 - val_loss: 0.3256 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 851/4096\n",
      "24/24 - 0s - loss: 0.0108 - fn: 26.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2991.0000 - precision: 0.9904 - recall: 0.9914 - val_loss: 0.3190 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 852/4096\n",
      "24/24 - 0s - loss: 0.0052 - fn: 15.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3002.0000 - precision: 0.9960 - recall: 0.9950 - val_loss: 0.3182 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 853/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.3249 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 854/4096\n",
      "24/24 - 0s - loss: 0.0079 - fn: 25.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2992.0000 - precision: 0.9927 - recall: 0.9917 - val_loss: 0.3290 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 855/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 28.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2989.0000 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.3126 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 856/4096\n",
      "24/24 - 0s - loss: 0.0107 - fn: 32.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2985.0000 - precision: 0.9887 - recall: 0.9894 - val_loss: 0.3111 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 857/4096\n",
      "24/24 - 0s - loss: 0.0089 - fn: 21.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2996.0000 - precision: 0.9924 - recall: 0.9930 - val_loss: 0.3138 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 858/4096\n",
      "24/24 - 0s - loss: 0.0273 - fn: 21.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2996.0000 - precision: 0.9924 - recall: 0.9930 - val_loss: 0.3158 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 859/4096\n",
      "24/24 - 0s - loss: 0.0075 - fn: 20.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2997.0000 - precision: 0.9940 - recall: 0.9934 - val_loss: 0.3197 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 860/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 23.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2994.0000 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.3197 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 861/4096\n",
      "24/24 - 0s - loss: 0.0067 - fn: 20.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2997.0000 - precision: 0.9944 - recall: 0.9934 - val_loss: 0.3207 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 862/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 28.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2989.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.3127 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 863/4096\n",
      "24/24 - 0s - loss: 0.0090 - fn: 31.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2986.0000 - precision: 0.9891 - recall: 0.9897 - val_loss: 0.3056 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 864/4096\n",
      "24/24 - 0s - loss: 0.0047 - fn: 13.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3004.0000 - precision: 0.9960 - recall: 0.9957 - val_loss: 0.3107 - val_fn: 17.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 738.0000 - val_precision: 0.9801 - val_recall: 0.9775\n",
      "Epoch 865/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 16.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3001.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3353 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 866/4096\n",
      "24/24 - 0s - loss: 0.0150 - fn: 52.0000 - fp: 50.0000 - tn: 5984.0000 - tp: 2965.0000 - precision: 0.9834 - recall: 0.9828 - val_loss: 0.3122 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 867/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.3112 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 868/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 20.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2997.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.3222 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 869/4096\n",
      "24/24 - 0s - loss: 0.0091 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.3180 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 870/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 26.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2991.0000 - precision: 0.9920 - recall: 0.9914 - val_loss: 0.3110 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 871/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 20.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2997.0000 - precision: 0.9927 - recall: 0.9934 - val_loss: 0.3161 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 872/4096\n",
      "24/24 - 0s - loss: 0.0171 - fn: 21.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2996.0000 - precision: 0.9934 - recall: 0.9930 - val_loss: 0.3206 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 873/4096\n",
      "24/24 - 0s - loss: 0.0090 - fn: 32.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2985.0000 - precision: 0.9897 - recall: 0.9894 - val_loss: 0.3253 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 874/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 28.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2989.0000 - precision: 0.9920 - recall: 0.9907 - val_loss: 0.3284 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 875/4096\n",
      "24/24 - 0s - loss: 0.0152 - fn: 24.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2993.0000 - precision: 0.9911 - recall: 0.9920 - val_loss: 0.3171 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 876/4096\n",
      "24/24 - 0s - loss: 0.0137 - fn: 39.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2978.0000 - precision: 0.9881 - recall: 0.9871 - val_loss: 0.3141 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 877/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 23.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2994.0000 - precision: 0.9917 - recall: 0.9924 - val_loss: 0.3242 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 878/4096\n",
      "24/24 - 0s - loss: 0.0130 - fn: 36.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2981.0000 - precision: 0.9877 - recall: 0.9881 - val_loss: 0.3153 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 879/4096\n",
      "24/24 - 0s - loss: 0.0261 - fn: 22.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2995.0000 - precision: 0.9930 - recall: 0.9927 - val_loss: 0.3218 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 880/4096\n",
      "24/24 - 0s - loss: 0.0248 - fn: 31.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2986.0000 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.3150 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 881/4096\n",
      "24/24 - 0s - loss: 0.0254 - fn: 48.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2969.0000 - precision: 0.9847 - recall: 0.9841 - val_loss: 0.2964 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 882/4096\n",
      "24/24 - 0s - loss: 0.0243 - fn: 40.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2977.0000 - precision: 0.9867 - recall: 0.9867 - val_loss: 0.3028 - val_fn: 14.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 741.0000 - val_precision: 0.9802 - val_recall: 0.9815\n",
      "Epoch 883/4096\n",
      "24/24 - 0s - loss: 0.0222 - fn: 37.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2980.0000 - precision: 0.9868 - recall: 0.9877 - val_loss: 0.2971 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 884/4096\n",
      "24/24 - 0s - loss: 0.0093 - fn: 13.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3004.0000 - precision: 0.9960 - recall: 0.9957 - val_loss: 0.2989 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 885/4096\n",
      "24/24 - 0s - loss: 0.0187 - fn: 26.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2991.0000 - precision: 0.9901 - recall: 0.9914 - val_loss: 0.3040 - val_fn: 14.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 741.0000 - val_precision: 0.9828 - val_recall: 0.9815\n",
      "Epoch 886/4096\n",
      "24/24 - 0s - loss: 0.0132 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.3169 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 887/4096\n",
      "24/24 - 0s - loss: 0.0154 - fn: 28.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2989.0000 - precision: 0.9904 - recall: 0.9907 - val_loss: 0.3108 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 888/4096\n",
      "24/24 - 0s - loss: 0.0093 - fn: 22.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2995.0000 - precision: 0.9930 - recall: 0.9927 - val_loss: 0.3124 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 889/4096\n",
      "24/24 - 0s - loss: 0.0154 - fn: 20.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2997.0000 - precision: 0.9940 - recall: 0.9934 - val_loss: 0.3294 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 890/4096\n",
      "24/24 - 0s - loss: 0.0312 - fn: 44.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2973.0000 - precision: 0.9864 - recall: 0.9854 - val_loss: 0.3034 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 891/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 28.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2989.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.3089 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 892/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 29.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2988.0000 - precision: 0.9907 - recall: 0.9904 - val_loss: 0.3070 - val_fn: 12.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 743.0000 - val_precision: 0.9841 - val_recall: 0.9841\n",
      "Epoch 893/4096\n",
      "24/24 - 0s - loss: 0.0117 - fn: 26.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2991.0000 - precision: 0.9904 - recall: 0.9914 - val_loss: 0.3137 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 894/4096\n",
      "24/24 - 0s - loss: 0.0082 - fn: 16.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3001.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3172 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 895/4096\n",
      "24/24 - 0s - loss: 0.0089 - fn: 15.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3002.0000 - precision: 0.9947 - recall: 0.9950 - val_loss: 0.3145 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 896/4096\n",
      "24/24 - 0s - loss: 0.0115 - fn: 23.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2994.0000 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.3139 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 897/4096\n",
      "24/24 - 0s - loss: 0.0316 - fn: 23.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2994.0000 - precision: 0.9924 - recall: 0.9924 - val_loss: 0.3296 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 898/4096\n",
      "24/24 - 0s - loss: 0.0292 - fn: 25.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2992.0000 - precision: 0.9924 - recall: 0.9917 - val_loss: 0.3346 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 899/4096\n",
      "24/24 - 0s - loss: 0.0142 - fn: 28.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2989.0000 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.3352 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 900/4096\n",
      "24/24 - 0s - loss: 0.0111 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.3208 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 901/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 31.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2986.0000 - precision: 0.9901 - recall: 0.9897 - val_loss: 0.3232 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 902/4096\n",
      "24/24 - 0s - loss: 0.0100 - fn: 18.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2999.0000 - precision: 0.9937 - recall: 0.9940 - val_loss: 0.3170 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 903/4096\n",
      "24/24 - 0s - loss: 0.0174 - fn: 24.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2993.0000 - precision: 0.9924 - recall: 0.9920 - val_loss: 0.3245 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 904/4096\n",
      "24/24 - 0s - loss: 0.0126 - fn: 27.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2990.0000 - precision: 0.9907 - recall: 0.9911 - val_loss: 0.3288 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 905/4096\n",
      "24/24 - 0s - loss: 0.0225 - fn: 41.0000 - fp: 44.0000 - tn: 5990.0000 - tp: 2976.0000 - precision: 0.9854 - recall: 0.9864 - val_loss: 0.3317 - val_fn: 19.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 736.0000 - val_precision: 0.9735 - val_recall: 0.9748\n",
      "Epoch 906/4096\n",
      "24/24 - 0s - loss: 0.0203 - fn: 62.0000 - fp: 61.0000 - tn: 5973.0000 - tp: 2955.0000 - precision: 0.9798 - recall: 0.9794 - val_loss: 0.3124 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 907/4096\n",
      "24/24 - 0s - loss: 0.0124 - fn: 36.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2981.0000 - precision: 0.9881 - recall: 0.9881 - val_loss: 0.3130 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 908/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 33.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2984.0000 - precision: 0.9904 - recall: 0.9891 - val_loss: 0.3118 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 909/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 25.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2992.0000 - precision: 0.9904 - recall: 0.9917 - val_loss: 0.3141 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 910/4096\n",
      "24/24 - 0s - loss: 0.0159 - fn: 44.0000 - fp: 46.0000 - tn: 5988.0000 - tp: 2973.0000 - precision: 0.9848 - recall: 0.9854 - val_loss: 0.3203 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 911/4096\n",
      "24/24 - 0s - loss: 0.0095 - fn: 28.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2989.0000 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.3173 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 912/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 18.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2999.0000 - precision: 0.9927 - recall: 0.9940 - val_loss: 0.3246 - val_fn: 20.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 735.0000 - val_precision: 0.9709 - val_recall: 0.9735\n",
      "Epoch 913/4096\n",
      "24/24 - 0s - loss: 0.0090 - fn: 29.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2988.0000 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.3178 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 914/4096\n",
      "24/24 - 0s - loss: 0.0053 - fn: 16.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3001.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3172 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 915/4096\n",
      "24/24 - 0s - loss: 0.0054 - fn: 16.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3001.0000 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.3178 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 916/4096\n",
      "24/24 - 0s - loss: 0.0047 - fn: 14.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3003.0000 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.3201 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 917/4096\n",
      "24/24 - 0s - loss: 0.0095 - fn: 29.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2988.0000 - precision: 0.9907 - recall: 0.9904 - val_loss: 0.3211 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 918/4096\n",
      "24/24 - 0s - loss: 0.0054 - fn: 14.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3003.0000 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.3241 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 919/4096\n",
      "24/24 - 0s - loss: 0.0050 - fn: 12.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3005.0000 - precision: 0.9954 - recall: 0.9960 - val_loss: 0.3208 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 920/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 24.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2993.0000 - precision: 0.9914 - recall: 0.9920 - val_loss: 0.3220 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 921/4096\n",
      "24/24 - 0s - loss: 0.0079 - fn: 25.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2992.0000 - precision: 0.9914 - recall: 0.9917 - val_loss: 0.3140 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 922/4096\n",
      "24/24 - 0s - loss: 0.0047 - fn: 14.0000 - fp: 13.0000 - tn: 6021.0000 - tp: 3003.0000 - precision: 0.9957 - recall: 0.9954 - val_loss: 0.3245 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 923/4096\n",
      "24/24 - 0s - loss: 0.0058 - fn: 20.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2997.0000 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.3203 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 924/4096\n",
      "24/24 - 0s - loss: 0.0048 - fn: 15.0000 - fp: 13.0000 - tn: 6021.0000 - tp: 3002.0000 - precision: 0.9957 - recall: 0.9950 - val_loss: 0.3214 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 925/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 17.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 3000.0000 - precision: 0.9937 - recall: 0.9944 - val_loss: 0.3178 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 926/4096\n",
      "24/24 - 0s - loss: 0.0071 - fn: 23.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2994.0000 - precision: 0.9917 - recall: 0.9924 - val_loss: 0.3124 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 927/4096\n",
      "24/24 - 0s - loss: 0.0079 - fn: 24.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2993.0000 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.3127 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 928/4096\n",
      "24/24 - 0s - loss: 0.0131 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.3144 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 929/4096\n",
      "24/24 - 0s - loss: 0.0159 - fn: 31.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2986.0000 - precision: 0.9901 - recall: 0.9897 - val_loss: 0.3260 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 930/4096\n",
      "24/24 - 0s - loss: 0.0091 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.3221 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 931/4096\n",
      "24/24 - 0s - loss: 0.0064 - fn: 14.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3003.0000 - precision: 0.9954 - recall: 0.9954 - val_loss: 0.3180 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 932/4096\n",
      "24/24 - 0s - loss: 0.0065 - fn: 21.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2996.0000 - precision: 0.9924 - recall: 0.9930 - val_loss: 0.3182 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 933/4096\n",
      "24/24 - 0s - loss: 0.0047 - fn: 15.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3002.0000 - precision: 0.9947 - recall: 0.9950 - val_loss: 0.3201 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 934/4096\n",
      "24/24 - 0s - loss: 0.0048 - fn: 18.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2999.0000 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.3238 - val_fn: 13.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 742.0000 - val_precision: 0.9828 - val_recall: 0.9828\n",
      "Epoch 935/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 30.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2987.0000 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.3234 - val_fn: 18.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 737.0000 - val_precision: 0.9801 - val_recall: 0.9762\n",
      "Epoch 936/4096\n",
      "24/24 - 0s - loss: 0.0075 - fn: 28.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2989.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.3238 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 937/4096\n",
      "24/24 - 0s - loss: 0.0094 - fn: 27.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2990.0000 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.3289 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 938/4096\n",
      "24/24 - 0s - loss: 0.0079 - fn: 24.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2993.0000 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.3239 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 939/4096\n",
      "24/24 - 0s - loss: 0.0064 - fn: 17.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 3000.0000 - precision: 0.9934 - recall: 0.9944 - val_loss: 0.3274 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 940/4096\n",
      "24/24 - 0s - loss: 0.0091 - fn: 24.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2993.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.3201 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 941/4096\n",
      "24/24 - 0s - loss: 0.0102 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.3278 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 942/4096\n",
      "24/24 - 0s - loss: 0.0108 - fn: 30.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2987.0000 - precision: 0.9910 - recall: 0.9901 - val_loss: 0.3317 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 943/4096\n",
      "24/24 - 0s - loss: 0.0280 - fn: 26.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2991.0000 - precision: 0.9911 - recall: 0.9914 - val_loss: 0.3255 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 944/4096\n",
      "24/24 - 0s - loss: 0.0257 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.3230 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 945/4096\n",
      "24/24 - 0s - loss: 0.0202 - fn: 21.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2996.0000 - precision: 0.9917 - recall: 0.9930 - val_loss: 0.3340 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 946/4096\n",
      "24/24 - 0s - loss: 0.0151 - fn: 19.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2998.0000 - precision: 0.9934 - recall: 0.9937 - val_loss: 0.3295 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 947/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 21.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2996.0000 - precision: 0.9934 - recall: 0.9930 - val_loss: 0.3258 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 948/4096\n",
      "24/24 - 0s - loss: 0.0188 - fn: 16.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3001.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3309 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 949/4096\n",
      "24/24 - 0s - loss: 0.0320 - fn: 44.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2973.0000 - precision: 0.9844 - recall: 0.9854 - val_loss: 0.3357 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 950/4096\n",
      "24/24 - 0s - loss: 0.0145 - fn: 37.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2980.0000 - precision: 0.9864 - recall: 0.9877 - val_loss: 0.3240 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 951/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 28.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2989.0000 - precision: 0.9904 - recall: 0.9907 - val_loss: 0.3216 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 952/4096\n",
      "24/24 - 0s - loss: 0.0116 - fn: 27.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2990.0000 - precision: 0.9920 - recall: 0.9911 - val_loss: 0.3206 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n",
      "Epoch 953/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.3084 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 954/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 31.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2986.0000 - precision: 0.9904 - recall: 0.9897 - val_loss: 0.3114 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 955/4096\n",
      "24/24 - 0s - loss: 0.0080 - fn: 25.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2992.0000 - precision: 0.9917 - recall: 0.9917 - val_loss: 0.3189 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 956/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 18.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 2999.0000 - precision: 0.9947 - recall: 0.9940 - val_loss: 0.3205 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 957/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 11.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3006.0000 - precision: 0.9960 - recall: 0.9964 - val_loss: 0.3168 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 958/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 17.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3000.0000 - precision: 0.9954 - recall: 0.9944 - val_loss: 0.3205 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 959/4096\n",
      "24/24 - 0s - loss: 0.0115 - fn: 22.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2995.0000 - precision: 0.9930 - recall: 0.9927 - val_loss: 0.3328 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 960/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 26.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2991.0000 - precision: 0.9924 - recall: 0.9914 - val_loss: 0.3300 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 961/4096\n",
      "24/24 - 0s - loss: 0.0060 - fn: 13.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3004.0000 - precision: 0.9954 - recall: 0.9957 - val_loss: 0.3253 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 962/4096\n",
      "24/24 - 0s - loss: 0.0074 - fn: 19.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2998.0000 - precision: 0.9937 - recall: 0.9937 - val_loss: 0.3242 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 963/4096\n",
      "24/24 - 0s - loss: 0.0139 - fn: 34.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2983.0000 - precision: 0.9894 - recall: 0.9887 - val_loss: 0.3209 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 964/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 27.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2990.0000 - precision: 0.9904 - recall: 0.9911 - val_loss: 0.3299 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 965/4096\n",
      "24/24 - 0s - loss: 0.0091 - fn: 26.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2991.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.3143 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 966/4096\n",
      "24/24 - 0s - loss: 0.0095 - fn: 26.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2991.0000 - precision: 0.9904 - recall: 0.9914 - val_loss: 0.3169 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 967/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 23.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2994.0000 - precision: 0.9920 - recall: 0.9924 - val_loss: 0.3190 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 968/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 19.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2998.0000 - precision: 0.9924 - recall: 0.9937 - val_loss: 0.3157 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 969/4096\n",
      "24/24 - 0s - loss: 0.0085 - fn: 24.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2993.0000 - precision: 0.9924 - recall: 0.9920 - val_loss: 0.3359 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 732.0000 - val_precision: 0.9708 - val_recall: 0.9695\n",
      "Epoch 970/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 20.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2997.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.3297 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 971/4096\n",
      "24/24 - 0s - loss: 0.0090 - fn: 33.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2984.0000 - precision: 0.9884 - recall: 0.9891 - val_loss: 0.3219 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 972/4096\n",
      "24/24 - 0s - loss: 0.0140 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.3161 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 973/4096\n",
      "24/24 - 0s - loss: 0.0079 - fn: 22.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2995.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.3166 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 974/4096\n",
      "24/24 - 0s - loss: 0.0101 - fn: 35.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2982.0000 - precision: 0.9887 - recall: 0.9884 - val_loss: 0.3282 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 975/4096\n",
      "24/24 - 0s - loss: 0.0132 - fn: 36.0000 - fp: 39.0000 - tn: 5995.0000 - tp: 2981.0000 - precision: 0.9871 - recall: 0.9881 - val_loss: 0.3275 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 976/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 16.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 3001.0000 - precision: 0.9937 - recall: 0.9947 - val_loss: 0.3268 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 977/4096\n",
      "24/24 - 0s - loss: 0.0046 - fn: 12.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3005.0000 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.3228 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 978/4096\n",
      "24/24 - 0s - loss: 0.0047 - fn: 12.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3005.0000 - precision: 0.9960 - recall: 0.9960 - val_loss: 0.3296 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 979/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 19.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2998.0000 - precision: 0.9930 - recall: 0.9937 - val_loss: 0.3285 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 980/4096\n",
      "24/24 - 0s - loss: 0.0054 - fn: 17.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 3000.0000 - precision: 0.9940 - recall: 0.9944 - val_loss: 0.3313 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 981/4096\n",
      "24/24 - 0s - loss: 0.0086 - fn: 25.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2992.0000 - precision: 0.9914 - recall: 0.9917 - val_loss: 0.3166 - val_fn: 13.0000 - val_fp: 13.0000 - val_tn: 1497.0000 - val_tp: 742.0000 - val_precision: 0.9828 - val_recall: 0.9828\n",
      "Epoch 982/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 20.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2997.0000 - precision: 0.9930 - recall: 0.9934 - val_loss: 0.3236 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 983/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.3276 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 984/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.3424 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 985/4096\n",
      "24/24 - 0s - loss: 0.0060 - fn: 22.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2995.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.3288 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 986/4096\n",
      "24/24 - 0s - loss: 0.0058 - fn: 20.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2997.0000 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.3317 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 987/4096\n",
      "24/24 - 0s - loss: 0.0055 - fn: 18.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 2999.0000 - precision: 0.9947 - recall: 0.9940 - val_loss: 0.3308 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 988/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.3303 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 989/4096\n",
      "24/24 - 0s - loss: 0.0051 - fn: 16.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3001.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3356 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 990/4096\n",
      "24/24 - 0s - loss: 0.0046 - fn: 16.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3001.0000 - precision: 0.9954 - recall: 0.9947 - val_loss: 0.3332 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 991/4096\n",
      "24/24 - 0s - loss: 0.0049 - fn: 16.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3001.0000 - precision: 0.9944 - recall: 0.9947 - val_loss: 0.3374 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 992/4096\n",
      "24/24 - 0s - loss: 0.0040 - fn: 10.0000 - fp: 10.0000 - tn: 6024.0000 - tp: 3007.0000 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.3364 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 993/4096\n",
      "24/24 - 0s - loss: 0.0069 - fn: 22.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2995.0000 - precision: 0.9930 - recall: 0.9927 - val_loss: 0.3374 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 994/4096\n",
      "24/24 - 0s - loss: 0.0092 - fn: 26.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2991.0000 - precision: 0.9907 - recall: 0.9914 - val_loss: 0.3370 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 995/4096\n",
      "24/24 - 0s - loss: 0.0142 - fn: 30.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2987.0000 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.3458 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 1488.0000 - val_tp: 733.0000 - val_precision: 0.9709 - val_recall: 0.9709\n",
      "Epoch 996/4096\n",
      "24/24 - 0s - loss: 0.0097 - fn: 32.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2985.0000 - precision: 0.9891 - recall: 0.9894 - val_loss: 0.3275 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 997/4096\n",
      "24/24 - 0s - loss: 0.0052 - fn: 17.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3000.0000 - precision: 0.9950 - recall: 0.9944 - val_loss: 0.3374 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 998/4096\n",
      "24/24 - 0s - loss: 0.0050 - fn: 18.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2999.0000 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.3394 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 999/4096\n",
      "24/24 - 0s - loss: 0.0053 - fn: 15.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3002.0000 - precision: 0.9954 - recall: 0.9950 - val_loss: 0.3371 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1000/4096\n",
      "24/24 - 0s - loss: 0.0059 - fn: 17.0000 - fp: 14.0000 - tn: 6020.0000 - tp: 3000.0000 - precision: 0.9954 - recall: 0.9944 - val_loss: 0.3377 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 1001/4096\n",
      "24/24 - 0s - loss: 0.0036 - fn: 11.0000 - fp: 10.0000 - tn: 6024.0000 - tp: 3006.0000 - precision: 0.9967 - recall: 0.9964 - val_loss: 0.3379 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 1002/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 24.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2993.0000 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.3424 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 1003/4096\n",
      "24/24 - 0s - loss: 0.0111 - fn: 20.0000 - fp: 19.0000 - tn: 6015.0000 - tp: 2997.0000 - precision: 0.9937 - recall: 0.9934 - val_loss: 0.3373 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1004/4096\n",
      "24/24 - 0s - loss: 0.0254 - fn: 72.0000 - fp: 77.0000 - tn: 5957.0000 - tp: 2945.0000 - precision: 0.9745 - recall: 0.9761 - val_loss: 0.3404 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1005/4096\n",
      "24/24 - 0s - loss: 0.0120 - fn: 38.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2979.0000 - precision: 0.9874 - recall: 0.9874 - val_loss: 0.3389 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1006/4096\n",
      "24/24 - 0s - loss: 0.0150 - fn: 50.0000 - fp: 51.0000 - tn: 5983.0000 - tp: 2967.0000 - precision: 0.9831 - recall: 0.9834 - val_loss: 0.3386 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 1007/4096\n",
      "24/24 - 0s - loss: 0.0234 - fn: 65.0000 - fp: 65.0000 - tn: 5969.0000 - tp: 2952.0000 - precision: 0.9785 - recall: 0.9785 - val_loss: 0.3239 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1008/4096\n",
      "24/24 - 0s - loss: 0.0118 - fn: 34.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2983.0000 - precision: 0.9891 - recall: 0.9887 - val_loss: 0.3290 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1009/4096\n",
      "24/24 - 0s - loss: 0.0108 - fn: 43.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2974.0000 - precision: 0.9844 - recall: 0.9857 - val_loss: 0.3350 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 1010/4096\n",
      "24/24 - 0s - loss: 0.0062 - fn: 26.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2991.0000 - precision: 0.9917 - recall: 0.9914 - val_loss: 0.3398 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 1011/4096\n",
      "24/24 - 0s - loss: 0.0143 - fn: 37.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2980.0000 - precision: 0.9881 - recall: 0.9877 - val_loss: 0.3484 - val_fn: 27.0000 - val_fp: 28.0000 - val_tn: 1482.0000 - val_tp: 728.0000 - val_precision: 0.9630 - val_recall: 0.9642\n",
      "Epoch 1012/4096\n",
      "24/24 - 0s - loss: 0.0141 - fn: 49.0000 - fp: 47.0000 - tn: 5987.0000 - tp: 2968.0000 - precision: 0.9844 - recall: 0.9838 - val_loss: 0.3297 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1013/4096\n",
      "24/24 - 0s - loss: 0.0077 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.3319 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1014/4096\n",
      "24/24 - 0s - loss: 0.0057 - fn: 15.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3002.0000 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.3328 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 1015/4096\n",
      "24/24 - 0s - loss: 0.0049 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.3364 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 1016/4096\n",
      "24/24 - 0s - loss: 0.0042 - fn: 11.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3006.0000 - precision: 0.9960 - recall: 0.9964 - val_loss: 0.3318 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1017/4096\n",
      "24/24 - 0s - loss: 0.0059 - fn: 16.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3001.0000 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.3336 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1018/4096\n",
      "24/24 - 0s - loss: 0.0048 - fn: 18.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 2999.0000 - precision: 0.9940 - recall: 0.9940 - val_loss: 0.3266 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 1019/4096\n",
      "24/24 - 0s - loss: 0.0058 - fn: 17.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3000.0000 - precision: 0.9944 - recall: 0.9944 - val_loss: 0.3350 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1020/4096\n",
      "24/24 - 0s - loss: 0.0044 - fn: 14.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3003.0000 - precision: 0.9950 - recall: 0.9954 - val_loss: 0.3375 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1021/4096\n",
      "24/24 - 0s - loss: 0.0051 - fn: 18.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 2999.0000 - precision: 0.9950 - recall: 0.9940 - val_loss: 0.3337 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1022/4096\n",
      "24/24 - 0s - loss: 0.0088 - fn: 27.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2990.0000 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.3307 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1023/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 23.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2994.0000 - precision: 0.9930 - recall: 0.9924 - val_loss: 0.3423 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1024/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.3403 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1025/4096\n",
      "24/24 - 0s - loss: 0.0063 - fn: 20.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2997.0000 - precision: 0.9930 - recall: 0.9934 - val_loss: 0.3428 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 1026/4096\n",
      "24/24 - 0s - loss: 0.0054 - fn: 17.0000 - fp: 15.0000 - tn: 6019.0000 - tp: 3000.0000 - precision: 0.9950 - recall: 0.9944 - val_loss: 0.3376 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 1027/4096\n",
      "24/24 - 0s - loss: 0.0082 - fn: 26.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2991.0000 - precision: 0.9920 - recall: 0.9914 - val_loss: 0.3551 - val_fn: 20.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 735.0000 - val_precision: 0.9722 - val_recall: 0.9735\n",
      "Epoch 1028/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 31.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2986.0000 - precision: 0.9894 - recall: 0.9897 - val_loss: 0.3549 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 1029/4096\n",
      "24/24 - 0s - loss: 0.0121 - fn: 27.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2990.0000 - precision: 0.9907 - recall: 0.9911 - val_loss: 0.3562 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1030/4096\n",
      "24/24 - 0s - loss: 0.0157 - fn: 43.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2974.0000 - precision: 0.9861 - recall: 0.9857 - val_loss: 0.3443 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1031/4096\n",
      "24/24 - 0s - loss: 0.0051 - fn: 13.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3004.0000 - precision: 0.9960 - recall: 0.9957 - val_loss: 0.3386 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1032/4096\n",
      "24/24 - 0s - loss: 0.0067 - fn: 26.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2991.0000 - precision: 0.9920 - recall: 0.9914 - val_loss: 0.3344 - val_fn: 13.0000 - val_fp: 12.0000 - val_tn: 1498.0000 - val_tp: 742.0000 - val_precision: 0.9841 - val_recall: 0.9828\n",
      "Epoch 1033/4096\n",
      "24/24 - 0s - loss: 0.0088 - fn: 26.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2991.0000 - precision: 0.9911 - recall: 0.9914 - val_loss: 0.3208 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 1034/4096\n",
      "24/24 - 0s - loss: 0.0184 - fn: 39.0000 - fp: 42.0000 - tn: 5992.0000 - tp: 2978.0000 - precision: 0.9861 - recall: 0.9871 - val_loss: 0.3267 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 1035/4096\n",
      "24/24 - 0s - loss: 0.0213 - fn: 33.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2984.0000 - precision: 0.9884 - recall: 0.9891 - val_loss: 0.3283 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1036/4096\n",
      "24/24 - 0s - loss: 0.0181 - fn: 41.0000 - fp: 41.0000 - tn: 5993.0000 - tp: 2976.0000 - precision: 0.9864 - recall: 0.9864 - val_loss: 0.3218 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1037/4096\n",
      "24/24 - 0s - loss: 0.0125 - fn: 39.0000 - fp: 40.0000 - tn: 5994.0000 - tp: 2978.0000 - precision: 0.9867 - recall: 0.9871 - val_loss: 0.3322 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1038/4096\n",
      "24/24 - 0s - loss: 0.0239 - fn: 47.0000 - fp: 48.0000 - tn: 5986.0000 - tp: 2970.0000 - precision: 0.9841 - recall: 0.9844 - val_loss: 0.3465 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 734.0000 - val_precision: 0.9722 - val_recall: 0.9722\n",
      "Epoch 1039/4096\n",
      "24/24 - 0s - loss: 0.0261 - fn: 30.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2987.0000 - precision: 0.9904 - recall: 0.9901 - val_loss: 0.3410 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 1040/4096\n",
      "24/24 - 0s - loss: 0.0566 - fn: 33.0000 - fp: 34.0000 - tn: 6000.0000 - tp: 2984.0000 - precision: 0.9887 - recall: 0.9891 - val_loss: 0.3277 - val_fn: 20.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 735.0000 - val_precision: 0.9722 - val_recall: 0.9735\n",
      "Epoch 1041/4096\n",
      "24/24 - 0s - loss: 0.0160 - fn: 34.0000 - fp: 31.0000 - tn: 6003.0000 - tp: 2983.0000 - precision: 0.9897 - recall: 0.9887 - val_loss: 0.3350 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 1042/4096\n",
      "24/24 - 0s - loss: 0.0141 - fn: 33.0000 - fp: 32.0000 - tn: 6002.0000 - tp: 2984.0000 - precision: 0.9894 - recall: 0.9891 - val_loss: 0.3264 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1043/4096\n",
      "24/24 - 0s - loss: 0.0142 - fn: 26.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2991.0000 - precision: 0.9911 - recall: 0.9914 - val_loss: 0.3337 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 1044/4096\n",
      "24/24 - 0s - loss: 0.0106 - fn: 21.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2996.0000 - precision: 0.9934 - recall: 0.9930 - val_loss: 0.3289 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1045/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 31.0000 - fp: 29.0000 - tn: 6005.0000 - tp: 2986.0000 - precision: 0.9904 - recall: 0.9897 - val_loss: 0.3201 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 1046/4096\n",
      "24/24 - 0s - loss: 0.0122 - fn: 18.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 2999.0000 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.3296 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 1047/4096\n",
      "24/24 - 0s - loss: 0.0171 - fn: 32.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2985.0000 - precision: 0.9900 - recall: 0.9894 - val_loss: 0.3188 - val_fn: 14.0000 - val_fp: 14.0000 - val_tn: 1496.0000 - val_tp: 741.0000 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "Epoch 1048/4096\n",
      "24/24 - 0s - loss: 0.0335 - fn: 41.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2976.0000 - precision: 0.9874 - recall: 0.9864 - val_loss: 0.3352 - val_fn: 17.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 738.0000 - val_precision: 0.9788 - val_recall: 0.9775\n",
      "Epoch 1049/4096\n",
      "24/24 - 0s - loss: 0.0472 - fn: 28.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2989.0000 - precision: 0.9914 - recall: 0.9907 - val_loss: 0.3404 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 1487.0000 - val_tp: 732.0000 - val_precision: 0.9695 - val_recall: 0.9695\n",
      "Epoch 1050/4096\n",
      "24/24 - 0s - loss: 0.0180 - fn: 33.0000 - fp: 33.0000 - tn: 6001.0000 - tp: 2984.0000 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.3278 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1051/4096\n",
      "24/24 - 0s - loss: 0.0107 - fn: 35.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2982.0000 - precision: 0.9884 - recall: 0.9884 - val_loss: 0.3314 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 1489.0000 - val_tp: 733.0000 - val_precision: 0.9721 - val_recall: 0.9709\n",
      "Epoch 1052/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 30.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2987.0000 - precision: 0.9907 - recall: 0.9901 - val_loss: 0.3170 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 1053/4096\n",
      "24/24 - 0s - loss: 0.0079 - fn: 23.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2994.0000 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.3197 - val_fn: 19.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 736.0000 - val_precision: 0.9761 - val_recall: 0.9748\n",
      "Epoch 1054/4096\n",
      "24/24 - 0s - loss: 0.0068 - fn: 17.0000 - fp: 16.0000 - tn: 6018.0000 - tp: 3000.0000 - precision: 0.9947 - recall: 0.9944 - val_loss: 0.3255 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 1055/4096\n",
      "24/24 - 0s - loss: 0.0069 - fn: 22.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2995.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.3259 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 1056/4096\n",
      "24/24 - 0s - loss: 0.0066 - fn: 24.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2993.0000 - precision: 0.9917 - recall: 0.9920 - val_loss: 0.3320 - val_fn: 15.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 740.0000 - val_precision: 0.9801 - val_recall: 0.9801\n",
      "Epoch 1057/4096\n",
      "24/24 - 0s - loss: 0.0051 - fn: 11.0000 - fp: 12.0000 - tn: 6022.0000 - tp: 3006.0000 - precision: 0.9960 - recall: 0.9964 - val_loss: 0.3347 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1058/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 41.0000 - fp: 35.0000 - tn: 5999.0000 - tp: 2976.0000 - precision: 0.9884 - recall: 0.9864 - val_loss: 0.3375 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1059/4096\n",
      "24/24 - 0s - loss: 0.0099 - fn: 26.0000 - fp: 30.0000 - tn: 6004.0000 - tp: 2991.0000 - precision: 0.9901 - recall: 0.9914 - val_loss: 0.3226 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 1060/4096\n",
      "24/24 - 0s - loss: 0.0073 - fn: 20.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2997.0000 - precision: 0.9924 - recall: 0.9934 - val_loss: 0.3237 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 1061/4096\n",
      "24/24 - 0s - loss: 0.0072 - fn: 24.0000 - fp: 24.0000 - tn: 6010.0000 - tp: 2993.0000 - precision: 0.9920 - recall: 0.9920 - val_loss: 0.3307 - val_fn: 18.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 737.0000 - val_precision: 0.9775 - val_recall: 0.9762\n",
      "Epoch 1062/4096\n",
      "24/24 - 0s - loss: 0.0052 - fn: 13.0000 - fp: 13.0000 - tn: 6021.0000 - tp: 3004.0000 - precision: 0.9957 - recall: 0.9957 - val_loss: 0.3297 - val_fn: 20.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 735.0000 - val_precision: 0.9748 - val_recall: 0.9735\n",
      "Epoch 1063/4096\n",
      "24/24 - 0s - loss: 0.0109 - fn: 24.0000 - fp: 25.0000 - tn: 6009.0000 - tp: 2993.0000 - precision: 0.9917 - recall: 0.9920 - val_loss: 0.3328 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1064/4096\n",
      "24/24 - 0s - loss: 0.0106 - fn: 33.0000 - fp: 28.0000 - tn: 6006.0000 - tp: 2984.0000 - precision: 0.9907 - recall: 0.9891 - val_loss: 0.3376 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1065/4096\n",
      "24/24 - 0s - loss: 0.0061 - fn: 24.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2993.0000 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.3419 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 1066/4096\n",
      "24/24 - 0s - loss: 0.0081 - fn: 24.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2993.0000 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.3334 - val_fn: 14.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 741.0000 - val_precision: 0.9802 - val_recall: 0.9815\n",
      "Epoch 1067/4096\n",
      "24/24 - 0s - loss: 0.0159 - fn: 37.0000 - fp: 37.0000 - tn: 5997.0000 - tp: 2980.0000 - precision: 0.9877 - recall: 0.9877 - val_loss: 0.3411 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1068/4096\n",
      "24/24 - 0s - loss: 0.0165 - fn: 27.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2990.0000 - precision: 0.9914 - recall: 0.9911 - val_loss: 0.3426 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1069/4096\n",
      "24/24 - 0s - loss: 0.0098 - fn: 21.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2996.0000 - precision: 0.9930 - recall: 0.9930 - val_loss: 0.3435 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1070/4096\n",
      "24/24 - 0s - loss: 0.0089 - fn: 15.0000 - fp: 17.0000 - tn: 6017.0000 - tp: 3002.0000 - precision: 0.9944 - recall: 0.9950 - val_loss: 0.3521 - val_fn: 19.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 736.0000 - val_precision: 0.9748 - val_recall: 0.9748\n",
      "Epoch 1071/4096\n",
      "24/24 - 0s - loss: 0.0164 - fn: 36.0000 - fp: 38.0000 - tn: 5996.0000 - tp: 2981.0000 - precision: 0.9874 - recall: 0.9881 - val_loss: 0.3421 - val_fn: 17.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 738.0000 - val_precision: 0.9749 - val_recall: 0.9775\n",
      "Epoch 1072/4096\n",
      "24/24 - 0s - loss: 0.0114 - fn: 26.0000 - fp: 26.0000 - tn: 6008.0000 - tp: 2991.0000 - precision: 0.9914 - recall: 0.9914 - val_loss: 0.3381 - val_fn: 16.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 739.0000 - val_precision: 0.9775 - val_recall: 0.9788\n",
      "Epoch 1073/4096\n",
      "24/24 - 0s - loss: 0.0076 - fn: 21.0000 - fp: 23.0000 - tn: 6011.0000 - tp: 2996.0000 - precision: 0.9924 - recall: 0.9930 - val_loss: 0.3312 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1074/4096\n",
      "24/24 - 0s - loss: 0.0103 - fn: 21.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2996.0000 - precision: 0.9927 - recall: 0.9930 - val_loss: 0.3332 - val_fn: 16.0000 - val_fp: 16.0000 - val_tn: 1494.0000 - val_tp: 739.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 1075/4096\n",
      "24/24 - 0s - loss: 0.0168 - fn: 48.0000 - fp: 49.0000 - tn: 5985.0000 - tp: 2969.0000 - precision: 0.9838 - recall: 0.9841 - val_loss: 0.3405 - val_fn: 17.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 738.0000 - val_precision: 0.9775 - val_recall: 0.9775\n",
      "Epoch 1076/4096\n",
      "24/24 - 0s - loss: 0.0067 - fn: 22.0000 - fp: 22.0000 - tn: 6012.0000 - tp: 2995.0000 - precision: 0.9927 - recall: 0.9927 - val_loss: 0.3394 - val_fn: 16.0000 - val_fp: 15.0000 - val_tn: 1495.0000 - val_tp: 739.0000 - val_precision: 0.9801 - val_recall: 0.9788\n",
      "Epoch 1077/4096\n",
      "24/24 - 0s - loss: 0.0133 - fn: 16.0000 - fp: 18.0000 - tn: 6016.0000 - tp: 3001.0000 - precision: 0.9940 - recall: 0.9947 - val_loss: 0.3487 - val_fn: 20.0000 - val_fp: 20.0000 - val_tn: 1490.0000 - val_tp: 735.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 1078/4096\n",
      "24/24 - 0s - loss: 0.0179 - fn: 30.0000 - fp: 27.0000 - tn: 6007.0000 - tp: 2987.0000 - precision: 0.9910 - recall: 0.9901 - val_loss: 0.3375 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1079/4096\n",
      "24/24 - 0s - loss: 0.0096 - fn: 20.0000 - fp: 21.0000 - tn: 6013.0000 - tp: 2997.0000 - precision: 0.9930 - recall: 0.9934 - val_loss: 0.3332 - val_fn: 19.0000 - val_fp: 17.0000 - val_tn: 1493.0000 - val_tp: 736.0000 - val_precision: 0.9774 - val_recall: 0.9748\n",
      "Epoch 1080/4096\n",
      "24/24 - 0s - loss: 0.0083 - fn: 20.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2997.0000 - precision: 0.9934 - recall: 0.9934 - val_loss: 0.3356 - val_fn: 18.0000 - val_fp: 19.0000 - val_tn: 1491.0000 - val_tp: 737.0000 - val_precision: 0.9749 - val_recall: 0.9762\n",
      "Epoch 1081/4096\n",
      "24/24 - 0s - loss: 0.0071 - fn: 23.0000 - fp: 20.0000 - tn: 6014.0000 - tp: 2994.0000 - precision: 0.9934 - recall: 0.9924 - val_loss: 0.3424 - val_fn: 18.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 737.0000 - val_precision: 0.9762 - val_recall: 0.9762\n",
      "Epoch 1082/4096\n",
      "24/24 - 0s - loss: 0.0110 - fn: 35.0000 - fp: 36.0000 - tn: 5998.0000 - tp: 2982.0000 - precision: 0.9881 - recall: 0.9884 - val_loss: 0.3388 - val_fn: 17.0000 - val_fp: 18.0000 - val_tn: 1492.0000 - val_tp: 738.0000 - val_precision: 0.9762 - val_recall: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa2da766070>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\")\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"checkpoints/thyroid_model_at_epoch_{epoch}.h5\"),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1000, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=4096,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    class_weight=d_class_weights,\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss train')\n",
    "plt.plot(history.history['val_loss'], label='loss validation')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to create model based on hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               5632      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 137,987\n",
      "Trainable params: 137,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_model(\n",
    "        lr=1e-3, \n",
    "        patience=1000, \n",
    "        hidden_layer_sizes=(256,256,256),\n",
    "        dropouts=(None,0.3,0.3),\n",
    "        opt=\"adam\",\n",
    "        hidden_activations = (\"relu\", \"relu\", \"relu\"),\n",
    "        input_shape=X_train.shape[1]\n",
    "    ):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "  \n",
    "\n",
    "    # Building model\n",
    "    layers = []\n",
    "    for hidden_layer_size, dropout, hidden_act in zip(hidden_layer_sizes, dropouts, hidden_activations):\n",
    "        dense = None\n",
    "        if len(layers)==0:\n",
    "            dense=Dense(hidden_layer_size, activation = hidden_act, input_shape=(input_shape,))\n",
    "        else:\n",
    "            dense = Dense(hidden_layer_size, activation = hidden_act)\n",
    "\n",
    "        layers.append(\n",
    "            dense\n",
    "        )\n",
    "        \n",
    "        if dropout is not None:\n",
    "            layers.append(Dropout(dropout))\n",
    "        \n",
    "    # Output\n",
    "    layers.append(Dense(3, activation=\"softmax\"))\n",
    "    model = Sequential(\n",
    "       layers\n",
    "    )\n",
    "\n",
    "    metrics = [\n",
    "        keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        keras.metrics.TruePositives(name=\"tp\"),\n",
    "        keras.metrics.Precision(name=\"precision\"),\n",
    "        keras.metrics.Recall(name=\"recall\"),\n",
    "        keras.metrics.Accuracy(name=\"accuracy\")\n",
    "    ]\n",
    "\n",
    "    optimizers = {\n",
    "        \"adam\":Adam(lr),\n",
    "        \"sgd\":SGD(lr),\n",
    "    }\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers[opt],  loss=\"binary_crossentropy\", metrics=metrics\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\"checkpoints/thyroid_model_at_epoch_{epoch}.h5\"),\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=patience, restore_best_weights=True)\n",
    "    ]   \n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running some Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Learning Rate\n",
    "lrs = [1e-4, 1e-3 ,1e-2, 1e-1, 1]\n",
    "\n",
    "### Batch Size\n",
    "batch_sizes =  [32,64,128,256]\n",
    "\n",
    "### Optimizer\n",
    "opts = [\"adam\", \"sgd\"]\n",
    "\n",
    "### Number of layers\n",
    "layers = [(256,), (256, 256,), (256, 256, 256,)]\n",
    "\n",
    "### Number of neurons in hidden layers\n",
    "neurons = [(i, i, i) for i in [64,128,256,512]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, label):\n",
    "\n",
    "    print('Confusion Matrix\\n')\n",
    "    print(conf)\n",
    "\n",
    "    #importing accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "    print('Micro Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='micro')))\n",
    "    print('Micro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='micro')))\n",
    "    print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='micro')))\n",
    "\n",
    "    print('Macro Precision: {:.2f}'.format(precision_score(y_true, TrainPy_predredictions, average='macro')))\n",
    "    print('Macro Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='macro')))\n",
    "    print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_true, y_pred, average='macro')))\n",
    "\n",
    "    print('Weighted Precision: {:.2f}'.format(precision_score(y_true, y_pred, average='weighted')))\n",
    "    print('Weighted Recall: {:.2f}'.format(recall_score(y_true, y_pred, average='weighted')))\n",
    "    print('Weighted F1-score: {:.2f}'.format(f1_score(y_true, y_pred, average='weighted')))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print('\\nClassification Report\\n')\n",
    "    print(classification_report(y_true, y_pred, target_names=['Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Confusion Matrix\n",
      "\n",
      "[[  68    4    1]\n",
      " [  16   83   78]\n",
      " [  61   69 3048]]\n",
      "\n",
      "Accuracy: 0.92\n",
      "\n",
      "Micro Precision: 0.92\n",
      "Micro Recall: 0.92\n",
      "Micro F1-score: 0.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trdp/anaconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TrainPy_predredictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio Tireoide.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000038?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000038?line=7'>8</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x_val)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000038?line=8'>9</a>\u001b[0m evaluate(y_val, y_pred, \u001b[39m\"\u001b[39;49m\u001b[39mValidation\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000038?line=9'>10</a>\u001b[0m recalls\u001b[39m.\u001b[39mappend(recall_score(y_val, y_pred, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;32m/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio Tireoide.ipynb Cell 26'\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y_true, y_pred, label)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000039?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMicro Recall: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(recall_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000039?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMicro F1-score: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(f1_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000039?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMacro Precision: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(precision_score(y_true, TrainPy_predredictions, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000039?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMacro Recall: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(recall_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/trdp/Arquivos/Studies/PhD/Subjects/2022-1/IAC/iac_exercises/exercicio5/Exercicio%20Tireoide.ipynb#ch0000039?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMacro F1-score: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(f1_score(y_true, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainPy_predredictions' is not defined"
     ]
    }
   ],
   "source": [
    "recalls = []\n",
    "for lr in lrs:\n",
    "    print(\"=\"*100)\n",
    "    model =KerasClassifier(create_model, lr=lr, verbose=0)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_val)\n",
    "    evaluate(y_val, y_pred, \"Validation\")\n",
    "    recalls.append(recall_score(y_val, y_pred, average=\"macro\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1627161206593,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "I-KfNDpdg6tj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TrainPredictions = model.predict(inputTrain)\n",
    "TrainPredictions = np.argmax(TrainPredictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1627161207021,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "Hzv9ccyjV8u5",
    "outputId": "b95308f0-7a89-4c6f-8ac3-afce0deb7264",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(outputTrain, TrainPredictions)\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "# plot confusion matrix\n",
    "plt.imshow(conf, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "plt.title(\"Train Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "fmt = 'd'\n",
    "thresh = conf.max() / 2.\n",
    "for i, j in itertools.product(range(conf.shape[0]), range(conf.shape[1])):\n",
    "    plt.text(j, i, format(conf[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if conf[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1627161207025,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "nfF7KaksWXqC",
    "outputId": "29d04dfe-bbc9-4e72-ed2b-89dcb079d7b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  92    0    1]\n",
      " [  42   89   60]\n",
      " [  47   61 3380]]\n",
      "\n",
      "Accuracy: 0.94\n",
      "\n",
      "Micro Precision: 0.94\n",
      "Micro Recall: 0.94\n",
      "Micro F1-score: 0.94\n",
      "\n",
      "Macro Precision: 0.69\n",
      "Macro Recall: 0.81\n",
      "Macro F1-score: 0.72\n",
      "\n",
      "Weighted Precision: 0.95\n",
      "Weighted Recall: 0.94\n",
      "Weighted F1-score: 0.95\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.51      0.99      0.67        93\n",
      "     Class 2       0.59      0.47      0.52       191\n",
      "     Class 3       0.98      0.97      0.98      3488\n",
      "\n",
      "    accuracy                           0.94      3772\n",
      "   macro avg       0.69      0.81      0.72      3772\n",
      "weighted avg       0.95      0.94      0.95      3772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix\\n')\n",
    "print(conf)\n",
    "\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(outputTrain, TrainPredictions)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(outputTrain, TrainPredictions, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(outputTrain, TrainPredictions, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(outputTrain, TrainPredictions, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(outputTrain, TrainPredictions, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(outputTrain, TrainPredictions, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(outputTrain, TrainPredictions, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(outputTrain, TrainPredictions, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(outputTrain, TrainPredictions, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(outputTrain, TrainPredictions, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(outputTrain, TrainPredictions, target_names=['Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1627161207026,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "B8X_irRRVwxQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TestPredictions = model.predict(inputTest)\n",
    "TestPredictions = np.argmax(TestPredictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1627161207390,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "E-xeUrkIA8-A",
    "outputId": "662030e4-4117-4343-cb91-c2763f32e238",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(outputTest, TestPredictions)\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "# plot confusion matrix\n",
    "plt.imshow(conf, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "fmt = 'd'\n",
    "thresh = conf.max() / 2.\n",
    "for i, j in itertools.product(range(conf.shape[0]), range(conf.shape[1])):\n",
    "    plt.text(j, i, format(conf[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if conf[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1627161207392,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "YzVuA0AwL5be",
    "outputId": "537ac605-48b5-4a5b-f781-4fd95cc6fb67",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  68    4    1]\n",
      " [  16   83   78]\n",
      " [  61   69 3048]]\n",
      "\n",
      "Accuracy: 0.93\n",
      "\n",
      "Micro Precision: 0.93\n",
      "Micro Recall: 0.93\n",
      "Micro F1-score: 0.93\n",
      "\n",
      "Macro Precision: 0.66\n",
      "Macro Recall: 0.79\n",
      "Macro F1-score: 0.70\n",
      "\n",
      "Weighted Precision: 0.94\n",
      "Weighted Recall: 0.93\n",
      "Weighted F1-score: 0.94\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.47      0.93      0.62        73\n",
      "     Class 2       0.53      0.47      0.50       177\n",
      "     Class 3       0.97      0.96      0.97      3178\n",
      "\n",
      "    accuracy                           0.93      3428\n",
      "   macro avg       0.66      0.79      0.70      3428\n",
      "weighted avg       0.94      0.93      0.94      3428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix\\n')\n",
    "print(conf)\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(outputTest, TestPredictions)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(outputTest, TestPredictions, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(outputTest, TestPredictions, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(outputTest, TestPredictions, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(outputTest, TestPredictions, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(outputTest, TestPredictions, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(outputTest, TestPredictions, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(outputTest, TestPredictions, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(outputTest, TestPredictions, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(outputTest, TestPredictions, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(outputTest, TestPredictions, target_names=['Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1627161207648,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "bWFMjqdYUwVm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercicio Tireoide.ipynb",
   "provenance": [
    {
     "file_id": "1Z5luJsl-IYT-v9zbj60Xd-Q7WubyB-Vy",
     "timestamp": 1627005465267
    },
    {
     "file_id": "1r6kPh4dwuGaPnd46hCfhz_FsI1cIgIaw",
     "timestamp": 1626995069751
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c79f3b749ac1c615955d5d100e4e2835a83d7f04dde803c7105836bec394313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
