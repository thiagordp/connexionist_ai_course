{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 5 - Thyroid desease prediction using Convolutional Neural Networks\n",
    "\n",
    "\n",
    "Available at: \n",
    "- https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease\n",
    "- http://networkrepository.com/thyroid-disease-thyroid0387.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 3614,
     "status": "ok",
     "timestamp": 1627161045686,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "ONTVLB0nA89y",
    "outputId": "eabfa509-56e7-4ee7-f092-a70a6d438248",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:12:38.416410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: <module 'tensorflow._api.v2.version' from '/home/trdp/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/_api/v2/version/__init__.py'>\n",
      "Is GPU backend?\n",
      " [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1504106200700601782\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 62586880\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11406121349571818429\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:12:39.606387: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-19 14:12:39.606975: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-19 14:12:39.632762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-19 14:12:39.653423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:12:39.653524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.392GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-06-19 14:12:39.653544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-19 14:12:39.676086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-19 14:12:39.676166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-19 14:12:39.688315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-19 14:12:39.702981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-19 14:12:39.715149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-19 14:12:39.726565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-19 14:12:39.741370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-19 14:12:39.741513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:12:39.741680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:12:39.741755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-19 14:12:39.741796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-19 14:12:40.980447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-19 14:12:40.980474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-06-19 14:12:40.980482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-06-19 14:12:40.980696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:12:40.980904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:12:40.981126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:12:40.981273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 59 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools    \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TF version:\", tf.version)\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Is GPU backend?\\n\", device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Downloading Training Dataset\n",
    "\n",
    "The first step is the download of dataset and transform it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset\n",
      "Tranform to pandas dataframe\n",
      "Shape: (3772, 24)\n",
      "Head\n"
     ]
    },
    {
     "data": {
      "text/plain": "     0   1   2   3   4   5   6   7   8   9   ...  14  15       16     17  \\\n0  0.73   0   1   0   0   0   0   0   1   0  ...   0   0  0.00060  0.015   \n1  0.24   0   0   0   0   0   0   0   0   0  ...   0   0  0.00025  0.030   \n2  0.47   0   0   0   0   0   0   0   0   0  ...   0   0  0.00190  0.024   \n3  0.64   1   0   0   0   0   0   0   0   0  ...   0   0  0.00090  0.017   \n4  0.23   0   0   0   0   0   0   0   0   0  ...   0   0  0.00025  0.026   \n\n      18     19     20  21  22  23  \n0  0.120  0.082  0.146   3 NaN NaN  \n1  0.143  0.133  0.108   3 NaN NaN  \n2  0.102  0.131  0.078   3 NaN NaN  \n3  0.077  0.090  0.085   3 NaN NaN  \n4  0.139  0.090  0.153   3 NaN NaN  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.73</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00060</td>\n      <td>0.015</td>\n      <td>0.120</td>\n      <td>0.082</td>\n      <td>0.146</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00025</td>\n      <td>0.030</td>\n      <td>0.143</td>\n      <td>0.133</td>\n      <td>0.108</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.47</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00190</td>\n      <td>0.024</td>\n      <td>0.102</td>\n      <td>0.131</td>\n      <td>0.078</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.64</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00090</td>\n      <td>0.017</td>\n      <td>0.077</td>\n      <td>0.090</td>\n      <td>0.085</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00025</td>\n      <td>0.026</td>\n      <td>0.139</td>\n      <td>0.090</td>\n      <td>0.153</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Downloading the dataset\")\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/ann-train.data\"\n",
    "s = requests.get(url).contents=requests.get(url).content\n",
    "print(\"Tranform to pandas dataframe\")\n",
    "dataTrain=pd.read_csv(io.StringIO(s.decode('utf-8')),delimiter=' ',header=None)\n",
    "\n",
    "\n",
    "print(\"Shape:\", dataTrain.shape)\n",
    "print(\"Head\")\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1627161045688,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "WUYWQzfIA894",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Removing NaN columns\n",
    "del dataTrain[22]\n",
    "del dataTrain[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1627161045689,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "9sUGNCb1A895",
    "outputId": "ab00fa7b-52cb-4a00-e61d-dd0120e6b1f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15       16  \\\n0  0.73   0   1   0   0   0   0   0   1   0  ...   0   0   0   0  0.00060   \n1  0.24   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00025   \n2  0.47   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00190   \n3  0.64   1   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00090   \n4  0.23   0   0   0   0   0   0   0   0   0  ...   0   0   0   0  0.00025   \n\n      17     18     19     20  21  \n0  0.015  0.120  0.082  0.146   3  \n1  0.030  0.143  0.133  0.108   3  \n2  0.024  0.102  0.131  0.078   3  \n3  0.017  0.077  0.090  0.085   3  \n4  0.026  0.139  0.090  0.153   3  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.73</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00060</td>\n      <td>0.015</td>\n      <td>0.120</td>\n      <td>0.082</td>\n      <td>0.146</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00025</td>\n      <td>0.030</td>\n      <td>0.143</td>\n      <td>0.133</td>\n      <td>0.108</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.47</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00190</td>\n      <td>0.024</td>\n      <td>0.102</td>\n      <td>0.131</td>\n      <td>0.078</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.64</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00090</td>\n      <td>0.017</td>\n      <td>0.077</td>\n      <td>0.090</td>\n      <td>0.085</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00025</td>\n      <td>0.026</td>\n      <td>0.139</td>\n      <td>0.090</td>\n      <td>0.153</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1627161045691,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "H0clK1EmA896",
    "outputId": "fae44f5a-5abf-4c3a-dfec-baf772c15902",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     0   1   2   3   4   5   6   7   8   9   ...  11  12  13  14  15       16  \\\n0  0.73   0   1   0   0   0   0   0   1   0  ...   0   0   0   0   0  0.00060   \n1  0.24   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00025   \n2  0.47   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00190   \n3  0.64   1   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00090   \n4  0.23   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0  0.00025   \n\n      17     18     19     20  \n0  0.015  0.120  0.082  0.146  \n1  0.030  0.143  0.133  0.108  \n2  0.024  0.102  0.131  0.078  \n3  0.017  0.077  0.090  0.085  \n4  0.026  0.139  0.090  0.153  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.73</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00060</td>\n      <td>0.015</td>\n      <td>0.120</td>\n      <td>0.082</td>\n      <td>0.146</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00025</td>\n      <td>0.030</td>\n      <td>0.143</td>\n      <td>0.133</td>\n      <td>0.108</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.47</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00190</td>\n      <td>0.024</td>\n      <td>0.102</td>\n      <td>0.131</td>\n      <td>0.078</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.64</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00090</td>\n      <td>0.017</td>\n      <td>0.077</td>\n      <td>0.090</td>\n      <td>0.085</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.23</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.00025</td>\n      <td>0.026</td>\n      <td>0.139</td>\n      <td>0.090</td>\n      <td>0.153</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictor data\n",
    "inputTrain = dataTrain.drop([21], axis=1)\n",
    "inputTrain.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1627161045692,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "O6cawaraA897",
    "outputId": "00c9b163-75b8-4213-a9ab-d8aea1357b77",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Counter({2: 3488, 1: 191, 0: 93})\n"
     ]
    }
   ],
   "source": [
    "# Target data\n",
    "outputTrain = dataTrain[21] - 1\n",
    "\n",
    "print(\"Labels\", Counter(outputTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 1370,
     "status": "ok",
     "timestamp": 1627161047007,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "wXClhA2jA897",
    "outputId": "c2fb0649-da66-466d-b7e5-dc5914e9494c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3428, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     0   1   2   3   4   5   6   7   8   9   ...  14  15      16     17  \\\n0  0.29   0   0   0   0   0   0   0   0   0  ...   0   0  0.0061  0.028   \n1  0.32   0   0   0   0   0   0   0   0   0  ...   0   0  0.0013  0.019   \n2  0.35   0   0   0   0   0   0   0   0   0  ...   0   0  0.0000  0.031   \n3  0.21   0   0   0   0   0   0   0   0   0  ...   0   0  0.0010  0.018   \n4  0.22   0   0   0   0   1   0   0   0   0  ...   0   0  0.0004  0.022   \n\n      18     19     20  21  22  23  \n0  0.111  0.131  0.085   2 NaN NaN  \n1  0.084  0.078  0.107   3 NaN NaN  \n2  0.239  0.100  0.239   3 NaN NaN  \n3  0.087  0.088  0.099   3 NaN NaN  \n4  0.134  0.135  0.099   3 NaN NaN  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0061</td>\n      <td>0.028</td>\n      <td>0.111</td>\n      <td>0.131</td>\n      <td>0.085</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.32</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0013</td>\n      <td>0.019</td>\n      <td>0.084</td>\n      <td>0.078</td>\n      <td>0.107</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0000</td>\n      <td>0.031</td>\n      <td>0.239</td>\n      <td>0.100</td>\n      <td>0.239</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0010</td>\n      <td>0.018</td>\n      <td>0.087</td>\n      <td>0.088</td>\n      <td>0.099</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0004</td>\n      <td>0.022</td>\n      <td>0.134</td>\n      <td>0.135</td>\n      <td>0.099</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Downloading test data\n",
    "#\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/ann-test.data\"\n",
    "s = requests.get(url).contents=requests.get(url).content\n",
    "dataTest=pd.read_csv(io.StringIO(s.decode('utf-8')),delimiter=' ',header=None)\n",
    "\n",
    "dataTest.head()\n",
    "\n",
    "print(dataTest.shape)\n",
    "dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1627161047010,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "MBJZQH0fA898",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del dataTest[22]\n",
    "del dataTest[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1627161047012,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "R2SEl2KZA899",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputTest = dataTest.drop([21], axis=1)\n",
    "outputTest = dataTest[21] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1627161047019,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "HFsXbrdMA899",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "# fit using the train set\n",
    "scaler.fit(inputTrain)\n",
    "# transform the test test\n",
    "xtrainN = scaler.transform(inputTrain)\n",
    "xtestN = scaler.transform(inputTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1627161047024,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "i7PYjIIomZFl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputTrain_one_hot = keras.utils.to_categorical(outputTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1627161047026,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "S1_jcOG0A89-",
    "outputId": "fa4f877c-2e5e-40a0-96cc-2d529523de73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1 2]\n",
      "Class weights: [13.51971326  6.58289703  0.36047401]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Calculating class weights\n",
    "#\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes = np.unique(outputTrain), y=outputTrain)\n",
    "print(\"Labels:\", np.unique(outputTrain))\n",
    "print(\"Class weights:\", class_weights)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1627161047055,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "d7vAF0TFA89_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " X_train, X_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "     xtrainN, \n",
    "     outputTrain_one_hot, \n",
    "     test_size = 0.3, \n",
    "     random_state = 1, \n",
    "     stratify=outputTrain\n",
    " )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1627161047058,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "e7xiLTRyA89_",
    "outputId": "43fc955d-29c7-440d-937e-6a1b649fcbdc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               5632      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 137,987\n",
      "Trainable params: 137,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:13:48.500903: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-19 14:13:48.501104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.501279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.392GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-06-19 14:13:48.501345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-19 14:13:48.501379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-19 14:13:48.501403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-19 14:13:48.501426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-19 14:13:48.501448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-19 14:13:48.501470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-19 14:13:48.501492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-19 14:13:48.501515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-19 14:13:48.501607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.501941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.502067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-19 14:13:48.502283: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-19 14:13:48.502383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.502516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.392GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-06-19 14:13:48.502548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-19 14:13:48.502573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-19 14:13:48.502595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-19 14:13:48.502618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-19 14:13:48.502640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-19 14:13:48.502662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-19 14:13:48.502683: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-19 14:13:48.502705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-19 14:13:48.502782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.502975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.503179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-19 14:13:48.503209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-19 14:13:48.503218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-06-19 14:13:48.503225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-06-19 14:13:48.503332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.503524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 14:13:48.503659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 59 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(256, activation=\"relu\", input_shape=(X_train.shape[-1],)\n",
    "        ),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(3, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 158938,
     "status": "ok",
     "timestamp": 1627161205929,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "UuQ4Jg9oA8-A",
    "outputId": "f2742d8b-8819-4961-aab1-86a2c525f3b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:13:55.557292: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-19 14:13:55.577345: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3199980000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/14 [=>............................] - ETA: 14s - loss: 0.7076 - fn: 158.0000 - fp: 126.0000 - tn: 274.0000 - tp: 42.0000 - precision: 0.2500 - recall: 0.2100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 14:13:56.530805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 52ms/step - loss: 0.6471 - fn: 1515.2000 - fp: 147.4000 - tn: 2983.2667 - tp: 50.1333 - precision: 0.2537 - recall: 0.0530 - val_loss: 0.5656 - val_fn: 1132.0000 - val_fp: 0.0000e+00 - val_tn: 2264.0000 - val_tp: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5963 - fn: 1545.6667 - fp: 0.2000 - tn: 3130.4667 - tp: 19.6667 - precision: 0.5969 - recall: 0.0081 - val_loss: 0.5283 - val_fn: 1017.0000 - val_fp: 2.0000 - val_tn: 2262.0000 - val_tp: 115.0000 - val_precision: 0.9829 - val_recall: 0.1016\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5561 - fn: 1152.9333 - fp: 16.7333 - tn: 3113.9333 - tp: 412.4000 - precision: 0.9666 - recall: 0.2362 - val_loss: 0.4492 - val_fn: 579.0000 - val_fp: 64.0000 - val_tn: 2200.0000 - val_tp: 553.0000 - val_precision: 0.8963 - val_recall: 0.4885\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4400 - fn: 777.8000 - fp: 447.0000 - tn: 2683.6667 - tp: 787.5333 - precision: 0.6569 - recall: 0.4907 - val_loss: 0.4457 - val_fn: 522.0000 - val_fp: 372.0000 - val_tn: 1892.0000 - val_tp: 610.0000 - val_precision: 0.6212 - val_recall: 0.5389\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.3702 - fn: 573.6000 - fp: 595.2000 - tn: 2535.4667 - tp: 991.7333 - precision: 0.6295 - recall: 0.6137 - val_loss: 0.3883 - val_fn: 435.0000 - val_fp: 59.0000 - val_tn: 2205.0000 - val_tp: 697.0000 - val_precision: 0.9220 - val_recall: 0.6157\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3452 - fn: 432.5333 - fp: 384.7333 - tn: 2745.9333 - tp: 1132.8000 - precision: 0.7642 - recall: 0.7066 - val_loss: 0.3978 - val_fn: 349.0000 - val_fp: 386.0000 - val_tn: 1878.0000 - val_tp: 783.0000 - val_precision: 0.6698 - val_recall: 0.6917\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3108 - fn: 461.2667 - fp: 415.4667 - tn: 2715.2000 - tp: 1104.0667 - precision: 0.7103 - recall: 0.6937 - val_loss: 0.3106 - val_fn: 212.0000 - val_fp: 168.0000 - val_tn: 2096.0000 - val_tp: 920.0000 - val_precision: 0.8456 - val_recall: 0.8127\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.3141 - fn: 440.8000 - fp: 404.0667 - tn: 2726.6000 - tp: 1124.5333 - precision: 0.7486 - recall: 0.7303 - val_loss: 0.2402 - val_fn: 132.0000 - val_fp: 110.0000 - val_tn: 2154.0000 - val_tp: 1000.0000 - val_precision: 0.9009 - val_recall: 0.8834\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2771 - fn: 395.5333 - fp: 357.4667 - tn: 2773.2000 - tp: 1169.8000 - precision: 0.7876 - recall: 0.7722 - val_loss: 0.2733 - val_fn: 171.0000 - val_fp: 169.0000 - val_tn: 2095.0000 - val_tp: 961.0000 - val_precision: 0.8504 - val_recall: 0.8489\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2961 - fn: 438.3333 - fp: 469.8000 - tn: 2660.8667 - tp: 1127.0000 - precision: 0.7197 - recall: 0.7302 - val_loss: 0.2678 - val_fn: 198.0000 - val_fp: 155.0000 - val_tn: 2109.0000 - val_tp: 934.0000 - val_precision: 0.8577 - val_recall: 0.8251\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2682 - fn: 398.8000 - fp: 356.8667 - tn: 2773.8000 - tp: 1166.5333 - precision: 0.7946 - recall: 0.7682 - val_loss: 0.2831 - val_fn: 149.0000 - val_fp: 238.0000 - val_tn: 2026.0000 - val_tp: 983.0000 - val_precision: 0.8051 - val_recall: 0.8684\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2751 - fn: 392.2667 - fp: 441.1333 - tn: 2689.5333 - tp: 1173.0667 - precision: 0.7323 - recall: 0.7709 - val_loss: 0.3376 - val_fn: 290.0000 - val_fp: 243.0000 - val_tn: 2021.0000 - val_tp: 842.0000 - val_precision: 0.7760 - val_recall: 0.7438\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2491 - fn: 454.5333 - fp: 403.0000 - tn: 2727.6667 - tp: 1110.8000 - precision: 0.7242 - recall: 0.6941 - val_loss: 0.3445 - val_fn: 275.0000 - val_fp: 308.0000 - val_tn: 1956.0000 - val_tp: 857.0000 - val_precision: 0.7356 - val_recall: 0.7571\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2632 - fn: 480.4000 - fp: 485.0000 - tn: 2645.6667 - tp: 1084.9333 - precision: 0.6876 - recall: 0.6930 - val_loss: 0.3055 - val_fn: 237.0000 - val_fp: 225.0000 - val_tn: 2039.0000 - val_tp: 895.0000 - val_precision: 0.7991 - val_recall: 0.7906\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2628 - fn: 368.6000 - fp: 364.0667 - tn: 2766.6000 - tp: 1196.7333 - precision: 0.7684 - recall: 0.7609 - val_loss: 0.2959 - val_fn: 213.0000 - val_fp: 236.0000 - val_tn: 2028.0000 - val_tp: 919.0000 - val_precision: 0.7957 - val_recall: 0.8118\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2391 - fn: 317.4667 - fp: 317.1333 - tn: 2813.5333 - tp: 1247.8667 - precision: 0.7996 - recall: 0.8044 - val_loss: 0.3868 - val_fn: 345.0000 - val_fp: 351.0000 - val_tn: 1913.0000 - val_tp: 787.0000 - val_precision: 0.6916 - val_recall: 0.6952\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2565 - fn: 441.2000 - fp: 455.7333 - tn: 2674.9333 - tp: 1124.1333 - precision: 0.6938 - recall: 0.6961 - val_loss: 0.3998 - val_fn: 364.0000 - val_fp: 366.0000 - val_tn: 1898.0000 - val_tp: 768.0000 - val_precision: 0.6772 - val_recall: 0.6784\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2369 - fn: 413.4000 - fp: 404.4667 - tn: 2726.2000 - tp: 1151.9333 - precision: 0.7292 - recall: 0.7257 - val_loss: 0.3242 - val_fn: 257.0000 - val_fp: 262.0000 - val_tn: 2002.0000 - val_tp: 875.0000 - val_precision: 0.7696 - val_recall: 0.7730\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2398 - fn: 324.4667 - fp: 330.1333 - tn: 2800.5333 - tp: 1240.8667 - precision: 0.7935 - recall: 0.7926 - val_loss: 0.3668 - val_fn: 311.0000 - val_fp: 325.0000 - val_tn: 1939.0000 - val_tp: 821.0000 - val_precision: 0.7164 - val_recall: 0.7253\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2403 - fn: 401.0667 - fp: 399.5333 - tn: 2731.1333 - tp: 1164.2667 - precision: 0.7294 - recall: 0.7294 - val_loss: 0.3447 - val_fn: 287.0000 - val_fp: 283.0000 - val_tn: 1981.0000 - val_tp: 845.0000 - val_precision: 0.7491 - val_recall: 0.7465\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2417 - fn: 314.3333 - fp: 315.9333 - tn: 2814.7333 - tp: 1251.0000 - precision: 0.7937 - recall: 0.7910 - val_loss: 0.4418 - val_fn: 420.0000 - val_fp: 417.0000 - val_tn: 1847.0000 - val_tp: 712.0000 - val_precision: 0.6306 - val_recall: 0.6290\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2373 - fn: 389.2000 - fp: 387.2000 - tn: 2743.4667 - tp: 1176.1333 - precision: 0.7240 - recall: 0.7229 - val_loss: 0.4314 - val_fn: 381.0000 - val_fp: 415.0000 - val_tn: 1849.0000 - val_tp: 751.0000 - val_precision: 0.6441 - val_recall: 0.6634\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2328 - fn: 381.9333 - fp: 414.0667 - tn: 2716.6000 - tp: 1183.4000 - precision: 0.7208 - recall: 0.7383 - val_loss: 0.3266 - val_fn: 271.0000 - val_fp: 256.0000 - val_tn: 2008.0000 - val_tp: 861.0000 - val_precision: 0.7708 - val_recall: 0.7606\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2452 - fn: 327.0000 - fp: 297.4667 - tn: 2833.2000 - tp: 1238.3333 - precision: 0.8024 - recall: 0.7852 - val_loss: 0.2514 - val_fn: 177.0000 - val_fp: 174.0000 - val_tn: 2090.0000 - val_tp: 955.0000 - val_precision: 0.8459 - val_recall: 0.8436\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2320 - fn: 285.0667 - fp: 307.2667 - tn: 2823.4000 - tp: 1280.2667 - precision: 0.8215 - recall: 0.8305 - val_loss: 0.2603 - val_fn: 185.0000 - val_fp: 193.0000 - val_tn: 2071.0000 - val_tp: 947.0000 - val_precision: 0.8307 - val_recall: 0.8366\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2375 - fn: 355.4667 - fp: 347.6000 - tn: 2783.0667 - tp: 1209.8667 - precision: 0.7923 - recall: 0.7904 - val_loss: 0.2101 - val_fn: 124.0000 - val_fp: 111.0000 - val_tn: 2153.0000 - val_tp: 1008.0000 - val_precision: 0.9008 - val_recall: 0.8905\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2314 - fn: 260.8667 - fp: 269.4000 - tn: 2861.2667 - tp: 1304.4667 - precision: 0.8449 - recall: 0.8483 - val_loss: 0.3282 - val_fn: 274.0000 - val_fp: 258.0000 - val_tn: 2006.0000 - val_tp: 858.0000 - val_precision: 0.7688 - val_recall: 0.7580\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2274 - fn: 326.3333 - fp: 268.3333 - tn: 2862.3333 - tp: 1239.0000 - precision: 0.8104 - recall: 0.7786 - val_loss: 0.3715 - val_fn: 301.0000 - val_fp: 347.0000 - val_tn: 1917.0000 - val_tp: 831.0000 - val_precision: 0.7054 - val_recall: 0.7341\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2180 - fn: 339.8000 - fp: 384.1333 - tn: 2746.5333 - tp: 1225.5333 - precision: 0.7566 - recall: 0.7792 - val_loss: 0.4004 - val_fn: 371.0000 - val_fp: 344.0000 - val_tn: 1920.0000 - val_tp: 761.0000 - val_precision: 0.6887 - val_recall: 0.6723\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2303 - fn: 282.2000 - fp: 262.5333 - tn: 2868.1333 - tp: 1283.1333 - precision: 0.8117 - recall: 0.7985 - val_loss: 0.5687 - val_fn: 574.0000 - val_fp: 589.0000 - val_tn: 1675.0000 - val_tp: 558.0000 - val_precision: 0.4865 - val_recall: 0.4929\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2495 - fn: 385.8000 - fp: 415.0000 - tn: 2715.6667 - tp: 1179.5333 - precision: 0.6909 - recall: 0.7055 - val_loss: 0.4725 - val_fn: 454.0000 - val_fp: 461.0000 - val_tn: 1803.0000 - val_tp: 678.0000 - val_precision: 0.5953 - val_recall: 0.5989\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2341 - fn: 392.1333 - fp: 402.8000 - tn: 2727.8667 - tp: 1173.2000 - precision: 0.7053 - recall: 0.7084 - val_loss: 0.3377 - val_fn: 277.0000 - val_fp: 288.0000 - val_tn: 1976.0000 - val_tp: 855.0000 - val_precision: 0.7480 - val_recall: 0.7553\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1918 - fn: 279.0667 - fp: 299.2000 - tn: 2831.4667 - tp: 1286.2667 - precision: 0.7999 - recall: 0.8136 - val_loss: 0.3622 - val_fn: 322.0000 - val_fp: 320.0000 - val_tn: 1944.0000 - val_tp: 810.0000 - val_precision: 0.7168 - val_recall: 0.7155\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2085 - fn: 299.1333 - fp: 310.8000 - tn: 2819.8667 - tp: 1266.2000 - precision: 0.7841 - recall: 0.7907 - val_loss: 0.2770 - val_fn: 197.0000 - val_fp: 209.0000 - val_tn: 2055.0000 - val_tp: 935.0000 - val_precision: 0.8173 - val_recall: 0.8260\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1821 - fn: 243.0000 - fp: 243.0000 - tn: 2887.6667 - tp: 1322.3333 - precision: 0.8503 - recall: 0.8516 - val_loss: 0.2691 - val_fn: 201.0000 - val_fp: 183.0000 - val_tn: 2081.0000 - val_tp: 931.0000 - val_precision: 0.8357 - val_recall: 0.8224\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1755 - fn: 279.6000 - fp: 272.0000 - tn: 2858.6667 - tp: 1285.7333 - precision: 0.8292 - recall: 0.8260 - val_loss: 0.2420 - val_fn: 166.0000 - val_fp: 151.0000 - val_tn: 2113.0000 - val_tp: 966.0000 - val_precision: 0.8648 - val_recall: 0.8534\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1645 - fn: 226.2667 - fp: 233.8000 - tn: 2896.8667 - tp: 1339.0667 - precision: 0.8583 - recall: 0.8606 - val_loss: 0.2092 - val_fn: 125.0000 - val_fp: 121.0000 - val_tn: 2143.0000 - val_tp: 1007.0000 - val_precision: 0.8927 - val_recall: 0.8896\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1575 - fn: 201.6667 - fp: 193.3333 - tn: 2937.3333 - tp: 1363.6667 - precision: 0.8816 - recall: 0.8776 - val_loss: 0.2171 - val_fn: 134.0000 - val_fp: 131.0000 - val_tn: 2133.0000 - val_tp: 998.0000 - val_precision: 0.8840 - val_recall: 0.8816\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1713 - fn: 219.9333 - fp: 227.2667 - tn: 2903.4000 - tp: 1345.4000 - precision: 0.8568 - recall: 0.8600 - val_loss: 0.1553 - val_fn: 83.0000 - val_fp: 71.0000 - val_tn: 2193.0000 - val_tp: 1049.0000 - val_precision: 0.9366 - val_recall: 0.9267\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1717 - fn: 219.1333 - fp: 200.8667 - tn: 2929.8000 - tp: 1346.2000 - precision: 0.8837 - recall: 0.8724 - val_loss: 0.2061 - val_fn: 130.0000 - val_fp: 117.0000 - val_tn: 2147.0000 - val_tp: 1002.0000 - val_precision: 0.8954 - val_recall: 0.8852\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1402 - fn: 201.0667 - fp: 196.7333 - tn: 2933.9333 - tp: 1364.2667 - precision: 0.8807 - recall: 0.8790 - val_loss: 0.2671 - val_fn: 187.0000 - val_fp: 185.0000 - val_tn: 2079.0000 - val_tp: 945.0000 - val_precision: 0.8363 - val_recall: 0.8348\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1419 - fn: 220.1333 - fp: 218.7333 - tn: 2911.9333 - tp: 1345.2000 - precision: 0.8570 - recall: 0.8559 - val_loss: 0.1330 - val_fn: 59.0000 - val_fp: 52.0000 - val_tn: 2212.0000 - val_tp: 1073.0000 - val_precision: 0.9538 - val_recall: 0.9479\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1723 - fn: 223.1333 - fp: 211.7333 - tn: 2918.9333 - tp: 1342.2000 - precision: 0.8737 - recall: 0.8668 - val_loss: 0.3982 - val_fn: 341.0000 - val_fp: 353.0000 - val_tn: 1911.0000 - val_tp: 791.0000 - val_precision: 0.6914 - val_recall: 0.6988\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1848 - fn: 342.7333 - fp: 341.0667 - tn: 2789.6000 - tp: 1222.6000 - precision: 0.7534 - recall: 0.7512 - val_loss: 0.3688 - val_fn: 269.0000 - val_fp: 301.0000 - val_tn: 1963.0000 - val_tp: 863.0000 - val_precision: 0.7414 - val_recall: 0.7624\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1720 - fn: 251.3333 - fp: 262.6000 - tn: 2868.0667 - tp: 1314.0000 - precision: 0.8110 - recall: 0.8191 - val_loss: 0.3178 - val_fn: 253.0000 - val_fp: 251.0000 - val_tn: 2013.0000 - val_tp: 879.0000 - val_precision: 0.7779 - val_recall: 0.7765\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1452 - fn: 196.4000 - fp: 191.4000 - tn: 2939.2667 - tp: 1368.9333 - precision: 0.8650 - recall: 0.8587 - val_loss: 0.2079 - val_fn: 117.0000 - val_fp: 107.0000 - val_tn: 2157.0000 - val_tp: 1015.0000 - val_precision: 0.9046 - val_recall: 0.8966\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1315 - fn: 146.1333 - fp: 150.3333 - tn: 2980.3333 - tp: 1419.2000 - precision: 0.9024 - recall: 0.9053 - val_loss: 0.2243 - val_fn: 142.0000 - val_fp: 140.0000 - val_tn: 2124.0000 - val_tp: 990.0000 - val_precision: 0.8761 - val_recall: 0.8746\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1225 - fn: 140.9333 - fp: 136.2667 - tn: 2994.4000 - tp: 1424.4000 - precision: 0.9011 - recall: 0.9004 - val_loss: 0.1859 - val_fn: 107.0000 - val_fp: 96.0000 - val_tn: 2168.0000 - val_tp: 1025.0000 - val_precision: 0.9144 - val_recall: 0.9055\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1037 - fn: 124.7333 - fp: 117.1333 - tn: 3013.5333 - tp: 1440.6000 - precision: 0.9274 - recall: 0.9215 - val_loss: 0.1255 - val_fn: 55.0000 - val_fp: 44.0000 - val_tn: 2220.0000 - val_tp: 1077.0000 - val_precision: 0.9607 - val_recall: 0.9514\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.1082 - fn: 105.6000 - fp: 95.4000 - tn: 3035.2667 - tp: 1459.7333 - precision: 0.9425 - recall: 0.9369 - val_loss: 0.1563 - val_fn: 71.0000 - val_fp: 60.0000 - val_tn: 2204.0000 - val_tp: 1061.0000 - val_precision: 0.9465 - val_recall: 0.9373\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0859 - fn: 99.4667 - fp: 93.2667 - tn: 3037.4000 - tp: 1465.8667 - precision: 0.9404 - recall: 0.9370 - val_loss: 0.2487 - val_fn: 154.0000 - val_fp: 150.0000 - val_tn: 2114.0000 - val_tp: 978.0000 - val_precision: 0.8670 - val_recall: 0.8640\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1093 - fn: 165.2667 - fp: 147.6000 - tn: 2983.0667 - tp: 1400.0667 - precision: 0.9053 - recall: 0.8960 - val_loss: 0.1176 - val_fn: 36.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1096.0000 - val_precision: 0.9673 - val_recall: 0.9682\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1520 - fn: 137.2667 - fp: 135.6000 - tn: 2995.0667 - tp: 1428.0667 - precision: 0.9184 - recall: 0.9220 - val_loss: 0.1007 - val_fn: 39.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1093.0000 - val_precision: 0.9664 - val_recall: 0.9655\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1232 - fn: 120.3333 - fp: 112.2667 - tn: 3018.4000 - tp: 1445.0000 - precision: 0.9336 - recall: 0.9284 - val_loss: 0.2120 - val_fn: 124.0000 - val_fp: 113.0000 - val_tn: 2151.0000 - val_tp: 1008.0000 - val_precision: 0.8992 - val_recall: 0.8905\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1016 - fn: 93.9333 - fp: 94.8667 - tn: 3035.8000 - tp: 1471.4000 - precision: 0.9306 - recall: 0.9302 - val_loss: 0.1254 - val_fn: 47.0000 - val_fp: 43.0000 - val_tn: 2221.0000 - val_tp: 1085.0000 - val_precision: 0.9619 - val_recall: 0.9585\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0950 - fn: 96.9333 - fp: 86.2667 - tn: 3044.4000 - tp: 1468.4000 - precision: 0.9478 - recall: 0.9426 - val_loss: 0.1169 - val_fn: 42.0000 - val_fp: 42.0000 - val_tn: 2222.0000 - val_tp: 1090.0000 - val_precision: 0.9629 - val_recall: 0.9629\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0786 - fn: 83.9333 - fp: 74.8667 - tn: 3055.8000 - tp: 1481.4000 - precision: 0.9533 - recall: 0.9496 - val_loss: 0.1972 - val_fn: 103.0000 - val_fp: 92.0000 - val_tn: 2172.0000 - val_tp: 1029.0000 - val_precision: 0.9179 - val_recall: 0.9090\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0822 - fn: 106.1333 - fp: 98.3333 - tn: 3032.3333 - tp: 1459.2000 - precision: 0.9318 - recall: 0.9277 - val_loss: 0.1040 - val_fn: 34.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1098.0000 - val_precision: 0.9734 - val_recall: 0.9700\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0809 - fn: 103.2000 - fp: 100.4000 - tn: 3030.2667 - tp: 1462.1333 - precision: 0.9479 - recall: 0.9451 - val_loss: 0.1867 - val_fn: 88.0000 - val_fp: 87.0000 - val_tn: 2177.0000 - val_tp: 1044.0000 - val_precision: 0.9231 - val_recall: 0.9223\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0967 - fn: 148.5333 - fp: 139.5333 - tn: 2991.1333 - tp: 1416.8000 - precision: 0.9010 - recall: 0.8952 - val_loss: 0.1227 - val_fn: 43.0000 - val_fp: 41.0000 - val_tn: 2223.0000 - val_tp: 1089.0000 - val_precision: 0.9637 - val_recall: 0.9620\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0621 - fn: 63.0667 - fp: 60.8000 - tn: 3069.8667 - tp: 1502.2667 - precision: 0.9647 - recall: 0.9643 - val_loss: 0.0944 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0819 - fn: 63.6000 - fp: 61.2667 - tn: 3069.4000 - tp: 1501.7333 - precision: 0.9657 - recall: 0.9647 - val_loss: 0.1144 - val_fn: 49.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1083.0000 - val_precision: 0.9730 - val_recall: 0.9567\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0838 - fn: 62.6000 - fp: 53.6667 - tn: 3077.0000 - tp: 1502.7333 - precision: 0.9687 - recall: 0.9619 - val_loss: 0.1087 - val_fn: 37.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1095.0000 - val_precision: 0.9690 - val_recall: 0.9673\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0610 - fn: 58.0667 - fp: 55.2000 - tn: 3075.4667 - tp: 1507.2667 - precision: 0.9669 - recall: 0.9650 - val_loss: 0.1188 - val_fn: 40.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1092.0000 - val_precision: 0.9655 - val_recall: 0.9647\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0563 - fn: 51.2667 - fp: 57.3333 - tn: 3073.3333 - tp: 1514.0667 - precision: 0.9646 - recall: 0.9687 - val_loss: 0.1126 - val_fn: 44.0000 - val_fp: 42.0000 - val_tn: 2222.0000 - val_tp: 1088.0000 - val_precision: 0.9628 - val_recall: 0.9611\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0680 - fn: 67.8000 - fp: 56.7333 - tn: 3073.9333 - tp: 1497.5333 - precision: 0.9646 - recall: 0.9590 - val_loss: 0.1232 - val_fn: 46.0000 - val_fp: 44.0000 - val_tn: 2220.0000 - val_tp: 1086.0000 - val_precision: 0.9611 - val_recall: 0.9594\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0496 - fn: 46.2000 - fp: 41.8000 - tn: 3088.8667 - tp: 1519.1333 - precision: 0.9741 - recall: 0.9716 - val_loss: 0.1078 - val_fn: 37.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1095.0000 - val_precision: 0.9707 - val_recall: 0.9673\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0547 - fn: 44.1333 - fp: 42.4000 - tn: 3088.2667 - tp: 1521.2000 - precision: 0.9755 - recall: 0.9739 - val_loss: 0.1164 - val_fn: 37.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1095.0000 - val_precision: 0.9690 - val_recall: 0.9673\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0530 - fn: 48.6667 - fp: 47.5333 - tn: 3083.1333 - tp: 1516.6667 - precision: 0.9748 - recall: 0.9740 - val_loss: 0.0970 - val_fn: 25.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1107.0000 - val_precision: 0.9771 - val_recall: 0.9779\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0471 - fn: 56.2667 - fp: 55.0000 - tn: 3075.6667 - tp: 1509.0667 - precision: 0.9674 - recall: 0.9664 - val_loss: 0.1560 - val_fn: 59.0000 - val_fp: 55.0000 - val_tn: 2209.0000 - val_tp: 1073.0000 - val_precision: 0.9512 - val_recall: 0.9479\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0516 - fn: 51.4000 - fp: 47.9333 - tn: 3082.7333 - tp: 1513.9333 - precision: 0.9670 - recall: 0.9649 - val_loss: 0.1004 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1101.0000 - val_precision: 0.9743 - val_recall: 0.9726\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0536 - fn: 58.8667 - fp: 56.6000 - tn: 3074.0667 - tp: 1506.4667 - precision: 0.9685 - recall: 0.9673 - val_loss: 0.1728 - val_fn: 74.0000 - val_fp: 74.0000 - val_tn: 2190.0000 - val_tp: 1058.0000 - val_precision: 0.9346 - val_recall: 0.9346\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0612 - fn: 74.0667 - fp: 75.4000 - tn: 3055.2667 - tp: 1491.2667 - precision: 0.9464 - recall: 0.9476 - val_loss: 0.1234 - val_fn: 46.0000 - val_fp: 49.0000 - val_tn: 2215.0000 - val_tp: 1086.0000 - val_precision: 0.9568 - val_recall: 0.9594\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0489 - fn: 53.6667 - fp: 56.6000 - tn: 3074.0667 - tp: 1511.6667 - precision: 0.9590 - recall: 0.9609 - val_loss: 0.1090 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0265 - fn: 27.8000 - fp: 26.2667 - tn: 3104.4000 - tp: 1537.5333 - precision: 0.9859 - recall: 0.9850 - val_loss: 0.1103 - val_fn: 33.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1099.0000 - val_precision: 0.9717 - val_recall: 0.9708\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0346 - fn: 39.6000 - fp: 36.2000 - tn: 3094.4667 - tp: 1525.7333 - precision: 0.9788 - recall: 0.9765 - val_loss: 0.1215 - val_fn: 39.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1093.0000 - val_precision: 0.9647 - val_recall: 0.9655\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0344 - fn: 40.5333 - fp: 40.2667 - tn: 3090.4000 - tp: 1524.8000 - precision: 0.9731 - recall: 0.9743 - val_loss: 0.1098 - val_fn: 35.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1097.0000 - val_precision: 0.9717 - val_recall: 0.9691\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0516 - fn: 51.0667 - fp: 51.6000 - tn: 3079.0667 - tp: 1514.2667 - precision: 0.9688 - recall: 0.9677 - val_loss: 0.1606 - val_fn: 61.0000 - val_fp: 62.0000 - val_tn: 2202.0000 - val_tp: 1071.0000 - val_precision: 0.9453 - val_recall: 0.9461\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0560 - fn: 63.4000 - fp: 64.0667 - tn: 3066.6000 - tp: 1501.9333 - precision: 0.9575 - recall: 0.9574 - val_loss: 0.1080 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0423 - fn: 38.4667 - fp: 40.8000 - tn: 3089.8667 - tp: 1526.8667 - precision: 0.9752 - recall: 0.9767 - val_loss: 0.1379 - val_fn: 53.0000 - val_fp: 52.0000 - val_tn: 2212.0000 - val_tp: 1079.0000 - val_precision: 0.9540 - val_recall: 0.9532\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0396 - fn: 45.9333 - fp: 43.4667 - tn: 3087.2000 - tp: 1519.4000 - precision: 0.9682 - recall: 0.9664 - val_loss: 0.2307 - val_fn: 109.0000 - val_fp: 108.0000 - val_tn: 2156.0000 - val_tp: 1023.0000 - val_precision: 0.9045 - val_recall: 0.9037\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0591 - fn: 76.0000 - fp: 72.1333 - tn: 3058.5333 - tp: 1489.3333 - precision: 0.9449 - recall: 0.9427 - val_loss: 0.1610 - val_fn: 56.0000 - val_fp: 54.0000 - val_tn: 2210.0000 - val_tp: 1076.0000 - val_precision: 0.9522 - val_recall: 0.9505\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0583 - fn: 74.4000 - fp: 74.0000 - tn: 3056.6667 - tp: 1490.9333 - precision: 0.9520 - recall: 0.9512 - val_loss: 0.1960 - val_fn: 77.0000 - val_fp: 78.0000 - val_tn: 2186.0000 - val_tp: 1055.0000 - val_precision: 0.9312 - val_recall: 0.9320\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0658 - fn: 68.0000 - fp: 68.3333 - tn: 3062.3333 - tp: 1497.3333 - precision: 0.9502 - recall: 0.9507 - val_loss: 0.1172 - val_fn: 37.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1095.0000 - val_precision: 0.9673 - val_recall: 0.9673\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0421 - fn: 36.9333 - fp: 33.3333 - tn: 3097.3333 - tp: 1528.4000 - precision: 0.9796 - recall: 0.9778 - val_loss: 0.1083 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0387 - fn: 38.8667 - fp: 35.4667 - tn: 3095.2000 - tp: 1526.4667 - precision: 0.9814 - recall: 0.9786 - val_loss: 0.1081 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0291 - fn: 28.8000 - fp: 27.2000 - tn: 3103.4667 - tp: 1536.5333 - precision: 0.9862 - recall: 0.9847 - val_loss: 0.1072 - val_fn: 26.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1106.0000 - val_precision: 0.9796 - val_recall: 0.9770\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0345 - fn: 34.3333 - fp: 34.1333 - tn: 3096.5333 - tp: 1531.0000 - precision: 0.9789 - recall: 0.9796 - val_loss: 0.1075 - val_fn: 29.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1103.0000 - val_precision: 0.9770 - val_recall: 0.9744\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0265 - fn: 24.6667 - fp: 24.6000 - tn: 3106.0667 - tp: 1540.6667 - precision: 0.9849 - recall: 0.9853 - val_loss: 0.1130 - val_fn: 33.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1099.0000 - val_precision: 0.9708 - val_recall: 0.9708\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0257 - fn: 29.7333 - fp: 25.6000 - tn: 3105.0667 - tp: 1535.6000 - precision: 0.9844 - recall: 0.9814 - val_loss: 0.1123 - val_fn: 29.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1103.0000 - val_precision: 0.9761 - val_recall: 0.9744\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0322 - fn: 30.0667 - fp: 30.6000 - tn: 3100.0667 - tp: 1535.2667 - precision: 0.9839 - recall: 0.9839 - val_loss: 0.1091 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0608 - fn: 69.1333 - fp: 68.8667 - tn: 3061.8000 - tp: 1496.2000 - precision: 0.9588 - recall: 0.9585 - val_loss: 0.1449 - val_fn: 55.0000 - val_fp: 53.0000 - val_tn: 2211.0000 - val_tp: 1077.0000 - val_precision: 0.9531 - val_recall: 0.9514\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0400 - fn: 54.8667 - fp: 55.6667 - tn: 3075.0000 - tp: 1510.4667 - precision: 0.9630 - recall: 0.9635 - val_loss: 0.1119 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0393 - fn: 33.2667 - fp: 30.5333 - tn: 3100.1333 - tp: 1532.0667 - precision: 0.9813 - recall: 0.9794 - val_loss: 0.1233 - val_fn: 40.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1092.0000 - val_precision: 0.9655 - val_recall: 0.9647\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0309 - fn: 42.2000 - fp: 43.7333 - tn: 3086.9333 - tp: 1523.1333 - precision: 0.9730 - recall: 0.9740 - val_loss: 0.1087 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0358 - fn: 41.3333 - fp: 42.1333 - tn: 3088.5333 - tp: 1524.0000 - precision: 0.9738 - recall: 0.9739 - val_loss: 0.1383 - val_fn: 46.0000 - val_fp: 45.0000 - val_tn: 2219.0000 - val_tp: 1086.0000 - val_precision: 0.9602 - val_recall: 0.9594\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0361 - fn: 46.2667 - fp: 41.6000 - tn: 3089.0667 - tp: 1519.0667 - precision: 0.9705 - recall: 0.9678 - val_loss: 0.1301 - val_fn: 41.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1091.0000 - val_precision: 0.9646 - val_recall: 0.9638\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0289 - fn: 42.1333 - fp: 36.4000 - tn: 3094.2667 - tp: 1523.2000 - precision: 0.9750 - recall: 0.9709 - val_loss: 0.1276 - val_fn: 41.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1091.0000 - val_precision: 0.9646 - val_recall: 0.9638\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0263 - fn: 39.8667 - fp: 35.4000 - tn: 3095.2667 - tp: 1525.4667 - precision: 0.9767 - recall: 0.9738 - val_loss: 0.1136 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0292 - fn: 37.0000 - fp: 34.8000 - tn: 3095.8667 - tp: 1528.3333 - precision: 0.9822 - recall: 0.9810 - val_loss: 0.1217 - val_fn: 33.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1099.0000 - val_precision: 0.9717 - val_recall: 0.9708\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0490 - fn: 85.8667 - fp: 86.1333 - tn: 3044.5333 - tp: 1479.4667 - precision: 0.9423 - recall: 0.9426 - val_loss: 0.1455 - val_fn: 55.0000 - val_fp: 52.0000 - val_tn: 2212.0000 - val_tp: 1077.0000 - val_precision: 0.9539 - val_recall: 0.9514\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0669 - fn: 66.6667 - fp: 65.2000 - tn: 3065.4667 - tp: 1498.6667 - precision: 0.9600 - recall: 0.9601 - val_loss: 0.2013 - val_fn: 77.0000 - val_fp: 78.0000 - val_tn: 2186.0000 - val_tp: 1055.0000 - val_precision: 0.9312 - val_recall: 0.9320\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0822 - fn: 124.8000 - fp: 123.8667 - tn: 3006.8000 - tp: 1440.5333 - precision: 0.9130 - recall: 0.9128 - val_loss: 0.1332 - val_fn: 50.0000 - val_fp: 48.0000 - val_tn: 2216.0000 - val_tp: 1082.0000 - val_precision: 0.9575 - val_recall: 0.9558\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0704 - fn: 69.6000 - fp: 70.7333 - tn: 3059.9333 - tp: 1495.7333 - precision: 0.9600 - recall: 0.9602 - val_loss: 0.1274 - val_fn: 34.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1098.0000 - val_precision: 0.9708 - val_recall: 0.9700\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0494 - fn: 62.2667 - fp: 63.3333 - tn: 3067.3333 - tp: 1503.0667 - precision: 0.9622 - recall: 0.9627 - val_loss: 0.1233 - val_fn: 33.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1099.0000 - val_precision: 0.9726 - val_recall: 0.9708\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0467 - fn: 51.8000 - fp: 47.0667 - tn: 3083.6000 - tp: 1513.5333 - precision: 0.9708 - recall: 0.9683 - val_loss: 0.1085 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0340 - fn: 51.6667 - fp: 44.4000 - tn: 3086.2667 - tp: 1513.6667 - precision: 0.9728 - recall: 0.9676 - val_loss: 0.1236 - val_fn: 42.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1090.0000 - val_precision: 0.9646 - val_recall: 0.9629\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0361 - fn: 48.2667 - fp: 44.2667 - tn: 3086.4000 - tp: 1517.0667 - precision: 0.9708 - recall: 0.9676 - val_loss: 0.1523 - val_fn: 51.0000 - val_fp: 50.0000 - val_tn: 2214.0000 - val_tp: 1081.0000 - val_precision: 0.9558 - val_recall: 0.9549\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0382 - fn: 42.6667 - fp: 43.6667 - tn: 3087.0000 - tp: 1522.6667 - precision: 0.9670 - recall: 0.9677 - val_loss: 0.1410 - val_fn: 45.0000 - val_fp: 45.0000 - val_tn: 2219.0000 - val_tp: 1087.0000 - val_precision: 0.9602 - val_recall: 0.9602\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0351 - fn: 34.0000 - fp: 33.6667 - tn: 3097.0000 - tp: 1531.3333 - precision: 0.9786 - recall: 0.9782 - val_loss: 0.1145 - val_fn: 27.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1105.0000 - val_precision: 0.9753 - val_recall: 0.9761\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0283 - fn: 24.1333 - fp: 25.2000 - tn: 3105.4667 - tp: 1541.2000 - precision: 0.9846 - recall: 0.9859 - val_loss: 0.1243 - val_fn: 35.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1097.0000 - val_precision: 0.9691 - val_recall: 0.9691\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0281 - fn: 30.4667 - fp: 30.6000 - tn: 3100.0667 - tp: 1534.8667 - precision: 0.9792 - recall: 0.9800 - val_loss: 0.1201 - val_fn: 33.0000 - val_fp: 34.0000 - val_tn: 2230.0000 - val_tp: 1099.0000 - val_precision: 0.9700 - val_recall: 0.9708\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0280 - fn: 30.1333 - fp: 28.7333 - tn: 3101.9333 - tp: 1535.2000 - precision: 0.9813 - recall: 0.9798 - val_loss: 0.1240 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0307 - fn: 31.1333 - fp: 29.6667 - tn: 3101.0000 - tp: 1534.2000 - precision: 0.9793 - recall: 0.9783 - val_loss: 0.1489 - val_fn: 44.0000 - val_fp: 44.0000 - val_tn: 2220.0000 - val_tp: 1088.0000 - val_precision: 0.9611 - val_recall: 0.9611\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0332 - fn: 38.3333 - fp: 37.2000 - tn: 3093.4667 - tp: 1527.0000 - precision: 0.9728 - recall: 0.9727 - val_loss: 0.1352 - val_fn: 42.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1090.0000 - val_precision: 0.9646 - val_recall: 0.9629\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0254 - fn: 25.4000 - fp: 23.6000 - tn: 3107.0667 - tp: 1539.9333 - precision: 0.9815 - recall: 0.9805 - val_loss: 0.1245 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0198 - fn: 23.4667 - fp: 22.8667 - tn: 3107.8000 - tp: 1541.8667 - precision: 0.9853 - recall: 0.9848 - val_loss: 0.1349 - val_fn: 37.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1095.0000 - val_precision: 0.9690 - val_recall: 0.9673\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0211 - fn: 31.1333 - fp: 28.3333 - tn: 3102.3333 - tp: 1534.2000 - precision: 0.9809 - recall: 0.9796 - val_loss: 0.1224 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0294 - fn: 39.4000 - fp: 35.7333 - tn: 3094.9333 - tp: 1525.9333 - precision: 0.9765 - recall: 0.9748 - val_loss: 0.1238 - val_fn: 27.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1105.0000 - val_precision: 0.9753 - val_recall: 0.9761\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0347 - fn: 45.3333 - fp: 41.8000 - tn: 3088.8667 - tp: 1520.0000 - precision: 0.9772 - recall: 0.9742 - val_loss: 0.1192 - val_fn: 27.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1105.0000 - val_precision: 0.9779 - val_recall: 0.9761\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0313 - fn: 36.8000 - fp: 33.7333 - tn: 3096.9333 - tp: 1528.5333 - precision: 0.9792 - recall: 0.9775 - val_loss: 0.1300 - val_fn: 35.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1097.0000 - val_precision: 0.9691 - val_recall: 0.9691\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0318 - fn: 49.3333 - fp: 47.1333 - tn: 3083.5333 - tp: 1516.0000 - precision: 0.9704 - recall: 0.9688 - val_loss: 0.3121 - val_fn: 152.0000 - val_fp: 157.0000 - val_tn: 2107.0000 - val_tp: 980.0000 - val_precision: 0.8619 - val_recall: 0.8657\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0694 - fn: 106.4000 - fp: 104.2000 - tn: 3026.4667 - tp: 1458.9333 - precision: 0.9172 - recall: 0.9155 - val_loss: 0.1825 - val_fn: 70.0000 - val_fp: 68.0000 - val_tn: 2196.0000 - val_tp: 1062.0000 - val_precision: 0.9398 - val_recall: 0.9382\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0362 - fn: 43.8000 - fp: 42.1333 - tn: 3088.5333 - tp: 1521.5333 - precision: 0.9672 - recall: 0.9651 - val_loss: 0.1274 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0260 - fn: 31.0667 - fp: 26.2000 - tn: 3104.4667 - tp: 1534.2667 - precision: 0.9820 - recall: 0.9787 - val_loss: 0.1264 - val_fn: 32.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1100.0000 - val_precision: 0.9735 - val_recall: 0.9717\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0249 - fn: 31.4000 - fp: 28.8000 - tn: 3101.8667 - tp: 1533.9333 - precision: 0.9789 - recall: 0.9773 - val_loss: 0.1474 - val_fn: 44.0000 - val_fp: 45.0000 - val_tn: 2219.0000 - val_tp: 1088.0000 - val_precision: 0.9603 - val_recall: 0.9611\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0298 - fn: 36.3333 - fp: 36.1333 - tn: 3094.5333 - tp: 1529.0000 - precision: 0.9734 - recall: 0.9732 - val_loss: 0.1337 - val_fn: 37.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1095.0000 - val_precision: 0.9682 - val_recall: 0.9673\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0253 - fn: 28.4667 - fp: 28.8000 - tn: 3101.8667 - tp: 1536.8667 - precision: 0.9800 - recall: 0.9802 - val_loss: 0.1303 - val_fn: 32.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1100.0000 - val_precision: 0.9717 - val_recall: 0.9717\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0204 - fn: 25.6667 - fp: 22.5333 - tn: 3108.1333 - tp: 1539.6667 - precision: 0.9871 - recall: 0.9855 - val_loss: 0.1726 - val_fn: 57.0000 - val_fp: 56.0000 - val_tn: 2208.0000 - val_tp: 1075.0000 - val_precision: 0.9505 - val_recall: 0.9496\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0284 - fn: 42.6667 - fp: 35.1333 - tn: 3095.5333 - tp: 1522.6667 - precision: 0.9751 - recall: 0.9703 - val_loss: 0.1608 - val_fn: 48.0000 - val_fp: 47.0000 - val_tn: 2217.0000 - val_tp: 1084.0000 - val_precision: 0.9584 - val_recall: 0.9576\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0301 - fn: 40.2667 - fp: 37.2667 - tn: 3093.4000 - tp: 1525.0667 - precision: 0.9724 - recall: 0.9707 - val_loss: 0.1682 - val_fn: 49.0000 - val_fp: 50.0000 - val_tn: 2214.0000 - val_tp: 1083.0000 - val_precision: 0.9559 - val_recall: 0.9567\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0311 - fn: 40.9333 - fp: 37.9333 - tn: 3092.7333 - tp: 1524.4000 - precision: 0.9728 - recall: 0.9707 - val_loss: 0.1422 - val_fn: 39.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1093.0000 - val_precision: 0.9664 - val_recall: 0.9655\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0218 - fn: 29.2000 - fp: 30.0667 - tn: 3100.6000 - tp: 1536.1333 - precision: 0.9784 - recall: 0.9790 - val_loss: 0.1199 - val_fn: 23.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1109.0000 - val_precision: 0.9780 - val_recall: 0.9797\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0213 - fn: 24.2000 - fp: 24.1333 - tn: 3106.5333 - tp: 1541.1333 - precision: 0.9857 - recall: 0.9858 - val_loss: 0.1211 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0261 - fn: 27.8667 - fp: 25.7333 - tn: 3104.9333 - tp: 1537.4667 - precision: 0.9844 - recall: 0.9832 - val_loss: 0.1247 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0162 - fn: 21.4667 - fp: 19.2000 - tn: 3111.4667 - tp: 1543.8667 - precision: 0.9898 - recall: 0.9889 - val_loss: 0.1206 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0297 - fn: 25.1333 - fp: 27.0667 - tn: 3103.6000 - tp: 1540.2000 - precision: 0.9848 - recall: 0.9864 - val_loss: 0.1296 - val_fn: 32.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1100.0000 - val_precision: 0.9735 - val_recall: 0.9717\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0455 - fn: 77.0667 - fp: 71.0000 - tn: 3059.6667 - tp: 1488.2667 - precision: 0.9553 - recall: 0.9518 - val_loss: 0.2025 - val_fn: 78.0000 - val_fp: 75.0000 - val_tn: 2189.0000 - val_tp: 1054.0000 - val_precision: 0.9336 - val_recall: 0.9311\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0450 - fn: 61.2000 - fp: 57.8000 - tn: 3072.8667 - tp: 1504.1333 - precision: 0.9530 - recall: 0.9506 - val_loss: 0.2031 - val_fn: 76.0000 - val_fp: 75.0000 - val_tn: 2189.0000 - val_tp: 1056.0000 - val_precision: 0.9337 - val_recall: 0.9329\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0408 - fn: 60.8000 - fp: 63.7333 - tn: 3066.9333 - tp: 1504.5333 - precision: 0.9491 - recall: 0.9510 - val_loss: 0.1359 - val_fn: 40.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1092.0000 - val_precision: 0.9655 - val_recall: 0.9647\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0187 - fn: 25.3333 - fp: 30.2667 - tn: 3100.4000 - tp: 1540.0000 - precision: 0.9794 - recall: 0.9834 - val_loss: 0.1533 - val_fn: 44.0000 - val_fp: 42.0000 - val_tn: 2222.0000 - val_tp: 1088.0000 - val_precision: 0.9628 - val_recall: 0.9611\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0301 - fn: 45.4667 - fp: 41.0667 - tn: 3089.6000 - tp: 1519.8667 - precision: 0.9714 - recall: 0.9683 - val_loss: 0.1504 - val_fn: 43.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1089.0000 - val_precision: 0.9654 - val_recall: 0.9620\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0298 - fn: 44.7333 - fp: 42.2667 - tn: 3088.4000 - tp: 1520.6000 - precision: 0.9700 - recall: 0.9687 - val_loss: 0.1345 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0286 - fn: 25.9333 - fp: 25.4000 - tn: 3105.2667 - tp: 1539.4000 - precision: 0.9859 - recall: 0.9854 - val_loss: 0.1230 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0232 - fn: 27.8667 - fp: 25.0667 - tn: 3105.6000 - tp: 1537.4667 - precision: 0.9855 - recall: 0.9831 - val_loss: 0.1262 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0177 - fn: 21.0667 - fp: 19.8667 - tn: 3110.8000 - tp: 1544.2667 - precision: 0.9881 - recall: 0.9871 - val_loss: 0.1480 - val_fn: 42.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1090.0000 - val_precision: 0.9646 - val_recall: 0.9629\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0222 - fn: 34.2000 - fp: 35.4667 - tn: 3095.2000 - tp: 1531.1333 - precision: 0.9743 - recall: 0.9749 - val_loss: 0.1375 - val_fn: 34.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1098.0000 - val_precision: 0.9717 - val_recall: 0.9700\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0186 - fn: 20.6000 - fp: 20.4667 - tn: 3110.2000 - tp: 1544.7333 - precision: 0.9867 - recall: 0.9866 - val_loss: 0.1359 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0152 - fn: 28.5333 - fp: 27.7333 - tn: 3102.9333 - tp: 1536.8000 - precision: 0.9812 - recall: 0.9810 - val_loss: 0.1398 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - fn: 24.3333 - fp: 22.1333 - tn: 3108.5333 - tp: 1541.0000 - precision: 0.9846 - recall: 0.9833 - val_loss: 0.1332 - val_fn: 29.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1103.0000 - val_precision: 0.9761 - val_recall: 0.9744\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0195 - fn: 25.4000 - fp: 21.8667 - tn: 3108.8000 - tp: 1539.9333 - precision: 0.9856 - recall: 0.9830 - val_loss: 0.1303 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0253 - fn: 28.4667 - fp: 25.6000 - tn: 3105.0667 - tp: 1536.8667 - precision: 0.9839 - recall: 0.9819 - val_loss: 0.1299 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0175 - fn: 22.4667 - fp: 21.4667 - tn: 3109.2000 - tp: 1542.8667 - precision: 0.9864 - recall: 0.9858 - val_loss: 0.1360 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0155 - fn: 19.2000 - fp: 18.2667 - tn: 3112.4000 - tp: 1546.1333 - precision: 0.9897 - recall: 0.9891 - val_loss: 0.1498 - val_fn: 35.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1097.0000 - val_precision: 0.9674 - val_recall: 0.9691\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0241 - fn: 31.8000 - fp: 30.7333 - tn: 3099.9333 - tp: 1533.5333 - precision: 0.9790 - recall: 0.9790 - val_loss: 0.1388 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0176 - fn: 21.8667 - fp: 23.4000 - tn: 3107.2667 - tp: 1543.4667 - precision: 0.9843 - recall: 0.9852 - val_loss: 0.1539 - val_fn: 38.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1094.0000 - val_precision: 0.9681 - val_recall: 0.9664\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0177 - fn: 22.6000 - fp: 21.7333 - tn: 3108.9333 - tp: 1542.7333 - precision: 0.9844 - recall: 0.9838 - val_loss: 0.1576 - val_fn: 40.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1092.0000 - val_precision: 0.9664 - val_recall: 0.9647\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0218 - fn: 34.0667 - fp: 30.9333 - tn: 3099.7333 - tp: 1531.2667 - precision: 0.9785 - recall: 0.9767 - val_loss: 0.1399 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0143 - fn: 24.5333 - fp: 20.9333 - tn: 3109.7333 - tp: 1540.8000 - precision: 0.9875 - recall: 0.9854 - val_loss: 0.1461 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - fn: 31.4000 - fp: 28.9333 - tn: 3101.7333 - tp: 1533.9333 - precision: 0.9830 - recall: 0.9810 - val_loss: 0.1409 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0229 - fn: 38.4667 - fp: 37.0667 - tn: 3093.6000 - tp: 1526.8667 - precision: 0.9770 - recall: 0.9759 - val_loss: 0.1538 - val_fn: 40.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1092.0000 - val_precision: 0.9664 - val_recall: 0.9647\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0214 - fn: 32.1333 - fp: 30.2000 - tn: 3100.4667 - tp: 1533.2000 - precision: 0.9779 - recall: 0.9766 - val_loss: 0.1627 - val_fn: 44.0000 - val_fp: 43.0000 - val_tn: 2221.0000 - val_tp: 1088.0000 - val_precision: 0.9620 - val_recall: 0.9611\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0216 - fn: 30.2667 - fp: 30.2000 - tn: 3100.4667 - tp: 1535.0667 - precision: 0.9774 - recall: 0.9769 - val_loss: 0.1597 - val_fn: 38.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1094.0000 - val_precision: 0.9664 - val_recall: 0.9664\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0211 - fn: 31.6667 - fp: 32.6667 - tn: 3098.0000 - tp: 1533.6667 - precision: 0.9760 - recall: 0.9767 - val_loss: 0.1538 - val_fn: 39.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1093.0000 - val_precision: 0.9647 - val_recall: 0.9655\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0222 - fn: 27.7333 - fp: 27.2000 - tn: 3103.4667 - tp: 1537.6000 - precision: 0.9806 - recall: 0.9799 - val_loss: 0.1524 - val_fn: 35.0000 - val_fp: 34.0000 - val_tn: 2230.0000 - val_tp: 1097.0000 - val_precision: 0.9699 - val_recall: 0.9691\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0165 - fn: 20.6667 - fp: 21.2667 - tn: 3109.4000 - tp: 1544.6667 - precision: 0.9855 - recall: 0.9859 - val_loss: 0.1430 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0167 - fn: 22.4000 - fp: 22.2000 - tn: 3108.4667 - tp: 1542.9333 - precision: 0.9850 - recall: 0.9850 - val_loss: 0.1474 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0268 - fn: 45.8000 - fp: 45.6667 - tn: 3085.0000 - tp: 1519.5333 - precision: 0.9695 - recall: 0.9692 - val_loss: 0.1454 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0178 - fn: 21.6667 - fp: 21.6000 - tn: 3109.0667 - tp: 1543.6667 - precision: 0.9865 - recall: 0.9864 - val_loss: 0.1437 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - fn: 20.4000 - fp: 20.8667 - tn: 3109.8000 - tp: 1544.9333 - precision: 0.9851 - recall: 0.9853 - val_loss: 0.1413 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0177 - fn: 18.0667 - fp: 16.3333 - tn: 3114.3333 - tp: 1547.2667 - precision: 0.9890 - recall: 0.9880 - val_loss: 0.1438 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0124 - fn: 14.8000 - fp: 13.4000 - tn: 3117.2667 - tp: 1550.5333 - precision: 0.9916 - recall: 0.9909 - val_loss: 0.1476 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0120 - fn: 12.4000 - fp: 13.0000 - tn: 3117.6667 - tp: 1552.9333 - precision: 0.9930 - recall: 0.9929 - val_loss: 0.1580 - val_fn: 38.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1094.0000 - val_precision: 0.9673 - val_recall: 0.9664\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0282 - fn: 48.2667 - fp: 45.9333 - tn: 3084.7333 - tp: 1517.0667 - precision: 0.9748 - recall: 0.9741 - val_loss: 0.1595 - val_fn: 29.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1103.0000 - val_precision: 0.9761 - val_recall: 0.9744\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0401 - fn: 36.8000 - fp: 35.3333 - tn: 3095.3333 - tp: 1528.5333 - precision: 0.9797 - recall: 0.9791 - val_loss: 0.1488 - val_fn: 27.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1105.0000 - val_precision: 0.9796 - val_recall: 0.9761\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0190 - fn: 23.1333 - fp: 24.1333 - tn: 3106.5333 - tp: 1542.2000 - precision: 0.9867 - recall: 0.9873 - val_loss: 0.1490 - val_fn: 34.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1098.0000 - val_precision: 0.9691 - val_recall: 0.9700\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0216 - fn: 21.3333 - fp: 20.7333 - tn: 3109.9333 - tp: 1544.0000 - precision: 0.9868 - recall: 0.9863 - val_loss: 0.1559 - val_fn: 37.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1095.0000 - val_precision: 0.9682 - val_recall: 0.9673\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0210 - fn: 38.6667 - fp: 33.5333 - tn: 3097.1333 - tp: 1526.6667 - precision: 0.9760 - recall: 0.9723 - val_loss: 0.1484 - val_fn: 29.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1103.0000 - val_precision: 0.9761 - val_recall: 0.9744\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0143 - fn: 19.5333 - fp: 18.7333 - tn: 3111.9333 - tp: 1545.8000 - precision: 0.9895 - recall: 0.9889 - val_loss: 0.1448 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1101.0000 - val_precision: 0.9743 - val_recall: 0.9726\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0140 - fn: 21.9333 - fp: 20.3333 - tn: 3110.3333 - tp: 1543.4000 - precision: 0.9871 - recall: 0.9856 - val_loss: 0.1448 - val_fn: 32.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1100.0000 - val_precision: 0.9743 - val_recall: 0.9717\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0251 - fn: 43.8000 - fp: 41.2667 - tn: 3089.4000 - tp: 1521.5333 - precision: 0.9792 - recall: 0.9784 - val_loss: 0.1598 - val_fn: 25.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1107.0000 - val_precision: 0.9796 - val_recall: 0.9779\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0612 - fn: 71.1333 - fp: 71.2000 - tn: 3059.4667 - tp: 1494.2000 - precision: 0.9627 - recall: 0.9627 - val_loss: 0.1554 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0343 - fn: 52.8667 - fp: 49.8000 - tn: 3080.8667 - tp: 1512.4667 - precision: 0.9717 - recall: 0.9696 - val_loss: 0.1422 - val_fn: 31.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1101.0000 - val_precision: 0.9761 - val_recall: 0.9726\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0208 - fn: 25.7333 - fp: 26.4000 - tn: 3104.2667 - tp: 1539.6000 - precision: 0.9840 - recall: 0.9841 - val_loss: 0.1401 - val_fn: 34.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1098.0000 - val_precision: 0.9734 - val_recall: 0.9700\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0157 - fn: 20.6000 - fp: 16.8667 - tn: 3113.8000 - tp: 1544.7333 - precision: 0.9908 - recall: 0.9888 - val_loss: 0.1327 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0149 - fn: 15.6000 - fp: 15.9333 - tn: 3114.7333 - tp: 1549.7333 - precision: 0.9901 - recall: 0.9906 - val_loss: 0.1390 - val_fn: 31.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1101.0000 - val_precision: 0.9769 - val_recall: 0.9726\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0161 - fn: 19.8667 - fp: 17.1333 - tn: 3113.5333 - tp: 1545.4667 - precision: 0.9886 - recall: 0.9873 - val_loss: 0.1336 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0176 - fn: 20.6667 - fp: 19.8000 - tn: 3110.8667 - tp: 1544.6667 - precision: 0.9889 - recall: 0.9888 - val_loss: 0.1449 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0124 - fn: 15.8000 - fp: 14.4667 - tn: 3116.2000 - tp: 1549.5333 - precision: 0.9915 - recall: 0.9907 - val_loss: 0.1422 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0157 - fn: 19.0000 - fp: 18.0000 - tn: 3112.6667 - tp: 1546.3333 - precision: 0.9895 - recall: 0.9889 - val_loss: 0.1449 - val_fn: 30.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1102.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0176 - fn: 18.1333 - fp: 19.8000 - tn: 3110.8667 - tp: 1547.2000 - precision: 0.9866 - recall: 0.9882 - val_loss: 0.1493 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0162 - fn: 20.6667 - fp: 20.7333 - tn: 3109.9333 - tp: 1544.6667 - precision: 0.9882 - recall: 0.9885 - val_loss: 0.1463 - val_fn: 31.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1101.0000 - val_precision: 0.9761 - val_recall: 0.9726\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - fn: 14.9333 - fp: 13.2000 - tn: 3117.4667 - tp: 1550.4000 - precision: 0.9934 - recall: 0.9923 - val_loss: 0.1465 - val_fn: 31.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1101.0000 - val_precision: 0.9752 - val_recall: 0.9726\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0142 - fn: 15.3333 - fp: 15.0000 - tn: 3115.6667 - tp: 1550.0000 - precision: 0.9912 - recall: 0.9912 - val_loss: 0.1433 - val_fn: 25.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1107.0000 - val_precision: 0.9796 - val_recall: 0.9779\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0180 - fn: 20.2667 - fp: 17.4667 - tn: 3113.2000 - tp: 1545.0667 - precision: 0.9897 - recall: 0.9874 - val_loss: 0.1518 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0145 - fn: 18.8667 - fp: 17.0667 - tn: 3113.6000 - tp: 1546.4667 - precision: 0.9885 - recall: 0.9875 - val_loss: 0.1643 - val_fn: 36.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1096.0000 - val_precision: 0.9691 - val_recall: 0.9682\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0122 - fn: 18.3333 - fp: 17.8000 - tn: 3112.8667 - tp: 1547.0000 - precision: 0.9882 - recall: 0.9877 - val_loss: 0.1748 - val_fn: 37.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1095.0000 - val_precision: 0.9673 - val_recall: 0.9673\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0172 - fn: 27.4667 - fp: 25.5333 - tn: 3105.1333 - tp: 1537.8667 - precision: 0.9829 - recall: 0.9819 - val_loss: 0.1741 - val_fn: 40.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1092.0000 - val_precision: 0.9647 - val_recall: 0.9647\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0220 - fn: 31.9333 - fp: 30.8000 - tn: 3099.8667 - tp: 1533.4000 - precision: 0.9817 - recall: 0.9813 - val_loss: 0.1675 - val_fn: 35.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1097.0000 - val_precision: 0.9708 - val_recall: 0.9691\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0171 - fn: 18.0000 - fp: 19.7333 - tn: 3110.9333 - tp: 1547.3333 - precision: 0.9886 - recall: 0.9896 - val_loss: 0.1586 - val_fn: 35.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1097.0000 - val_precision: 0.9717 - val_recall: 0.9691\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0372 - fn: 59.3333 - fp: 57.6000 - tn: 3073.0667 - tp: 1506.0000 - precision: 0.9703 - recall: 0.9695 - val_loss: 0.1767 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0328 - fn: 39.0000 - fp: 39.8000 - tn: 3090.8667 - tp: 1526.3333 - precision: 0.9778 - recall: 0.9785 - val_loss: 0.1484 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0179 - fn: 27.4000 - fp: 25.4000 - tn: 3105.2667 - tp: 1537.9333 - precision: 0.9836 - recall: 0.9822 - val_loss: 0.1552 - val_fn: 33.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1099.0000 - val_precision: 0.9726 - val_recall: 0.9708\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0161 - fn: 21.8667 - fp: 22.5333 - tn: 3108.1333 - tp: 1543.4667 - precision: 0.9838 - recall: 0.9843 - val_loss: 0.1573 - val_fn: 33.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1099.0000 - val_precision: 0.9717 - val_recall: 0.9708\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0161 - fn: 24.4000 - fp: 23.0000 - tn: 3107.6667 - tp: 1540.9333 - precision: 0.9854 - recall: 0.9847 - val_loss: 0.1736 - val_fn: 42.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1090.0000 - val_precision: 0.9655 - val_recall: 0.9629\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0160 - fn: 28.2000 - fp: 26.7333 - tn: 3103.9333 - tp: 1537.1333 - precision: 0.9796 - recall: 0.9786 - val_loss: 0.1579 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0112 - fn: 20.7333 - fp: 19.8000 - tn: 3110.8667 - tp: 1544.6000 - precision: 0.9874 - recall: 0.9864 - val_loss: 0.1615 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0115 - fn: 17.6000 - fp: 16.8667 - tn: 3113.8000 - tp: 1547.7333 - precision: 0.9909 - recall: 0.9905 - val_loss: 0.1573 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - fn: 15.2000 - fp: 12.8000 - tn: 3117.8667 - tp: 1550.1333 - precision: 0.9923 - recall: 0.9914 - val_loss: 0.1598 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - fn: 15.1333 - fp: 13.7333 - tn: 3116.9333 - tp: 1550.2000 - precision: 0.9913 - recall: 0.9905 - val_loss: 0.1599 - val_fn: 29.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1103.0000 - val_precision: 0.9735 - val_recall: 0.9744\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0112 - fn: 15.3333 - fp: 13.2667 - tn: 3117.4000 - tp: 1550.0000 - precision: 0.9912 - recall: 0.9898 - val_loss: 0.1594 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0149 - fn: 20.2667 - fp: 20.0667 - tn: 3110.6000 - tp: 1545.0667 - precision: 0.9897 - recall: 0.9890 - val_loss: 0.1554 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0146 - fn: 27.8000 - fp: 23.4667 - tn: 3107.2000 - tp: 1537.5333 - precision: 0.9860 - recall: 0.9834 - val_loss: 0.1724 - val_fn: 37.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1095.0000 - val_precision: 0.9673 - val_recall: 0.9673\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0230 - fn: 37.7333 - fp: 35.7333 - tn: 3094.9333 - tp: 1527.6000 - precision: 0.9729 - recall: 0.9716 - val_loss: 0.1600 - val_fn: 33.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1099.0000 - val_precision: 0.9717 - val_recall: 0.9708\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0152 - fn: 18.1333 - fp: 17.4000 - tn: 3113.2667 - tp: 1547.2000 - precision: 0.9874 - recall: 0.9868 - val_loss: 0.1566 - val_fn: 30.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1102.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0103 - fn: 17.3333 - fp: 15.4000 - tn: 3115.2667 - tp: 1548.0000 - precision: 0.9898 - recall: 0.9884 - val_loss: 0.1565 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0104 - fn: 11.9333 - fp: 13.2667 - tn: 3117.4000 - tp: 1553.4000 - precision: 0.9915 - recall: 0.9924 - val_loss: 0.1752 - val_fn: 36.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1096.0000 - val_precision: 0.9691 - val_recall: 0.9682\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0177 - fn: 23.4667 - fp: 22.4667 - tn: 3108.2000 - tp: 1541.8667 - precision: 0.9839 - recall: 0.9828 - val_loss: 0.1572 - val_fn: 31.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1101.0000 - val_precision: 0.9761 - val_recall: 0.9726\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0426 - fn: 22.7333 - fp: 20.8667 - tn: 3109.8000 - tp: 1542.6000 - precision: 0.9866 - recall: 0.9845 - val_loss: 0.2229 - val_fn: 61.0000 - val_fp: 60.0000 - val_tn: 2204.0000 - val_tp: 1071.0000 - val_precision: 0.9469 - val_recall: 0.9461\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0362 - fn: 48.2667 - fp: 43.0667 - tn: 3087.6000 - tp: 1517.0667 - precision: 0.9687 - recall: 0.9651 - val_loss: 0.1781 - val_fn: 41.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1091.0000 - val_precision: 0.9663 - val_recall: 0.9638\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0739 - fn: 50.6000 - fp: 51.0667 - tn: 3079.6000 - tp: 1514.7333 - precision: 0.9707 - recall: 0.9708 - val_loss: 0.2291 - val_fn: 50.0000 - val_fp: 53.0000 - val_tn: 2211.0000 - val_tp: 1082.0000 - val_precision: 0.9533 - val_recall: 0.9558\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1577 - fn: 40.2000 - fp: 39.1333 - tn: 3091.5333 - tp: 1525.1333 - precision: 0.9774 - recall: 0.9769 - val_loss: 0.1849 - val_fn: 52.0000 - val_fp: 47.0000 - val_tn: 2217.0000 - val_tp: 1080.0000 - val_precision: 0.9583 - val_recall: 0.9541\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0729 - fn: 44.4000 - fp: 40.4667 - tn: 3090.2000 - tp: 1520.9333 - precision: 0.9725 - recall: 0.9710 - val_loss: 0.1547 - val_fn: 36.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1096.0000 - val_precision: 0.9691 - val_recall: 0.9682\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0809 - fn: 38.4000 - fp: 34.0000 - tn: 3096.6667 - tp: 1526.9333 - precision: 0.9785 - recall: 0.9764 - val_loss: 0.1437 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0465 - fn: 30.6000 - fp: 26.9333 - tn: 3103.7333 - tp: 1534.7333 - precision: 0.9857 - recall: 0.9828 - val_loss: 0.1439 - val_fn: 34.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1098.0000 - val_precision: 0.9708 - val_recall: 0.9700\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0283 - fn: 30.9333 - fp: 26.5333 - tn: 3104.1333 - tp: 1534.4000 - precision: 0.9839 - recall: 0.9805 - val_loss: 0.1541 - val_fn: 36.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1096.0000 - val_precision: 0.9691 - val_recall: 0.9682\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0287 - fn: 41.7333 - fp: 41.9333 - tn: 3088.7333 - tp: 1523.6000 - precision: 0.9718 - recall: 0.9727 - val_loss: 0.1478 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0423 - fn: 30.7333 - fp: 29.8667 - tn: 3100.8000 - tp: 1534.6000 - precision: 0.9800 - recall: 0.9797 - val_loss: 0.2060 - val_fn: 63.0000 - val_fp: 62.0000 - val_tn: 2202.0000 - val_tp: 1069.0000 - val_precision: 0.9452 - val_recall: 0.9443\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0495 - fn: 74.8000 - fp: 77.6000 - tn: 3053.0667 - tp: 1490.5333 - precision: 0.9477 - recall: 0.9496 - val_loss: 0.1654 - val_fn: 40.0000 - val_fp: 42.0000 - val_tn: 2222.0000 - val_tp: 1092.0000 - val_precision: 0.9630 - val_recall: 0.9647\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0431 - fn: 48.4667 - fp: 52.4667 - tn: 3078.2000 - tp: 1516.8667 - precision: 0.9745 - recall: 0.9774 - val_loss: 0.1683 - val_fn: 44.0000 - val_fp: 45.0000 - val_tn: 2219.0000 - val_tp: 1088.0000 - val_precision: 0.9603 - val_recall: 0.9611\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0570 - fn: 47.0000 - fp: 49.6000 - tn: 3081.0667 - tp: 1518.3333 - precision: 0.9713 - recall: 0.9729 - val_loss: 0.1540 - val_fn: 41.0000 - val_fp: 45.0000 - val_tn: 2219.0000 - val_tp: 1091.0000 - val_precision: 0.9604 - val_recall: 0.9638\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0295 - fn: 29.4667 - fp: 30.5333 - tn: 3100.1333 - tp: 1535.8667 - precision: 0.9816 - recall: 0.9822 - val_loss: 0.1500 - val_fn: 41.0000 - val_fp: 41.0000 - val_tn: 2223.0000 - val_tp: 1091.0000 - val_precision: 0.9638 - val_recall: 0.9638\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0200 - fn: 25.4667 - fp: 26.6667 - tn: 3104.0000 - tp: 1539.8667 - precision: 0.9846 - recall: 0.9853 - val_loss: 0.1585 - val_fn: 40.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1092.0000 - val_precision: 0.9655 - val_recall: 0.9647\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0242 - fn: 27.0000 - fp: 28.5333 - tn: 3102.1333 - tp: 1538.3333 - precision: 0.9817 - recall: 0.9822 - val_loss: 0.1546 - val_fn: 40.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1092.0000 - val_precision: 0.9672 - val_recall: 0.9647\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0174 - fn: 19.9333 - fp: 19.6667 - tn: 3111.0000 - tp: 1545.4000 - precision: 0.9865 - recall: 0.9861 - val_loss: 0.1537 - val_fn: 33.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1099.0000 - val_precision: 0.9708 - val_recall: 0.9708\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0169 - fn: 21.7333 - fp: 21.0000 - tn: 3109.6667 - tp: 1543.6000 - precision: 0.9862 - recall: 0.9851 - val_loss: 0.1491 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1101.0000 - val_precision: 0.9743 - val_recall: 0.9726\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0162 - fn: 19.1333 - fp: 20.4667 - tn: 3110.2000 - tp: 1546.2000 - precision: 0.9874 - recall: 0.9886 - val_loss: 0.1586 - val_fn: 37.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1095.0000 - val_precision: 0.9690 - val_recall: 0.9673\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0129 - fn: 16.2000 - fp: 15.6000 - tn: 3115.0667 - tp: 1549.1333 - precision: 0.9891 - recall: 0.9888 - val_loss: 0.1555 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0110 - fn: 20.4667 - fp: 21.6000 - tn: 3109.0667 - tp: 1544.8667 - precision: 0.9846 - recall: 0.9862 - val_loss: 0.1518 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0101 - fn: 18.8667 - fp: 17.7333 - tn: 3112.9333 - tp: 1546.4667 - precision: 0.9891 - recall: 0.9885 - val_loss: 0.1576 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0167 - fn: 27.4000 - fp: 26.8667 - tn: 3103.8000 - tp: 1537.9333 - precision: 0.9832 - recall: 0.9831 - val_loss: 0.1589 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0139 - fn: 27.8667 - fp: 28.4667 - tn: 3102.2000 - tp: 1537.4667 - precision: 0.9835 - recall: 0.9839 - val_loss: 0.1572 - val_fn: 31.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1101.0000 - val_precision: 0.9752 - val_recall: 0.9726\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0106 - fn: 14.6000 - fp: 13.2000 - tn: 3117.4667 - tp: 1550.7333 - precision: 0.9924 - recall: 0.9915 - val_loss: 0.1542 - val_fn: 28.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1104.0000 - val_precision: 0.9744 - val_recall: 0.9753\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0139 - fn: 14.8000 - fp: 14.0667 - tn: 3116.6000 - tp: 1550.5333 - precision: 0.9901 - recall: 0.9899 - val_loss: 0.1606 - val_fn: 32.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1100.0000 - val_precision: 0.9735 - val_recall: 0.9717\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0137 - fn: 18.2000 - fp: 18.5333 - tn: 3112.1333 - tp: 1547.1333 - precision: 0.9871 - recall: 0.9870 - val_loss: 0.1596 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0127 - fn: 22.3333 - fp: 21.0667 - tn: 3109.6000 - tp: 1543.0000 - precision: 0.9876 - recall: 0.9870 - val_loss: 0.1958 - val_fn: 53.0000 - val_fp: 52.0000 - val_tn: 2212.0000 - val_tp: 1079.0000 - val_precision: 0.9540 - val_recall: 0.9532\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.1553 - fn: 219.2000 - fp: 222.1333 - tn: 2908.5333 - tp: 1346.1333 - precision: 0.8474 - recall: 0.8490 - val_loss: 0.2109 - val_fn: 65.0000 - val_fp: 75.0000 - val_tn: 2189.0000 - val_tp: 1067.0000 - val_precision: 0.9343 - val_recall: 0.9426\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0425 - fn: 68.2000 - fp: 76.8000 - tn: 3053.8667 - tp: 1497.1333 - precision: 0.9483 - recall: 0.9539 - val_loss: 0.1542 - val_fn: 40.0000 - val_fp: 41.0000 - val_tn: 2223.0000 - val_tp: 1092.0000 - val_precision: 0.9638 - val_recall: 0.9647\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0208 - fn: 28.8000 - fp: 35.4000 - tn: 3095.2667 - tp: 1536.5333 - precision: 0.9778 - recall: 0.9826 - val_loss: 0.1468 - val_fn: 32.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1100.0000 - val_precision: 0.9735 - val_recall: 0.9717\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0158 - fn: 18.8667 - fp: 18.5333 - tn: 3112.1333 - tp: 1546.4667 - precision: 0.9877 - recall: 0.9879 - val_loss: 0.1461 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1101.0000 - val_precision: 0.9743 - val_recall: 0.9726\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0130 - fn: 23.4667 - fp: 21.8000 - tn: 3108.8667 - tp: 1541.8667 - precision: 0.9862 - recall: 0.9845 - val_loss: 0.1472 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0183 - fn: 22.0667 - fp: 21.6667 - tn: 3109.0000 - tp: 1543.2667 - precision: 0.9866 - recall: 0.9872 - val_loss: 0.1608 - val_fn: 37.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1095.0000 - val_precision: 0.9682 - val_recall: 0.9673\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0135 - fn: 14.2667 - fp: 13.6000 - tn: 3117.0667 - tp: 1551.0667 - precision: 0.9913 - recall: 0.9908 - val_loss: 0.1526 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0135 - fn: 26.8667 - fp: 25.6000 - tn: 3105.0667 - tp: 1538.4667 - precision: 0.9846 - recall: 0.9839 - val_loss: 0.1514 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0147 - fn: 14.1333 - fp: 16.3333 - tn: 3114.3333 - tp: 1551.2000 - precision: 0.9908 - recall: 0.9922 - val_loss: 0.1539 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0123 - fn: 12.3333 - fp: 10.8000 - tn: 3119.8667 - tp: 1553.0000 - precision: 0.9934 - recall: 0.9924 - val_loss: 0.1666 - val_fn: 32.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1100.0000 - val_precision: 0.9717 - val_recall: 0.9717\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0107 - fn: 15.0000 - fp: 15.0000 - tn: 3115.6667 - tp: 1550.3333 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.1616 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0116 - fn: 17.9333 - fp: 16.1333 - tn: 3114.5333 - tp: 1547.4000 - precision: 0.9903 - recall: 0.9895 - val_loss: 0.1591 - val_fn: 27.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1105.0000 - val_precision: 0.9787 - val_recall: 0.9761\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - fn: 17.0667 - fp: 17.6667 - tn: 3113.0000 - tp: 1548.2667 - precision: 0.9918 - recall: 0.9922 - val_loss: 0.1666 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0167 - fn: 19.6667 - fp: 18.3333 - tn: 3112.3333 - tp: 1545.6667 - precision: 0.9901 - recall: 0.9892 - val_loss: 0.1841 - val_fn: 45.0000 - val_fp: 44.0000 - val_tn: 2220.0000 - val_tp: 1087.0000 - val_precision: 0.9611 - val_recall: 0.9602\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - fn: 13.8000 - fp: 14.4667 - tn: 3116.2000 - tp: 1551.5333 - precision: 0.9895 - recall: 0.9900 - val_loss: 0.1660 - val_fn: 33.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1099.0000 - val_precision: 0.9717 - val_recall: 0.9708\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0139 - fn: 22.4667 - fp: 24.0667 - tn: 3106.6000 - tp: 1542.8667 - precision: 0.9839 - recall: 0.9850 - val_loss: 0.1605 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - fn: 17.4000 - fp: 18.7333 - tn: 3111.9333 - tp: 1547.9333 - precision: 0.9870 - recall: 0.9882 - val_loss: 0.1603 - val_fn: 26.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1106.0000 - val_precision: 0.9788 - val_recall: 0.9770\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0077 - fn: 11.8667 - fp: 13.0000 - tn: 3117.6667 - tp: 1553.4667 - precision: 0.9931 - recall: 0.9936 - val_loss: 0.1647 - val_fn: 29.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1103.0000 - val_precision: 0.9770 - val_recall: 0.9744\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0083 - fn: 12.6667 - fp: 12.1333 - tn: 3118.5333 - tp: 1552.6667 - precision: 0.9921 - recall: 0.9914 - val_loss: 0.1701 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0100 - fn: 11.3333 - fp: 12.5333 - tn: 3118.1333 - tp: 1554.0000 - precision: 0.9904 - recall: 0.9911 - val_loss: 0.1691 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - fn: 7.7333 - fp: 8.1333 - tn: 3122.5333 - tp: 1557.6000 - precision: 0.9949 - recall: 0.9951 - val_loss: 0.1780 - val_fn: 34.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1098.0000 - val_precision: 0.9708 - val_recall: 0.9700\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0116 - fn: 19.8667 - fp: 17.7333 - tn: 3112.9333 - tp: 1545.4667 - precision: 0.9867 - recall: 0.9846 - val_loss: 0.1732 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0098 - fn: 17.6667 - fp: 18.6667 - tn: 3112.0000 - tp: 1547.6667 - precision: 0.9875 - recall: 0.9884 - val_loss: 0.1700 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0092 - fn: 13.0000 - fp: 14.7333 - tn: 3115.9333 - tp: 1552.3333 - precision: 0.9916 - recall: 0.9924 - val_loss: 0.1719 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0060 - fn: 11.0667 - fp: 10.4000 - tn: 3120.2667 - tp: 1554.2667 - precision: 0.9944 - recall: 0.9940 - val_loss: 0.1752 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0097 - fn: 11.8000 - fp: 12.0000 - tn: 3118.6667 - tp: 1553.5333 - precision: 0.9930 - recall: 0.9928 - val_loss: 0.1775 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0119 - fn: 14.6667 - fp: 14.0000 - tn: 3116.6667 - tp: 1550.6667 - precision: 0.9927 - recall: 0.9924 - val_loss: 0.1769 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1101.0000 - val_precision: 0.9743 - val_recall: 0.9726\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0090 - fn: 10.8000 - fp: 9.4000 - tn: 3121.2667 - tp: 1554.5333 - precision: 0.9949 - recall: 0.9936 - val_loss: 0.1760 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0070 - fn: 9.6000 - fp: 10.0000 - tn: 3120.6667 - tp: 1555.7333 - precision: 0.9940 - recall: 0.9942 - val_loss: 0.1835 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0088 - fn: 15.4000 - fp: 13.1333 - tn: 3117.5333 - tp: 1549.9333 - precision: 0.9906 - recall: 0.9885 - val_loss: 0.1786 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0091 - fn: 15.2667 - fp: 13.7333 - tn: 3116.9333 - tp: 1550.0667 - precision: 0.9925 - recall: 0.9918 - val_loss: 0.1883 - val_fn: 37.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1095.0000 - val_precision: 0.9673 - val_recall: 0.9673\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0139 - fn: 18.2667 - fp: 18.4000 - tn: 3112.2667 - tp: 1547.0667 - precision: 0.9861 - recall: 0.9863 - val_loss: 0.1926 - val_fn: 39.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1093.0000 - val_precision: 0.9664 - val_recall: 0.9655\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0145 - fn: 17.8667 - fp: 18.8667 - tn: 3111.8000 - tp: 1547.4667 - precision: 0.9858 - recall: 0.9865 - val_loss: 0.1843 - val_fn: 33.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1099.0000 - val_precision: 0.9734 - val_recall: 0.9708\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083 - fn: 12.3333 - fp: 11.6000 - tn: 3119.0667 - tp: 1553.0000 - precision: 0.9928 - recall: 0.9924 - val_loss: 0.1848 - val_fn: 32.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1100.0000 - val_precision: 0.9735 - val_recall: 0.9717\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - fn: 17.7333 - fp: 15.6000 - tn: 3115.0667 - tp: 1547.6000 - precision: 0.9895 - recall: 0.9883 - val_loss: 0.1790 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0073 - fn: 9.2000 - fp: 10.4667 - tn: 3120.2000 - tp: 1556.1333 - precision: 0.9928 - recall: 0.9934 - val_loss: 0.1821 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061 - fn: 12.4667 - fp: 11.2667 - tn: 3119.4000 - tp: 1552.8667 - precision: 0.9932 - recall: 0.9926 - val_loss: 0.1807 - val_fn: 31.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1101.0000 - val_precision: 0.9769 - val_recall: 0.9726\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - fn: 7.8000 - fp: 8.5333 - tn: 3122.1333 - tp: 1557.5333 - precision: 0.9955 - recall: 0.9959 - val_loss: 0.1863 - val_fn: 31.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1101.0000 - val_precision: 0.9743 - val_recall: 0.9726\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0095 - fn: 18.2000 - fp: 17.5333 - tn: 3113.1333 - tp: 1547.1333 - precision: 0.9890 - recall: 0.9887 - val_loss: 0.2054 - val_fn: 42.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1090.0000 - val_precision: 0.9646 - val_recall: 0.9629\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0246 - fn: 42.0667 - fp: 40.6000 - tn: 3090.0667 - tp: 1523.2667 - precision: 0.9716 - recall: 0.9706 - val_loss: 0.1832 - val_fn: 33.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1099.0000 - val_precision: 0.9726 - val_recall: 0.9708\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0091 - fn: 17.0667 - fp: 19.0000 - tn: 3111.6667 - tp: 1548.2667 - precision: 0.9884 - recall: 0.9894 - val_loss: 0.1832 - val_fn: 33.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1099.0000 - val_precision: 0.9708 - val_recall: 0.9708\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0058 - fn: 11.6000 - fp: 11.6667 - tn: 3119.0000 - tp: 1553.7333 - precision: 0.9932 - recall: 0.9933 - val_loss: 0.1912 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - fn: 9.6667 - fp: 9.8667 - tn: 3120.8000 - tp: 1555.6667 - precision: 0.9929 - recall: 0.9930 - val_loss: 0.1813 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0089 - fn: 15.9333 - fp: 15.0667 - tn: 3115.6000 - tp: 1549.4000 - precision: 0.9903 - recall: 0.9897 - val_loss: 0.1877 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - fn: 25.3333 - fp: 25.5333 - tn: 3105.1333 - tp: 1540.0000 - precision: 0.9834 - recall: 0.9834 - val_loss: 0.1849 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0113 - fn: 18.2667 - fp: 18.2000 - tn: 3112.4667 - tp: 1547.0667 - precision: 0.9913 - recall: 0.9913 - val_loss: 0.1843 - val_fn: 28.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1104.0000 - val_precision: 0.9787 - val_recall: 0.9753\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0167 - fn: 19.8667 - fp: 18.0000 - tn: 3112.6667 - tp: 1545.4667 - precision: 0.9906 - recall: 0.9897 - val_loss: 0.1903 - val_fn: 31.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1101.0000 - val_precision: 0.9752 - val_recall: 0.9726\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0164 - fn: 14.6000 - fp: 15.4000 - tn: 3115.2667 - tp: 1550.7333 - precision: 0.9918 - recall: 0.9923 - val_loss: 0.1812 - val_fn: 39.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1093.0000 - val_precision: 0.9681 - val_recall: 0.9655\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0144 - fn: 14.8000 - fp: 17.5333 - tn: 3113.1333 - tp: 1550.5333 - precision: 0.9883 - recall: 0.9900 - val_loss: 0.1798 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0092 - fn: 11.0000 - fp: 11.9333 - tn: 3118.7333 - tp: 1554.3333 - precision: 0.9900 - recall: 0.9908 - val_loss: 0.1883 - val_fn: 32.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1100.0000 - val_precision: 0.9743 - val_recall: 0.9717\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - fn: 16.1333 - fp: 16.2667 - tn: 3114.4000 - tp: 1549.2000 - precision: 0.9890 - recall: 0.9887 - val_loss: 0.1869 - val_fn: 32.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1100.0000 - val_precision: 0.9743 - val_recall: 0.9717\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0110 - fn: 16.6000 - fp: 16.2667 - tn: 3114.4000 - tp: 1548.7333 - precision: 0.9899 - recall: 0.9896 - val_loss: 0.1931 - val_fn: 25.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1107.0000 - val_precision: 0.9796 - val_recall: 0.9779\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0436 - fn: 56.3333 - fp: 52.4667 - tn: 3078.2000 - tp: 1509.0000 - precision: 0.9721 - recall: 0.9701 - val_loss: 0.1969 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 300/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0264 - fn: 20.4000 - fp: 18.4000 - tn: 3112.2667 - tp: 1544.9333 - precision: 0.9898 - recall: 0.9887 - val_loss: 0.1865 - val_fn: 35.0000 - val_fp: 34.0000 - val_tn: 2230.0000 - val_tp: 1097.0000 - val_precision: 0.9699 - val_recall: 0.9691\n",
      "Epoch 301/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0141 - fn: 20.3333 - fp: 20.9333 - tn: 3109.7333 - tp: 1545.0000 - precision: 0.9860 - recall: 0.9858 - val_loss: 0.1792 - val_fn: 30.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1102.0000 - val_precision: 0.9761 - val_recall: 0.9735\n",
      "Epoch 302/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - fn: 16.0000 - fp: 12.8000 - tn: 3117.8667 - tp: 1549.3333 - precision: 0.9928 - recall: 0.9901 - val_loss: 0.2390 - val_fn: 60.0000 - val_fp: 58.0000 - val_tn: 2206.0000 - val_tp: 1072.0000 - val_precision: 0.9487 - val_recall: 0.9470\n",
      "Epoch 303/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0242 - fn: 39.2000 - fp: 34.5333 - tn: 3096.1333 - tp: 1526.1333 - precision: 0.9735 - recall: 0.9689 - val_loss: 0.1869 - val_fn: 41.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1091.0000 - val_precision: 0.9646 - val_recall: 0.9638\n",
      "Epoch 304/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0125 - fn: 17.6667 - fp: 17.8000 - tn: 3112.8667 - tp: 1547.6667 - precision: 0.9876 - recall: 0.9875 - val_loss: 0.1917 - val_fn: 40.0000 - val_fp: 39.0000 - val_tn: 2225.0000 - val_tp: 1092.0000 - val_precision: 0.9655 - val_recall: 0.9647\n",
      "Epoch 305/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0138 - fn: 21.6000 - fp: 21.5333 - tn: 3109.1333 - tp: 1543.7333 - precision: 0.9829 - recall: 0.9829 - val_loss: 0.1805 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 306/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0081 - fn: 12.0667 - fp: 11.6667 - tn: 3119.0000 - tp: 1553.2667 - precision: 0.9909 - recall: 0.9907 - val_loss: 0.1806 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 307/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0067 - fn: 13.6000 - fp: 16.0667 - tn: 3114.6000 - tp: 1551.7333 - precision: 0.9909 - recall: 0.9924 - val_loss: 0.1804 - val_fn: 27.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1105.0000 - val_precision: 0.9779 - val_recall: 0.9761\n",
      "Epoch 308/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0084 - fn: 13.7333 - fp: 14.4667 - tn: 3116.2000 - tp: 1551.6000 - precision: 0.9896 - recall: 0.9902 - val_loss: 0.1817 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 309/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0065 - fn: 10.2000 - fp: 10.1333 - tn: 3120.5333 - tp: 1555.1333 - precision: 0.9942 - recall: 0.9938 - val_loss: 0.1839 - val_fn: 31.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1101.0000 - val_precision: 0.9761 - val_recall: 0.9726\n",
      "Epoch 310/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0066 - fn: 10.9333 - fp: 10.9333 - tn: 3119.7333 - tp: 1554.4000 - precision: 0.9932 - recall: 0.9932 - val_loss: 0.1849 - val_fn: 29.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1103.0000 - val_precision: 0.9778 - val_recall: 0.9744\n",
      "Epoch 311/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0086 - fn: 19.6000 - fp: 15.7333 - tn: 3114.9333 - tp: 1545.7333 - precision: 0.9902 - recall: 0.9873 - val_loss: 0.1910 - val_fn: 32.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1100.0000 - val_precision: 0.9743 - val_recall: 0.9717\n",
      "Epoch 312/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0287 - fn: 27.4667 - fp: 28.8667 - tn: 3101.8000 - tp: 1537.8667 - precision: 0.9827 - recall: 0.9844 - val_loss: 0.1956 - val_fn: 35.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1097.0000 - val_precision: 0.9708 - val_recall: 0.9691\n",
      "Epoch 313/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0561 - fn: 35.7333 - fp: 37.9333 - tn: 3092.7333 - tp: 1529.6000 - precision: 0.9749 - recall: 0.9767 - val_loss: 0.2149 - val_fn: 48.0000 - val_fp: 47.0000 - val_tn: 2217.0000 - val_tp: 1084.0000 - val_precision: 0.9584 - val_recall: 0.9576\n",
      "Epoch 314/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0580 - fn: 53.7333 - fp: 49.2000 - tn: 3081.4667 - tp: 1511.6000 - precision: 0.9653 - recall: 0.9627 - val_loss: 0.1740 - val_fn: 34.0000 - val_fp: 34.0000 - val_tn: 2230.0000 - val_tp: 1098.0000 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 315/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0238 - fn: 22.2667 - fp: 25.2667 - tn: 3105.4000 - tp: 1543.0667 - precision: 0.9825 - recall: 0.9852 - val_loss: 0.1767 - val_fn: 39.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1093.0000 - val_precision: 0.9664 - val_recall: 0.9655\n",
      "Epoch 316/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0181 - fn: 27.4000 - fp: 21.2000 - tn: 3109.4667 - tp: 1537.9333 - precision: 0.9842 - recall: 0.9795 - val_loss: 0.1767 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 317/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0124 - fn: 16.9333 - fp: 16.4667 - tn: 3114.2000 - tp: 1548.4000 - precision: 0.9908 - recall: 0.9903 - val_loss: 0.1703 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 318/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0132 - fn: 15.8667 - fp: 15.6000 - tn: 3115.0667 - tp: 1549.4667 - precision: 0.9888 - recall: 0.9887 - val_loss: 0.1717 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 319/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0090 - fn: 11.6000 - fp: 11.6667 - tn: 3119.0000 - tp: 1553.7333 - precision: 0.9929 - recall: 0.9933 - val_loss: 0.1744 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 320/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0131 - fn: 16.4667 - fp: 17.4000 - tn: 3113.2667 - tp: 1548.8667 - precision: 0.9896 - recall: 0.9901 - val_loss: 0.3081 - val_fn: 112.0000 - val_fp: 109.0000 - val_tn: 2155.0000 - val_tp: 1020.0000 - val_precision: 0.9035 - val_recall: 0.9011\n",
      "Epoch 321/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0389 - fn: 47.6000 - fp: 47.0667 - tn: 3083.6000 - tp: 1517.7333 - precision: 0.9587 - recall: 0.9587 - val_loss: 0.1872 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 322/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0134 - fn: 16.8000 - fp: 19.1333 - tn: 3111.5333 - tp: 1548.5333 - precision: 0.9877 - recall: 0.9890 - val_loss: 0.1876 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 323/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - fn: 15.4000 - fp: 15.4667 - tn: 3115.2000 - tp: 1549.9333 - precision: 0.9909 - recall: 0.9911 - val_loss: 0.1837 - val_fn: 31.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1101.0000 - val_precision: 0.9735 - val_recall: 0.9726\n",
      "Epoch 324/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - fn: 13.0667 - fp: 11.4000 - tn: 3119.2667 - tp: 1552.2667 - precision: 0.9920 - recall: 0.9912 - val_loss: 0.2005 - val_fn: 34.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1098.0000 - val_precision: 0.9717 - val_recall: 0.9700\n",
      "Epoch 325/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0200 - fn: 14.0000 - fp: 13.2667 - tn: 3117.4000 - tp: 1551.3333 - precision: 0.9909 - recall: 0.9905 - val_loss: 0.1823 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 326/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0282 - fn: 20.3333 - fp: 20.6667 - tn: 3110.0000 - tp: 1545.0000 - precision: 0.9860 - recall: 0.9864 - val_loss: 0.1922 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 327/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0319 - fn: 33.5333 - fp: 32.5333 - tn: 3098.1333 - tp: 1531.8000 - precision: 0.9824 - recall: 0.9816 - val_loss: 0.1931 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 328/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0150 - fn: 20.1333 - fp: 18.8000 - tn: 3111.8667 - tp: 1545.2000 - precision: 0.9903 - recall: 0.9895 - val_loss: 0.2007 - val_fn: 38.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1094.0000 - val_precision: 0.9673 - val_recall: 0.9664\n",
      "Epoch 329/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0123 - fn: 15.2000 - fp: 15.2000 - tn: 3115.4667 - tp: 1550.1333 - precision: 0.9899 - recall: 0.9899 - val_loss: 0.1891 - val_fn: 32.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1100.0000 - val_precision: 0.9726 - val_recall: 0.9717\n",
      "Epoch 330/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0120 - fn: 16.4000 - fp: 17.8000 - tn: 3112.8667 - tp: 1548.9333 - precision: 0.9872 - recall: 0.9880 - val_loss: 0.1847 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 331/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061 - fn: 4.8667 - fp: 5.2667 - tn: 3125.4000 - tp: 1560.4667 - precision: 0.9973 - recall: 0.9975 - val_loss: 0.2115 - val_fn: 40.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1092.0000 - val_precision: 0.9647 - val_recall: 0.9647\n",
      "Epoch 332/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0108 - fn: 17.9333 - fp: 17.6667 - tn: 3113.0000 - tp: 1547.4000 - precision: 0.9874 - recall: 0.9869 - val_loss: 0.1929 - val_fn: 32.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1100.0000 - val_precision: 0.9743 - val_recall: 0.9717\n",
      "Epoch 333/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0092 - fn: 15.8667 - fp: 15.2667 - tn: 3115.4000 - tp: 1549.4667 - precision: 0.9913 - recall: 0.9910 - val_loss: 0.2212 - val_fn: 46.0000 - val_fp: 46.0000 - val_tn: 2218.0000 - val_tp: 1086.0000 - val_precision: 0.9594 - val_recall: 0.9594\n",
      "Epoch 334/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0179 - fn: 29.4000 - fp: 30.8667 - tn: 3099.8000 - tp: 1535.9333 - precision: 0.9783 - recall: 0.9791 - val_loss: 0.2100 - val_fn: 39.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1093.0000 - val_precision: 0.9664 - val_recall: 0.9655\n",
      "Epoch 335/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0174 - fn: 28.3333 - fp: 27.2000 - tn: 3103.4667 - tp: 1537.0000 - precision: 0.9816 - recall: 0.9808 - val_loss: 0.2991 - val_fn: 90.0000 - val_fp: 89.0000 - val_tn: 2175.0000 - val_tp: 1042.0000 - val_precision: 0.9213 - val_recall: 0.9205\n",
      "Epoch 336/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0430 - fn: 65.6000 - fp: 66.6000 - tn: 3064.0667 - tp: 1499.7333 - precision: 0.9483 - recall: 0.9487 - val_loss: 0.2017 - val_fn: 38.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1094.0000 - val_precision: 0.9664 - val_recall: 0.9664\n",
      "Epoch 337/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0315 - fn: 32.4667 - fp: 33.0000 - tn: 3097.6667 - tp: 1532.8667 - precision: 0.9776 - recall: 0.9783 - val_loss: 0.1985 - val_fn: 34.0000 - val_fp: 34.0000 - val_tn: 2230.0000 - val_tp: 1098.0000 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 338/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0177 - fn: 20.4000 - fp: 22.3333 - tn: 3108.3333 - tp: 1544.9333 - precision: 0.9867 - recall: 0.9874 - val_loss: 0.2054 - val_fn: 45.0000 - val_fp: 46.0000 - val_tn: 2218.0000 - val_tp: 1087.0000 - val_precision: 0.9594 - val_recall: 0.9602\n",
      "Epoch 339/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0196 - fn: 23.4667 - fp: 22.5333 - tn: 3108.1333 - tp: 1541.8667 - precision: 0.9825 - recall: 0.9817 - val_loss: 0.2273 - val_fn: 54.0000 - val_fp: 54.0000 - val_tn: 2210.0000 - val_tp: 1078.0000 - val_precision: 0.9523 - val_recall: 0.9523\n",
      "Epoch 340/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0319 - fn: 44.5333 - fp: 45.4000 - tn: 3085.2667 - tp: 1520.8000 - precision: 0.9667 - recall: 0.9676 - val_loss: 0.2027 - val_fn: 36.0000 - val_fp: 35.0000 - val_tn: 2229.0000 - val_tp: 1096.0000 - val_precision: 0.9691 - val_recall: 0.9682\n",
      "Epoch 341/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0176 - fn: 33.3333 - fp: 33.3333 - tn: 3097.3333 - tp: 1532.0000 - precision: 0.9795 - recall: 0.9794 - val_loss: 0.1764 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 342/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0182 - fn: 25.6000 - fp: 23.5333 - tn: 3107.1333 - tp: 1539.7333 - precision: 0.9865 - recall: 0.9852 - val_loss: 0.1887 - val_fn: 32.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1100.0000 - val_precision: 0.9717 - val_recall: 0.9717\n",
      "Epoch 343/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0102 - fn: 16.7333 - fp: 17.4667 - tn: 3113.2000 - tp: 1548.6000 - precision: 0.9873 - recall: 0.9883 - val_loss: 0.1794 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 344/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0089 - fn: 16.0000 - fp: 17.8000 - tn: 3112.8667 - tp: 1549.3333 - precision: 0.9876 - recall: 0.9886 - val_loss: 0.1821 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 345/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0105 - fn: 24.7333 - fp: 22.5333 - tn: 3108.1333 - tp: 1540.6000 - precision: 0.9878 - recall: 0.9867 - val_loss: 0.1793 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 346/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0233 - fn: 28.8000 - fp: 28.5333 - tn: 3102.1333 - tp: 1536.5333 - precision: 0.9859 - recall: 0.9858 - val_loss: 0.1912 - val_fn: 29.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1103.0000 - val_precision: 0.9727 - val_recall: 0.9744\n",
      "Epoch 347/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0122 - fn: 11.0000 - fp: 11.2667 - tn: 3119.4000 - tp: 1554.3333 - precision: 0.9939 - recall: 0.9940 - val_loss: 0.1823 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 348/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - fn: 9.4667 - fp: 10.3333 - tn: 3120.3333 - tp: 1555.8667 - precision: 0.9938 - recall: 0.9949 - val_loss: 0.1932 - val_fn: 37.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1095.0000 - val_precision: 0.9682 - val_recall: 0.9673\n",
      "Epoch 349/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0097 - fn: 13.2667 - fp: 12.2000 - tn: 3118.4667 - tp: 1552.0667 - precision: 0.9903 - recall: 0.9897 - val_loss: 0.1893 - val_fn: 32.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1100.0000 - val_precision: 0.9717 - val_recall: 0.9717\n",
      "Epoch 350/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0085 - fn: 14.2000 - fp: 12.2000 - tn: 3118.4667 - tp: 1551.1333 - precision: 0.9908 - recall: 0.9894 - val_loss: 0.1844 - val_fn: 27.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1105.0000 - val_precision: 0.9753 - val_recall: 0.9761\n",
      "Epoch 351/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0069 - fn: 10.4667 - fp: 9.8667 - tn: 3120.8000 - tp: 1554.8667 - precision: 0.9937 - recall: 0.9935 - val_loss: 0.1827 - val_fn: 24.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1108.0000 - val_precision: 0.9779 - val_recall: 0.9788\n",
      "Epoch 352/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052 - fn: 7.1333 - fp: 6.9333 - tn: 3123.7333 - tp: 1558.2000 - precision: 0.9947 - recall: 0.9949 - val_loss: 0.1857 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 353/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0053 - fn: 10.6000 - fp: 8.4000 - tn: 3122.2667 - tp: 1554.7333 - precision: 0.9956 - recall: 0.9942 - val_loss: 0.1887 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 354/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0110 - fn: 14.4000 - fp: 13.6667 - tn: 3117.0000 - tp: 1550.9333 - precision: 0.9895 - recall: 0.9890 - val_loss: 0.1849 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 355/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0076 - fn: 12.4000 - fp: 10.6667 - tn: 3120.0000 - tp: 1552.9333 - precision: 0.9939 - recall: 0.9929 - val_loss: 0.2191 - val_fn: 44.0000 - val_fp: 45.0000 - val_tn: 2219.0000 - val_tp: 1088.0000 - val_precision: 0.9603 - val_recall: 0.9611\n",
      "Epoch 356/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0143 - fn: 18.8667 - fp: 20.4000 - tn: 3110.2667 - tp: 1546.4667 - precision: 0.9835 - recall: 0.9849 - val_loss: 0.1900 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 357/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0098 - fn: 21.9333 - fp: 19.3333 - tn: 3111.3333 - tp: 1543.4000 - precision: 0.9880 - recall: 0.9866 - val_loss: 0.1994 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 358/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0533 - fn: 66.2000 - fp: 62.1333 - tn: 3068.5333 - tp: 1499.1333 - precision: 0.9663 - recall: 0.9641 - val_loss: 0.1988 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 359/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0145 - fn: 19.4000 - fp: 19.4000 - tn: 3111.2667 - tp: 1545.9333 - precision: 0.9897 - recall: 0.9901 - val_loss: 0.1827 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 360/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - fn: 5.8000 - fp: 3.8667 - tn: 3126.8000 - tp: 1559.5333 - precision: 0.9980 - recall: 0.9961 - val_loss: 0.1824 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 361/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072 - fn: 9.8000 - fp: 10.2667 - tn: 3120.4000 - tp: 1555.5333 - precision: 0.9919 - recall: 0.9925 - val_loss: 0.1815 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 362/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0045 - fn: 4.8667 - fp: 5.7333 - tn: 3124.9333 - tp: 1560.4667 - precision: 0.9972 - recall: 0.9977 - val_loss: 0.1839 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 363/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045 - fn: 4.5333 - fp: 4.0000 - tn: 3126.6667 - tp: 1560.8000 - precision: 0.9978 - recall: 0.9971 - val_loss: 0.1945 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 364/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0084 - fn: 12.8000 - fp: 12.8667 - tn: 3117.8000 - tp: 1552.5333 - precision: 0.9899 - recall: 0.9907 - val_loss: 0.1868 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 365/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0044 - fn: 8.2000 - fp: 7.6000 - tn: 3123.0667 - tp: 1557.1333 - precision: 0.9952 - recall: 0.9952 - val_loss: 0.1885 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 366/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052 - fn: 6.7333 - fp: 4.4667 - tn: 3126.2000 - tp: 1558.6000 - precision: 0.9967 - recall: 0.9952 - val_loss: 0.2047 - val_fn: 33.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1099.0000 - val_precision: 0.9708 - val_recall: 0.9708\n",
      "Epoch 367/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0097 - fn: 20.1333 - fp: 20.6667 - tn: 3110.0000 - tp: 1545.2000 - precision: 0.9856 - recall: 0.9860 - val_loss: 0.2000 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 368/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102 - fn: 20.5333 - fp: 19.5333 - tn: 3111.1333 - tp: 1544.8000 - precision: 0.9867 - recall: 0.9862 - val_loss: 0.1894 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 369/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0065 - fn: 12.0667 - fp: 12.0667 - tn: 3118.6000 - tp: 1553.2667 - precision: 0.9916 - recall: 0.9916 - val_loss: 0.1913 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 2242.0000 - val_tp: 1110.0000 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "Epoch 370/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0081 - fn: 13.7333 - fp: 13.9333 - tn: 3116.7333 - tp: 1551.6000 - precision: 0.9931 - recall: 0.9932 - val_loss: 0.1994 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 371/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115 - fn: 12.8000 - fp: 12.0667 - tn: 3118.6000 - tp: 1552.5333 - precision: 0.9941 - recall: 0.9936 - val_loss: 0.1908 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 372/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0084 - fn: 9.1333 - fp: 9.3333 - tn: 3121.3333 - tp: 1556.2000 - precision: 0.9935 - recall: 0.9935 - val_loss: 0.1893 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 373/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0049 - fn: 7.8667 - fp: 6.9333 - tn: 3123.7333 - tp: 1557.4667 - precision: 0.9959 - recall: 0.9955 - val_loss: 0.1929 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 374/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0068 - fn: 7.6667 - fp: 8.0000 - tn: 3122.6667 - tp: 1557.6667 - precision: 0.9948 - recall: 0.9951 - val_loss: 0.2015 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 375/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0051 - fn: 6.0667 - fp: 6.0667 - tn: 3124.6000 - tp: 1559.2667 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.1987 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 376/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - fn: 13.9333 - fp: 15.6000 - tn: 3115.0667 - tp: 1551.4000 - precision: 0.9889 - recall: 0.9904 - val_loss: 0.2208 - val_fn: 38.0000 - val_fp: 37.0000 - val_tn: 2227.0000 - val_tp: 1094.0000 - val_precision: 0.9673 - val_recall: 0.9664\n",
      "Epoch 377/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0132 - fn: 22.0667 - fp: 22.6000 - tn: 3108.0667 - tp: 1543.2667 - precision: 0.9846 - recall: 0.9848 - val_loss: 0.2123 - val_fn: 34.0000 - val_fp: 34.0000 - val_tn: 2230.0000 - val_tp: 1098.0000 - val_precision: 0.9700 - val_recall: 0.9700\n",
      "Epoch 378/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0188 - fn: 32.0667 - fp: 31.5333 - tn: 3099.1333 - tp: 1533.2667 - precision: 0.9788 - recall: 0.9786 - val_loss: 0.1936 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 379/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0138 - fn: 25.7333 - fp: 25.1333 - tn: 3105.5333 - tp: 1539.6000 - precision: 0.9841 - recall: 0.9838 - val_loss: 0.1954 - val_fn: 27.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1105.0000 - val_precision: 0.9753 - val_recall: 0.9761\n",
      "Epoch 380/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0086 - fn: 12.6000 - fp: 13.4000 - tn: 3117.2667 - tp: 1552.7333 - precision: 0.9914 - recall: 0.9918 - val_loss: 0.1955 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 381/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - fn: 16.3333 - fp: 15.6000 - tn: 3115.0667 - tp: 1549.0000 - precision: 0.9889 - recall: 0.9884 - val_loss: 0.1925 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 382/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0078 - fn: 15.8000 - fp: 15.5333 - tn: 3115.1333 - tp: 1549.5333 - precision: 0.9909 - recall: 0.9909 - val_loss: 0.1923 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 383/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0148 - fn: 19.6667 - fp: 18.6000 - tn: 3112.0667 - tp: 1545.6667 - precision: 0.9877 - recall: 0.9870 - val_loss: 0.2202 - val_fn: 43.0000 - val_fp: 43.0000 - val_tn: 2221.0000 - val_tp: 1089.0000 - val_precision: 0.9620 - val_recall: 0.9620\n",
      "Epoch 384/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0300 - fn: 47.6667 - fp: 47.4667 - tn: 3083.2000 - tp: 1517.6667 - precision: 0.9659 - recall: 0.9651 - val_loss: 0.2015 - val_fn: 36.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1096.0000 - val_precision: 0.9682 - val_recall: 0.9682\n",
      "Epoch 385/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0157 - fn: 28.8000 - fp: 27.6000 - tn: 3103.0667 - tp: 1536.5333 - precision: 0.9806 - recall: 0.9799 - val_loss: 0.1900 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 386/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0158 - fn: 27.5333 - fp: 26.6667 - tn: 3104.0000 - tp: 1537.8000 - precision: 0.9850 - recall: 0.9850 - val_loss: 0.1799 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1108.0000 - val_precision: 0.9797 - val_recall: 0.9788\n",
      "Epoch 387/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0118 - fn: 16.4000 - fp: 17.4000 - tn: 3113.2667 - tp: 1548.9333 - precision: 0.9882 - recall: 0.9893 - val_loss: 0.1850 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 388/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0060 - fn: 11.3333 - fp: 12.0667 - tn: 3118.6000 - tp: 1554.0000 - precision: 0.9924 - recall: 0.9926 - val_loss: 0.1884 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 389/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0056 - fn: 4.6667 - fp: 4.6667 - tn: 3126.0000 - tp: 1560.6667 - precision: 0.9976 - recall: 0.9976 - val_loss: 0.1887 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 390/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0056 - fn: 7.8667 - fp: 8.0000 - tn: 3122.6667 - tp: 1557.4667 - precision: 0.9956 - recall: 0.9957 - val_loss: 0.1918 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 391/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0044 - fn: 4.1333 - fp: 4.1333 - tn: 3126.5333 - tp: 1561.2000 - precision: 0.9970 - recall: 0.9970 - val_loss: 0.1919 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 392/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0040 - fn: 5.9333 - fp: 6.0000 - tn: 3124.6667 - tp: 1559.4000 - precision: 0.9959 - recall: 0.9963 - val_loss: 0.1942 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1108.0000 - val_precision: 0.9797 - val_recall: 0.9788\n",
      "Epoch 393/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036 - fn: 4.4667 - fp: 4.4667 - tn: 3126.2000 - tp: 1560.8667 - precision: 0.9972 - recall: 0.9972 - val_loss: 0.1983 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 394/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028 - fn: 3.9333 - fp: 4.8000 - tn: 3125.8667 - tp: 1561.4000 - precision: 0.9967 - recall: 0.9973 - val_loss: 0.1997 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 2242.0000 - val_tp: 1110.0000 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "Epoch 395/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060 - fn: 9.4667 - fp: 8.8000 - tn: 3121.8667 - tp: 1555.8667 - precision: 0.9948 - recall: 0.9945 - val_loss: 0.2000 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 396/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036 - fn: 5.9333 - fp: 5.9333 - tn: 3124.7333 - tp: 1559.4000 - precision: 0.9966 - recall: 0.9966 - val_loss: 0.2026 - val_fn: 22.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1110.0000 - val_precision: 0.9797 - val_recall: 0.9806\n",
      "Epoch 397/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0100 - fn: 17.3333 - fp: 16.6000 - tn: 3114.0667 - tp: 1548.0000 - precision: 0.9918 - recall: 0.9915 - val_loss: 0.2043 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 398/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - fn: 16.0667 - fp: 17.0000 - tn: 3113.6667 - tp: 1549.2667 - precision: 0.9924 - recall: 0.9928 - val_loss: 0.2059 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 399/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0167 - fn: 15.8000 - fp: 16.6000 - tn: 3114.0667 - tp: 1549.5333 - precision: 0.9907 - recall: 0.9910 - val_loss: 0.2058 - val_fn: 26.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1106.0000 - val_precision: 0.9762 - val_recall: 0.9770\n",
      "Epoch 400/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0134 - fn: 19.3333 - fp: 17.2667 - tn: 3113.4000 - tp: 1546.0000 - precision: 0.9894 - recall: 0.9877 - val_loss: 0.2121 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 401/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0068 - fn: 13.1333 - fp: 16.8000 - tn: 3113.8667 - tp: 1552.2000 - precision: 0.9884 - recall: 0.9913 - val_loss: 0.1992 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 402/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0085 - fn: 16.8667 - fp: 15.6667 - tn: 3115.0000 - tp: 1548.4667 - precision: 0.9902 - recall: 0.9894 - val_loss: 0.2292 - val_fn: 42.0000 - val_fp: 42.0000 - val_tn: 2222.0000 - val_tp: 1090.0000 - val_precision: 0.9629 - val_recall: 0.9629\n",
      "Epoch 403/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0709 - fn: 114.9333 - fp: 109.9333 - tn: 3020.7333 - tp: 1450.4000 - precision: 0.9293 - recall: 0.9248 - val_loss: 0.5414 - val_fn: 241.0000 - val_fp: 240.0000 - val_tn: 2024.0000 - val_tp: 891.0000 - val_precision: 0.7878 - val_recall: 0.7871\n",
      "Epoch 404/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.1375 - fn: 188.4000 - fp: 189.5333 - tn: 2941.1333 - tp: 1376.9333 - precision: 0.8441 - recall: 0.8447 - val_loss: 0.2394 - val_fn: 72.0000 - val_fp: 75.0000 - val_tn: 2189.0000 - val_tp: 1060.0000 - val_precision: 0.9339 - val_recall: 0.9364\n",
      "Epoch 405/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0549 - fn: 87.9333 - fp: 95.6667 - tn: 3035.0000 - tp: 1477.4000 - precision: 0.9314 - recall: 0.9362 - val_loss: 0.1770 - val_fn: 25.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1107.0000 - val_precision: 0.9796 - val_recall: 0.9779\n",
      "Epoch 406/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0206 - fn: 18.6000 - fp: 19.8667 - tn: 3110.8000 - tp: 1546.7333 - precision: 0.9875 - recall: 0.9887 - val_loss: 0.1806 - val_fn: 36.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1096.0000 - val_precision: 0.9682 - val_recall: 0.9682\n",
      "Epoch 407/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0149 - fn: 16.0667 - fp: 16.9333 - tn: 3113.7333 - tp: 1549.2667 - precision: 0.9870 - recall: 0.9876 - val_loss: 0.1771 - val_fn: 32.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1100.0000 - val_precision: 0.9709 - val_recall: 0.9717\n",
      "Epoch 408/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0121 - fn: 16.8667 - fp: 20.6000 - tn: 3110.0667 - tp: 1548.4667 - precision: 0.9854 - recall: 0.9885 - val_loss: 0.1886 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 409/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0080 - fn: 16.6000 - fp: 16.0667 - tn: 3114.6000 - tp: 1548.7333 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.1941 - val_fn: 30.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1102.0000 - val_precision: 0.9744 - val_recall: 0.9735\n",
      "Epoch 410/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0068 - fn: 11.1333 - fp: 9.6000 - tn: 3121.0667 - tp: 1554.2000 - precision: 0.9944 - recall: 0.9931 - val_loss: 0.1912 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 411/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079 - fn: 9.6000 - fp: 9.2667 - tn: 3121.4000 - tp: 1555.7333 - precision: 0.9944 - recall: 0.9943 - val_loss: 0.1880 - val_fn: 28.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1104.0000 - val_precision: 0.9770 - val_recall: 0.9753\n",
      "Epoch 412/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0076 - fn: 9.6667 - fp: 9.5333 - tn: 3121.1333 - tp: 1555.6667 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.1939 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 413/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061 - fn: 5.8000 - fp: 6.7333 - tn: 3123.9333 - tp: 1559.5333 - precision: 0.9963 - recall: 0.9967 - val_loss: 0.1984 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 414/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045 - fn: 7.6000 - fp: 5.2667 - tn: 3125.4000 - tp: 1557.7333 - precision: 0.9971 - recall: 0.9956 - val_loss: 0.1987 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 415/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0067 - fn: 9.2000 - fp: 9.6000 - tn: 3121.0667 - tp: 1556.1333 - precision: 0.9926 - recall: 0.9930 - val_loss: 0.2022 - val_fn: 29.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1103.0000 - val_precision: 0.9761 - val_recall: 0.9744\n",
      "Epoch 416/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0051 - fn: 9.4667 - fp: 8.6667 - tn: 3122.0000 - tp: 1555.8667 - precision: 0.9944 - recall: 0.9939 - val_loss: 0.2043 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 417/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0126 - fn: 28.4667 - fp: 26.7333 - tn: 3103.9333 - tp: 1536.8667 - precision: 0.9842 - recall: 0.9833 - val_loss: 0.2062 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 418/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056 - fn: 6.7333 - fp: 6.2000 - tn: 3124.4667 - tp: 1558.6000 - precision: 0.9961 - recall: 0.9959 - val_loss: 0.2035 - val_fn: 26.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1106.0000 - val_precision: 0.9779 - val_recall: 0.9770\n",
      "Epoch 419/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060 - fn: 12.0000 - fp: 11.2000 - tn: 3119.4667 - tp: 1553.3333 - precision: 0.9930 - recall: 0.9925 - val_loss: 0.2014 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 420/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059 - fn: 12.2667 - fp: 11.8667 - tn: 3118.8000 - tp: 1553.0667 - precision: 0.9920 - recall: 0.9919 - val_loss: 0.2053 - val_fn: 25.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1107.0000 - val_precision: 0.9796 - val_recall: 0.9779\n",
      "Epoch 421/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062 - fn: 4.8000 - fp: 4.2000 - tn: 3126.4667 - tp: 1560.5333 - precision: 0.9974 - recall: 0.9970 - val_loss: 0.2091 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 422/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0049 - fn: 9.8667 - fp: 9.8000 - tn: 3120.8667 - tp: 1555.4667 - precision: 0.9942 - recall: 0.9941 - val_loss: 0.2050 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 423/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055 - fn: 9.3333 - fp: 8.5333 - tn: 3122.1333 - tp: 1556.0000 - precision: 0.9946 - recall: 0.9936 - val_loss: 0.2066 - val_fn: 23.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1109.0000 - val_precision: 0.9814 - val_recall: 0.9797\n",
      "Epoch 424/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0036 - fn: 5.6667 - fp: 8.0667 - tn: 3122.6000 - tp: 1559.6667 - precision: 0.9946 - recall: 0.9965 - val_loss: 0.2127 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 425/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032 - fn: 5.1333 - fp: 5.1333 - tn: 3125.5333 - tp: 1560.2000 - precision: 0.9965 - recall: 0.9965 - val_loss: 0.2161 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 426/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0044 - fn: 7.6000 - fp: 7.6000 - tn: 3123.0667 - tp: 1557.7333 - precision: 0.9943 - recall: 0.9943 - val_loss: 0.2099 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1111.0000 - val_precision: 0.9814 - val_recall: 0.9814\n",
      "Epoch 427/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0046 - fn: 7.0667 - fp: 6.0000 - tn: 3124.6667 - tp: 1558.2667 - precision: 0.9967 - recall: 0.9956 - val_loss: 0.2113 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1108.0000 - val_precision: 0.9797 - val_recall: 0.9788\n",
      "Epoch 428/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0048 - fn: 10.0000 - fp: 9.7333 - tn: 3120.9333 - tp: 1555.3333 - precision: 0.9948 - recall: 0.9947 - val_loss: 0.2142 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1111.0000 - val_precision: 0.9814 - val_recall: 0.9814\n",
      "Epoch 429/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0029 - fn: 3.2667 - fp: 3.2667 - tn: 3127.4000 - tp: 1562.0667 - precision: 0.9983 - recall: 0.9983 - val_loss: 0.2120 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 430/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0027 - fn: 4.1333 - fp: 3.8000 - tn: 3126.8667 - tp: 1561.2000 - precision: 0.9979 - recall: 0.9977 - val_loss: 0.2152 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 431/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0035 - fn: 6.9333 - fp: 6.9333 - tn: 3123.7333 - tp: 1558.4000 - precision: 0.9950 - recall: 0.9950 - val_loss: 0.2147 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1111.0000 - val_precision: 0.9814 - val_recall: 0.9814\n",
      "Epoch 432/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0038 - fn: 6.0000 - fp: 5.2667 - tn: 3125.4000 - tp: 1559.3333 - precision: 0.9962 - recall: 0.9958 - val_loss: 0.2148 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 433/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0071 - fn: 9.4667 - fp: 8.4667 - tn: 3122.2000 - tp: 1555.8667 - precision: 0.9948 - recall: 0.9937 - val_loss: 0.2146 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 434/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0042 - fn: 3.6667 - fp: 3.6667 - tn: 3127.0000 - tp: 1561.6667 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.2167 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 435/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0041 - fn: 7.1333 - fp: 6.4000 - tn: 3124.2667 - tp: 1558.2000 - precision: 0.9962 - recall: 0.9958 - val_loss: 0.2189 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 436/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0028 - fn: 6.0667 - fp: 6.0667 - tn: 3124.6000 - tp: 1559.2667 - precision: 0.9961 - recall: 0.9961 - val_loss: 0.2180 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1111.0000 - val_precision: 0.9814 - val_recall: 0.9814\n",
      "Epoch 437/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0037 - fn: 5.0000 - fp: 5.0000 - tn: 3125.6667 - tp: 1560.3333 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.2169 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 438/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0034 - fn: 8.6667 - fp: 8.8000 - tn: 3121.8667 - tp: 1556.6667 - precision: 0.9944 - recall: 0.9945 - val_loss: 0.2213 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 439/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0025 - fn: 5.0667 - fp: 4.0667 - tn: 3126.6000 - tp: 1560.2667 - precision: 0.9980 - recall: 0.9976 - val_loss: 0.3231 - val_fn: 65.0000 - val_fp: 65.0000 - val_tn: 2199.0000 - val_tp: 1067.0000 - val_precision: 0.9426 - val_recall: 0.9426\n",
      "Epoch 440/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2578 - fn: 256.6667 - fp: 256.3333 - tn: 2874.3333 - tp: 1308.6667 - precision: 0.8266 - recall: 0.8260 - val_loss: 0.3789 - val_fn: 134.0000 - val_fp: 147.0000 - val_tn: 2117.0000 - val_tp: 998.0000 - val_precision: 0.8716 - val_recall: 0.8816\n",
      "Epoch 441/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0913 - fn: 128.8667 - fp: 128.9333 - tn: 3001.7333 - tp: 1436.4667 - precision: 0.9052 - recall: 0.9044 - val_loss: 0.1990 - val_fn: 32.0000 - val_fp: 38.0000 - val_tn: 2226.0000 - val_tp: 1100.0000 - val_precision: 0.9666 - val_recall: 0.9717\n",
      "Epoch 442/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0788 - fn: 30.0000 - fp: 43.1333 - tn: 3087.5333 - tp: 1535.3333 - precision: 0.9724 - recall: 0.9804 - val_loss: 0.1789 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 443/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0163 - fn: 13.0667 - fp: 17.0000 - tn: 3113.6667 - tp: 1552.2667 - precision: 0.9894 - recall: 0.9919 - val_loss: 0.1927 - val_fn: 31.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1101.0000 - val_precision: 0.9718 - val_recall: 0.9726\n",
      "Epoch 444/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0326 - fn: 18.7333 - fp: 22.7333 - tn: 3107.9333 - tp: 1546.6000 - precision: 0.9846 - recall: 0.9870 - val_loss: 0.1887 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 445/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0113 - fn: 17.0000 - fp: 16.8667 - tn: 3113.8000 - tp: 1548.3333 - precision: 0.9904 - recall: 0.9902 - val_loss: 0.1888 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 446/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0083 - fn: 14.8667 - fp: 16.2000 - tn: 3114.4667 - tp: 1550.4667 - precision: 0.9892 - recall: 0.9906 - val_loss: 0.1880 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 447/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0068 - fn: 13.0000 - fp: 11.8000 - tn: 3118.8667 - tp: 1552.3333 - precision: 0.9929 - recall: 0.9924 - val_loss: 0.1903 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 448/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066 - fn: 8.9333 - fp: 8.3333 - tn: 3122.3333 - tp: 1556.4000 - precision: 0.9956 - recall: 0.9947 - val_loss: 0.2038 - val_fn: 29.0000 - val_fp: 29.0000 - val_tn: 2235.0000 - val_tp: 1103.0000 - val_precision: 0.9744 - val_recall: 0.9744\n",
      "Epoch 449/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059 - fn: 9.1333 - fp: 9.7333 - tn: 3120.9333 - tp: 1556.2000 - precision: 0.9933 - recall: 0.9936 - val_loss: 0.2050 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 450/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0047 - fn: 9.7333 - fp: 9.0000 - tn: 3121.6667 - tp: 1555.6000 - precision: 0.9947 - recall: 0.9937 - val_loss: 0.2034 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 451/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0067 - fn: 8.1333 - fp: 7.6000 - tn: 3123.0667 - tp: 1557.2000 - precision: 0.9953 - recall: 0.9951 - val_loss: 0.2125 - val_fn: 29.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1103.0000 - val_precision: 0.9761 - val_recall: 0.9744\n",
      "Epoch 452/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0047 - fn: 6.4000 - fp: 7.5333 - tn: 3123.1333 - tp: 1558.9333 - precision: 0.9952 - recall: 0.9958 - val_loss: 0.2171 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 453/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0058 - fn: 8.4667 - fp: 6.8000 - tn: 3123.8667 - tp: 1556.8667 - precision: 0.9953 - recall: 0.9938 - val_loss: 0.2211 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 454/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - fn: 6.7333 - fp: 6.7333 - tn: 3123.9333 - tp: 1558.6000 - precision: 0.9959 - recall: 0.9959 - val_loss: 0.2217 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 455/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0079 - fn: 10.0000 - fp: 9.8667 - tn: 3120.8000 - tp: 1555.3333 - precision: 0.9946 - recall: 0.9946 - val_loss: 0.2271 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 456/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0067 - fn: 13.1333 - fp: 11.6667 - tn: 3119.0000 - tp: 1552.2000 - precision: 0.9914 - recall: 0.9905 - val_loss: 0.2323 - val_fn: 30.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1102.0000 - val_precision: 0.9752 - val_recall: 0.9735\n",
      "Epoch 457/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0073 - fn: 9.4667 - fp: 9.4667 - tn: 3121.2000 - tp: 1555.8667 - precision: 0.9941 - recall: 0.9941 - val_loss: 0.2252 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 458/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071 - fn: 8.6667 - fp: 9.2000 - tn: 3121.4667 - tp: 1556.6667 - precision: 0.9949 - recall: 0.9952 - val_loss: 0.2254 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 459/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059 - fn: 7.7333 - fp: 7.2000 - tn: 3123.4667 - tp: 1557.6000 - precision: 0.9943 - recall: 0.9940 - val_loss: 0.2346 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 460/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0108 - fn: 9.6667 - fp: 10.7333 - tn: 3119.9333 - tp: 1555.6667 - precision: 0.9924 - recall: 0.9931 - val_loss: 0.2264 - val_fn: 29.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1103.0000 - val_precision: 0.9752 - val_recall: 0.9744\n",
      "Epoch 461/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0069 - fn: 11.0000 - fp: 11.0000 - tn: 3119.6667 - tp: 1554.3333 - precision: 0.9926 - recall: 0.9926 - val_loss: 0.2427 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 462/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0077 - fn: 14.5333 - fp: 14.7333 - tn: 3115.9333 - tp: 1550.8000 - precision: 0.9897 - recall: 0.9898 - val_loss: 0.2344 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 463/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0078 - fn: 8.0000 - fp: 10.0667 - tn: 3120.6000 - tp: 1557.3333 - precision: 0.9941 - recall: 0.9954 - val_loss: 0.2332 - val_fn: 28.0000 - val_fp: 28.0000 - val_tn: 2236.0000 - val_tp: 1104.0000 - val_precision: 0.9753 - val_recall: 0.9753\n",
      "Epoch 464/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0079 - fn: 5.8000 - fp: 6.4000 - tn: 3124.2667 - tp: 1559.5333 - precision: 0.9963 - recall: 0.9965 - val_loss: 0.2330 - val_fn: 26.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1106.0000 - val_precision: 0.9762 - val_recall: 0.9770\n",
      "Epoch 465/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0143 - fn: 5.0000 - fp: 5.8667 - tn: 3124.8000 - tp: 1560.3333 - precision: 0.9970 - recall: 0.9976 - val_loss: 0.2269 - val_fn: 32.0000 - val_fp: 32.0000 - val_tn: 2232.0000 - val_tp: 1100.0000 - val_precision: 0.9717 - val_recall: 0.9717\n",
      "Epoch 466/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0311 - fn: 13.1333 - fp: 13.1333 - tn: 3117.5333 - tp: 1552.2000 - precision: 0.9903 - recall: 0.9903 - val_loss: 0.2548 - val_fn: 31.0000 - val_fp: 31.0000 - val_tn: 2233.0000 - val_tp: 1101.0000 - val_precision: 0.9726 - val_recall: 0.9726\n",
      "Epoch 467/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.1167 - fn: 11.3333 - fp: 10.6000 - tn: 3120.0667 - tp: 1554.0000 - precision: 0.9910 - recall: 0.9907 - val_loss: 0.2037 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 468/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0109 - fn: 6.5333 - fp: 6.2667 - tn: 3124.4000 - tp: 1558.8000 - precision: 0.9967 - recall: 0.9967 - val_loss: 0.2171 - val_fn: 25.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1107.0000 - val_precision: 0.9771 - val_recall: 0.9779\n",
      "Epoch 469/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0074 - fn: 8.2667 - fp: 6.6667 - tn: 3124.0000 - tp: 1557.0667 - precision: 0.9961 - recall: 0.9945 - val_loss: 0.2117 - val_fn: 26.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1106.0000 - val_precision: 0.9762 - val_recall: 0.9770\n",
      "Epoch 470/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062 - fn: 8.4667 - fp: 7.0667 - tn: 3123.6000 - tp: 1556.8667 - precision: 0.9951 - recall: 0.9941 - val_loss: 0.2220 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 471/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0093 - fn: 12.4000 - fp: 11.4000 - tn: 3119.2667 - tp: 1552.9333 - precision: 0.9942 - recall: 0.9931 - val_loss: 0.2177 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 472/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0087 - fn: 9.9333 - fp: 7.7333 - tn: 3122.9333 - tp: 1555.4000 - precision: 0.9960 - recall: 0.9949 - val_loss: 0.2234 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 473/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0275 - fn: 10.3333 - fp: 8.8667 - tn: 3121.8000 - tp: 1555.0000 - precision: 0.9955 - recall: 0.9947 - val_loss: 0.2139 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 474/500\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0418 - fn: 33.0000 - fp: 30.0000 - tn: 3100.6667 - tp: 1532.3333 - precision: 0.9842 - recall: 0.9826 - val_loss: 0.2470 - val_fn: 40.0000 - val_fp: 40.0000 - val_tn: 2224.0000 - val_tp: 1092.0000 - val_precision: 0.9647 - val_recall: 0.9647\n",
      "Epoch 475/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0353 - fn: 21.4667 - fp: 23.6667 - tn: 3107.0000 - tp: 1543.8667 - precision: 0.9871 - recall: 0.9883 - val_loss: 0.2555 - val_fn: 47.0000 - val_fp: 49.0000 - val_tn: 2215.0000 - val_tp: 1085.0000 - val_precision: 0.9568 - val_recall: 0.9585\n",
      "Epoch 476/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0283 - fn: 26.8667 - fp: 27.9333 - tn: 3102.7333 - tp: 1538.4667 - precision: 0.9812 - recall: 0.9817 - val_loss: 0.2748 - val_fn: 62.0000 - val_fp: 70.0000 - val_tn: 2194.0000 - val_tp: 1070.0000 - val_precision: 0.9386 - val_recall: 0.9452\n",
      "Epoch 477/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0371 - fn: 41.6667 - fp: 44.8000 - tn: 3085.8667 - tp: 1523.6667 - precision: 0.9676 - recall: 0.9690 - val_loss: 0.1955 - val_fn: 35.0000 - val_fp: 36.0000 - val_tn: 2228.0000 - val_tp: 1097.0000 - val_precision: 0.9682 - val_recall: 0.9691\n",
      "Epoch 478/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0143 - fn: 25.2000 - fp: 27.6667 - tn: 3103.0000 - tp: 1540.1333 - precision: 0.9815 - recall: 0.9835 - val_loss: 0.1933 - val_fn: 30.0000 - val_fp: 30.0000 - val_tn: 2234.0000 - val_tp: 1102.0000 - val_precision: 0.9735 - val_recall: 0.9735\n",
      "Epoch 479/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0096 - fn: 13.0000 - fp: 14.5333 - tn: 3116.1333 - tp: 1552.3333 - precision: 0.9905 - recall: 0.9914 - val_loss: 0.1952 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 480/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056 - fn: 9.2667 - fp: 9.2667 - tn: 3121.4000 - tp: 1556.0667 - precision: 0.9929 - recall: 0.9929 - val_loss: 0.1960 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 481/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066 - fn: 7.0000 - fp: 7.0000 - tn: 3123.6667 - tp: 1558.3333 - precision: 0.9955 - recall: 0.9955 - val_loss: 0.1974 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 482/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0077 - fn: 6.1333 - fp: 7.4667 - tn: 3123.2000 - tp: 1559.2000 - precision: 0.9951 - recall: 0.9960 - val_loss: 0.1952 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 483/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056 - fn: 6.2000 - fp: 7.7333 - tn: 3122.9333 - tp: 1559.1333 - precision: 0.9948 - recall: 0.9955 - val_loss: 0.1990 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 484/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0047 - fn: 7.4000 - fp: 7.4000 - tn: 3123.2667 - tp: 1557.9333 - precision: 0.9947 - recall: 0.9947 - val_loss: 0.2009 - val_fn: 23.0000 - val_fp: 22.0000 - val_tn: 2242.0000 - val_tp: 1109.0000 - val_precision: 0.9805 - val_recall: 0.9797\n",
      "Epoch 485/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056 - fn: 3.3333 - fp: 3.0000 - tn: 3127.6667 - tp: 1562.0000 - precision: 0.9982 - recall: 0.9981 - val_loss: 0.2035 - val_fn: 25.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1107.0000 - val_precision: 0.9788 - val_recall: 0.9779\n",
      "Epoch 486/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0060 - fn: 10.8667 - fp: 10.2667 - tn: 3120.4000 - tp: 1554.4667 - precision: 0.9931 - recall: 0.9928 - val_loss: 0.2097 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 487/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0050 - fn: 2.8000 - fp: 2.8000 - tn: 3127.8667 - tp: 1562.5333 - precision: 0.9981 - recall: 0.9981 - val_loss: 0.2057 - val_fn: 23.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1109.0000 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "Epoch 488/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0039 - fn: 4.0667 - fp: 2.8000 - tn: 3127.8667 - tp: 1561.2667 - precision: 0.9984 - recall: 0.9977 - val_loss: 0.2146 - val_fn: 27.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1105.0000 - val_precision: 0.9770 - val_recall: 0.9761\n",
      "Epoch 489/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0033 - fn: 7.1333 - fp: 7.4667 - tn: 3123.2000 - tp: 1558.2000 - precision: 0.9953 - recall: 0.9954 - val_loss: 0.2155 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1108.0000 - val_precision: 0.9797 - val_recall: 0.9788\n",
      "Epoch 490/500\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0029 - fn: 4.0667 - fp: 3.5333 - tn: 3127.1333 - tp: 1561.2667 - precision: 0.9984 - recall: 0.9980 - val_loss: 0.2173 - val_fn: 26.0000 - val_fp: 26.0000 - val_tn: 2238.0000 - val_tp: 1106.0000 - val_precision: 0.9770 - val_recall: 0.9770\n",
      "Epoch 491/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0047 - fn: 5.0667 - fp: 5.9333 - tn: 3124.7333 - tp: 1560.2667 - precision: 0.9954 - recall: 0.9960 - val_loss: 0.2197 - val_fn: 27.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1105.0000 - val_precision: 0.9761 - val_recall: 0.9761\n",
      "Epoch 492/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0038 - fn: 5.6000 - fp: 7.2000 - tn: 3123.4667 - tp: 1559.7333 - precision: 0.9952 - recall: 0.9962 - val_loss: 0.2158 - val_fn: 21.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1111.0000 - val_precision: 0.9814 - val_recall: 0.9814\n",
      "Epoch 493/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0028 - fn: 4.1333 - fp: 4.6000 - tn: 3126.0667 - tp: 1561.2000 - precision: 0.9971 - recall: 0.9973 - val_loss: 0.2219 - val_fn: 25.0000 - val_fp: 25.0000 - val_tn: 2239.0000 - val_tp: 1107.0000 - val_precision: 0.9779 - val_recall: 0.9779\n",
      "Epoch 494/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0033 - fn: 4.8000 - fp: 6.0000 - tn: 3124.6667 - tp: 1560.5333 - precision: 0.9958 - recall: 0.9966 - val_loss: 0.2200 - val_fn: 22.0000 - val_fp: 22.0000 - val_tn: 2242.0000 - val_tp: 1110.0000 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "Epoch 495/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0036 - fn: 5.1333 - fp: 5.7333 - tn: 3124.9333 - tp: 1560.2000 - precision: 0.9967 - recall: 0.9970 - val_loss: 0.2219 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1108.0000 - val_precision: 0.9797 - val_recall: 0.9788\n",
      "Epoch 496/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0034 - fn: 4.6667 - fp: 3.9333 - tn: 3126.7333 - tp: 1560.6667 - precision: 0.9977 - recall: 0.9973 - val_loss: 0.2315 - val_fn: 28.0000 - val_fp: 27.0000 - val_tn: 2237.0000 - val_tp: 1104.0000 - val_precision: 0.9761 - val_recall: 0.9753\n",
      "Epoch 497/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0046 - fn: 7.2000 - fp: 8.0000 - tn: 3122.6667 - tp: 1558.1333 - precision: 0.9937 - recall: 0.9947 - val_loss: 0.2241 - val_fn: 24.0000 - val_fp: 24.0000 - val_tn: 2240.0000 - val_tp: 1108.0000 - val_precision: 0.9788 - val_recall: 0.9788\n",
      "Epoch 498/500\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031 - fn: 7.0667 - fp: 5.4667 - tn: 3125.2000 - tp: 1558.2667 - precision: 0.9962 - recall: 0.9952 - val_loss: 0.2269 - val_fn: 24.0000 - val_fp: 23.0000 - val_tn: 2241.0000 - val_tp: 1108.0000 - val_precision: 0.9797 - val_recall: 0.9788\n",
      "Epoch 499/500\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0024 - fn: 7.2000 - fp: 7.2000 - tn: 3123.4667 - tp: 1558.1333 - precision: 0.9956 - recall: 0.9956 - val_loss: 0.2327 - val_fn: 22.0000 - val_fp: 21.0000 - val_tn: 2243.0000 - val_tp: 1110.0000 - val_precision: 0.9814 - val_recall: 0.9806\n",
      "Epoch 500/500\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0066 - fn: 10.1333 - fp: 8.8000 - tn: 3121.8667 - tp: 1555.2000 - precision: 0.9962 - recall: 0.9955 - val_loss: 0.2428 - val_fn: 32.0000 - val_fp: 33.0000 - val_tn: 2231.0000 - val_tp: 1100.0000 - val_precision: 0.9709 - val_recall: 0.9717\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7f4ec4374fd0>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-3), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"checkpoints/thyroid_model_at_epoch_{epoch}.h5\")]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=200,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    class_weight=d_class_weights,\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1627161206593,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "I-KfNDpdg6tj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TrainPredictions = model.predict(inputTrain)\n",
    "TrainPredictions = np.argmax(TrainPredictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1627161207021,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "Hzv9ccyjV8u5",
    "outputId": "b95308f0-7a89-4c6f-8ac3-afce0deb7264",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 15.0, 'Predicted label')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(outputTrain, TrainPredictions)\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "# plot confusion matrix\n",
    "plt.imshow(conf, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "plt.title(\"Train Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "fmt = 'd'\n",
    "thresh = conf.max() / 2.\n",
    "for i, j in itertools.product(range(conf.shape[0]), range(conf.shape[1])):\n",
    "    plt.text(j, i, format(conf[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if conf[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1627161207025,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "nfF7KaksWXqC",
    "outputId": "29d04dfe-bbc9-4e72-ed2b-89dcb079d7b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  84    7    2]\n",
      " [  21  138   32]\n",
      " [  23   44 3421]]\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n",
      "Micro Precision: 0.97\n",
      "Micro Recall: 0.97\n",
      "Micro F1-score: 0.97\n",
      "\n",
      "Macro Precision: 0.79\n",
      "Macro Recall: 0.87\n",
      "Macro F1-score: 0.82\n",
      "\n",
      "Weighted Precision: 0.97\n",
      "Weighted Recall: 0.97\n",
      "Weighted F1-score: 0.97\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.66      0.90      0.76        93\n",
      "     Class 2       0.73      0.72      0.73       191\n",
      "     Class 3       0.99      0.98      0.99      3488\n",
      "\n",
      "    accuracy                           0.97      3772\n",
      "   macro avg       0.79      0.87      0.82      3772\n",
      "weighted avg       0.97      0.97      0.97      3772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix\\n')\n",
    "print(conf)\n",
    "\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(outputTrain, TrainPredictions)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(outputTrain, TrainPredictions, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(outputTrain, TrainPredictions, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(outputTrain, TrainPredictions, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(outputTrain, TrainPredictions, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(outputTrain, TrainPredictions, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(outputTrain, TrainPredictions, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(outputTrain, TrainPredictions, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(outputTrain, TrainPredictions, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(outputTrain, TrainPredictions, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(outputTrain, TrainPredictions, target_names=['Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1627161207026,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "B8X_irRRVwxQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TestPredictions = model.predict(inputTest)\n",
    "TestPredictions = np.argmax(TestPredictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1627161207390,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "E-xeUrkIA8-A",
    "outputId": "662030e4-4117-4343-cb91-c2763f32e238",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 15.0, 'Predicted label')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(outputTest, TestPredictions)\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "# plot confusion matrix\n",
    "plt.imshow(conf, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "fmt = 'd'\n",
    "thresh = conf.max() / 2.\n",
    "for i, j in itertools.product(range(conf.shape[0]), range(conf.shape[1])):\n",
    "    plt.text(j, i, format(conf[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if conf[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1627161207392,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "YzVuA0AwL5be",
    "outputId": "537ac605-48b5-4a5b-f781-4fd95cc6fb67",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[  50   18    5]\n",
      " [  11  127   39]\n",
      " [  39   61 3078]]\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n",
      "Micro Precision: 0.95\n",
      "Micro Recall: 0.95\n",
      "Micro F1-score: 0.95\n",
      "\n",
      "Macro Precision: 0.70\n",
      "Macro Recall: 0.79\n",
      "Macro F1-score: 0.74\n",
      "\n",
      "Weighted Precision: 0.96\n",
      "Weighted Recall: 0.95\n",
      "Weighted F1-score: 0.95\n",
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 1       0.50      0.68      0.58        73\n",
      "     Class 2       0.62      0.72      0.66       177\n",
      "     Class 3       0.99      0.97      0.98      3178\n",
      "\n",
      "    accuracy                           0.95      3428\n",
      "   macro avg       0.70      0.79      0.74      3428\n",
      "weighted avg       0.96      0.95      0.95      3428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix\\n')\n",
    "print(conf)\n",
    "\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(outputTest, TestPredictions)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(outputTest, TestPredictions, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(outputTest, TestPredictions, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(outputTest, TestPredictions, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(outputTest, TestPredictions, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(outputTest, TestPredictions, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(outputTest, TestPredictions, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(outputTest, TestPredictions, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(outputTest, TestPredictions, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(outputTest, TestPredictions, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(outputTest, TestPredictions, target_names=['Class 1', 'Class 2', 'Class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1627161207648,
     "user": {
      "displayName": "Mauro Roisenberg",
      "photoUrl": "",
      "userId": "14628479211278551410"
     },
     "user_tz": 180
    },
    "id": "bWFMjqdYUwVm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercicio Tireoide.ipynb",
   "provenance": [
    {
     "file_id": "1Z5luJsl-IYT-v9zbj60Xd-Q7WubyB-Vy",
     "timestamp": 1627005465267
    },
    {
     "file_id": "1r6kPh4dwuGaPnd46hCfhz_FsI1cIgIaw",
     "timestamp": 1626995069751
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c79f3b749ac1c615955d5d100e4e2835a83d7f04dde803c7105836bec394313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}