{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expriment with Sine function\n",
    "\n",
    "In this experiment, we try to build models using Keras framework to learn and predict the sine function.\n",
    "We test several parameters and check how well the networks learn and generalize.\n",
    "\n",
    "**NOTE:** The model train methods were unified into a generalized method that could receive the hyperparameters and build distinct neural networks.\n",
    "\n",
    "## Desktop used to run the experiment\n",
    "\n",
    "- Computador Dell XPS-8930-A5GM\n",
    "- Intel i7 8700\n",
    "- RAM 16GB\n",
    "- HD 2TB\n",
    "- GeForce GTX 1050 Ti 4GB\n",
    "\n",
    "## Libraries\n",
    "\n",
    "- Keras 2.4.3 (Using GPU)\n",
    "- Tensorflow 2.4.1 (Using GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "In this assignment, the function was modified to allow changes on the train/test sets sizes, noise scale, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(noise_scale=0.1, test_size=0.15,  out_start=0, out_end=2*np.pi, ntot=100):\n",
    "\n",
    "    \n",
    "    # Proportion of train size\n",
    "    train_size = 1 - test_size\n",
    "    \n",
    "    # Number of training examples\n",
    "    ntrain = int(train_size * ntot)\n",
    "\n",
    "    # Number of test examples\n",
    "    ntest = int(test_size * ntot)\n",
    "\n",
    "    #\n",
    "    #  range of values from random number function generator\n",
    "    #\n",
    "    in_start = 0\n",
    "    in_end = 1\n",
    "    \n",
    "    #\n",
    "    # Mapping the original values of random to the disired scale\n",
    "    #\n",
    "    slope = (out_end - out_start) / (in_end - in_start)\n",
    "    in_value = np.random.rand(ntot,1) \n",
    "    \n",
    "    #\n",
    "    # Final dataset\n",
    "    #\n",
    "    x = out_start + slope * (in_value - in_start)\n",
    "\n",
    "    #\n",
    "    # Generating noise\n",
    "    #\n",
    "    s=np.random.normal(0, noise_scale, size = (ntot,1))\n",
    "\n",
    "    #\n",
    "    # Generating output\n",
    "    #\n",
    "    y=np.sin(x)+s\n",
    "\n",
    "    #\n",
    "    # Dataset splitting\n",
    "    #\n",
    "    xtrain, xtest = x[:ntrain], x[ntrain:]\n",
    "    ytrain, ytest = y[:ntrain], y[ntrain:]\n",
    "\n",
    "    # Visualizing the train set using scatter splot\n",
    "    plt.plot(xtrain.T,ytrain.T,color = 'red', marker = \"o\")\n",
    "    plt.title(\"seno\")\n",
    "    plt.xlabel(\"Angulo\")\n",
    "    plt.ylabel(\"Seno\")\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"imgs/dataset_ns=%.2f_test_size=%.2f_ntot=%d.png\" %(ns, test_size, ntot), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    return xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(xtrain, ytrain, xtest, ytest, epochs, lr, ns=0.1, momentum=0.8, patience=100, batch_size=5, activation=\"tahn\", hidden_layer_size=10):\n",
    "    \"\"\"\n",
    "    Method to train Networks \n",
    "    \"\"\"\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    # define model\n",
    "    model = Sequential([Dense(hidden_layer_size, activation=activation, input_dim=1),\n",
    "                        Dense(1, activation='linear')\n",
    "                       ])\n",
    "                       \n",
    "    # compile model\n",
    "    opt = SGD(lr, momentum=momentum)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mse'])\n",
    "    # fit model\n",
    "    history = model.fit(xtrain, ytrain, validation_data=(xtest, ytest), epochs=epochs,  batch_size=batch_size, verbose=0, callbacks=[early_stop])\n",
    "\n",
    "    # plot learning curves\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.title('learning rate='+str(lr), pad=-80)\n",
    "\n",
    "    plt.legend()\n",
    "    output_path = \"imgs/model_loss_ns=%.2f_epochs=%d_lr=%.2f_mom=%.2f_activation=%s_pati=%d.png\"  %(ns, epochs, lr, momentum, activation, patience)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for the Exercise\n",
    "\n",
    "In this report, we try different setups of noise scale (ns), activation functions (af), learning rates (lr), patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Creating hyperparameters options\n",
    "#\n",
    "\n",
    "noise_scale_list = [0.05, 0.1, 0.2]\n",
    "act_func_list = [\"relu\", \"tanh\", \"sigmoid\"]\n",
    "lr_list = [0.01, 0.1]\n",
    "patience_list = [100, 300]\n",
    "hidden_layer_list = [10, 50, 100]\n",
    "\n",
    "# TODO: remove #####################\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "noise_scale_list = random.sample(noise_scale_list,1)\n",
    "act_func_list = random.sample(act_func_list,1)\n",
    "lr_list = random.sample(lr_list,1)\n",
    "patience_list = random.sample(patience_list,1)\n",
    "hidden_layer_list = random.sample(hidden_layer_list,1)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "noise_scale_list = [0.1]\n",
    "act_func_list = [\"relu\"]\n",
    "lr_list = [0.01]\n",
    "patience_list = [100]\n",
    "hidden_layer_list = [100]\n",
    "\"\"\"\n",
    "\n",
    "###########################\n",
    "epochs = 2000\n",
    "\n",
    "# Min and max value of sin function to learn\n",
    "min_value = 0\n",
    "max_value = 2*np.pi\n",
    "batch_size=5\n",
    "\n",
    "test_ratio = 0.3\n",
    "\n",
    "num_examples = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training network (ns: 0.05, act_funct: relu; lr: 0.01; patience:100, hidden_layer_size:10) ===\n",
      "=== Training network (ns: 0.05, act_funct: relu; lr: 0.01; patience:100, hidden_layer_size:50) ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "for ns in noise_scale_list:\n",
    "    for act_funct in act_func_list:\n",
    "        for lr in lr_list:\n",
    "            for patience in patience_list:\n",
    "                for hidden_layer_size in hidden_layer_list:\n",
    "                    print(\"=== Training network (ns: %.2f, act_funct: %s; lr: %.2f; patience:%d, hidden_layer_size:%d) ===\" % (ns, act_funct, lr, patience, hidden_layer_size))\n",
    "\n",
    "                    #\n",
    "                    # Preparing dataset\n",
    "                    #\n",
    "                    xtrain, ytrain, xtest, ytest = prepare_data(\n",
    "                        ntot=num_examples, \n",
    "                        noise_scale=ns, \n",
    "                        out_start=0, out_end=max_value, \n",
    "                        test_size=test_ratio\n",
    "                    )\n",
    "\n",
    "                    scaler = preprocessing.MinMaxScaler()\n",
    "                    # fit using the train set\n",
    "                    scaler.fit(xtrain)\n",
    "                    # transform the test test\n",
    "                    xtrainN = scaler.transform(xtrain)\n",
    "                    xtestN = scaler.transform(xtest) \n",
    "\n",
    "                    X = np.linspace(0.0 , 2.0 * np.pi, num_examples).reshape(-1, 1)\n",
    "                    XN = scaler.transform(X)\n",
    "\n",
    "                    #\n",
    "                    # Fitting model\n",
    "                    #\n",
    "                    \n",
    "                    model = fit_model(\n",
    "                        xtrainN, ytrain, xtestN, ytest, epochs=epochs, lr=lr, activation=act_funct, \n",
    "                        patience=patience, hidden_layer_size=hidden_layer_size, batch_size=batch_size\n",
    "                    )\n",
    "\n",
    "                    #\n",
    "                    # Making predictions\n",
    "                    #\n",
    "                    Y = model.predict(XN)\n",
    "                    plt.plot(XN,Y,color = 'red', marker = \"o\", label=\"model prediction\")\n",
    "                    plt.plot(xtestN.T,ytest.T,color = 'black', marker= \"+\")\n",
    "                    plt.title(\"seno\")\n",
    "                    plt.xlabel(\"Angulo\")\n",
    "                    plt.ylabel(\"Seno\")\n",
    "                    plt.grid()\n",
    "                    output_path = \"imgs/prediction_ns=%.2f_activation=%s_lr=%.2f_pati=%d_hidden=%d.png\"  % (ns, act_funct, lr, patience, hidden_layer_size)\n",
    "                    plt.tight_layout()\n",
    "                    plt.legend()\n",
    "                    plt.savefig(output_path, dpi=200)\n",
    "                    plt.close()\n",
    "\n",
    "                    y_pred = model.predict(xtestN)\n",
    "                    mse = mean_squared_error(ytest, y_pred)\n",
    "\n",
    "                    data.append([ns, act_funct, lr, patience, hidden_layer_size, mse])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[    \"Ns\",    \"Activation\",    \"Lr\", \"patience\",\"hidden_layer\", \"mse\"])\n",
    "df.to_excel(\"results.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ml_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c79f3b749ac1c615955d5d100e4e2835a83d7f04dde803c7105836bec394313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
